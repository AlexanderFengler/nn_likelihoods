{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "from kde_training_utilities import kde_load_data\n",
    "from kde_training_utilities import kde_make_train_test_split\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9048756146472092664\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1286736053566926672\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 12048649421\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10892668698647814911\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0, compute capability: 5.2\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9910625608849971321\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Handle some cuda business\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "\n",
    "# Define folder in which dataset lies\n",
    "data_folder = '/media/data_cifs/afengler/data/kde/ornstein_uhlenbeck/train_test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get files in folder\n",
      "check if we have a train and test sets already\n",
      "folder clean so proceeding...\n",
      "read, concatenate and shuffle data\n",
      "get training and test indices\n",
      "writing to file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make train test split\n",
    "kde_make_train_test_split(folder = data_folder,\n",
    "                          p_train = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train test split\n",
    "cpm.data['train_features'], cpm.data['train_labels'], cpm.data['test_features'], cpm.data['test_labels'] = kde_load_data(folder = data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['test_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].iloc[171247010, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']['log_l'] = cpm.data['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].sort_values(by = 'log_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].iloc[22428, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_labels'][22428, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 3,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'sigmoid',\n",
       " 'hidden_layers': [20, 20, 20, 20],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 2000,\n",
       " 'batch_size': 10000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'choice_probabilities',\n",
       " 'model_directory': '/media/data_cifs/afengler/git_repos/nn_likelihoods/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_choice_probabilities_analytic_',\n",
       " 'timestamp': '06_27_19_22_30_06',\n",
       " 'training_data_size': 2500000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, specify new set of parameters here:\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['hidden_layers'] = [20, 40, 60, 80, 100, 120]\n",
    "cpm.model_params['hidden_activations'] = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "cpm.model_params['input_shape'] = cpm.data['train_features'].shape[1]\n",
    "# cpm.model_params['l1_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "# cpm.model_params['l2_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l1_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l2_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "# Train params\n",
    "cpm.train_params['batch_size'] = 1000000\n",
    "cpm.train_params['max_train_epochs'] = 250\n",
    "cpm.train_params['min_delta'] = 0.00001\n",
    "\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'kde'\n",
    "cpm.data_params['data_type_signature'] = '_ornstein_uhlenbeck_'\n",
    "cpm.data_params['training_data_size'] = cpm.data['train_features'].shape[0]\n",
    "cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "cpm.data_params['model_directory'] = '/media/data_cifs/afengler/data/kde/linear_collapse/keras_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/afengler/.local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/afengler/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Make model\n",
    "cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191409589 samples, validate on 47844971 samples\n",
      "WARNING:tensorflow:From /home/afengler/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/250\n",
      "191409589/191409589 [==============================] - 334s 2us/sample - loss: 0.1637 - mean_squared_error: 0.1637 - val_loss: 0.0945 - val_mean_squared_error: 0.0945\n",
      "Epoch 2/250\n",
      "191409589/191409589 [==============================] - 554s 3us/sample - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 3/250\n",
      "191409589/191409589 [==============================] - 567s 3us/sample - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
      "Epoch 4/250\n",
      "191409589/191409589 [==============================] - 580s 3us/sample - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 5/250\n",
      "191409589/191409589 [==============================] - 578s 3us/sample - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "Epoch 6/250\n",
      "191409589/191409589 [==============================] - 588s 3us/sample - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 7/250\n",
      "191409589/191409589 [==============================] - 577s 3us/sample - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 8/250\n",
      "191409589/191409589 [==============================] - 565s 3us/sample - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 9/250\n",
      "191409589/191409589 [==============================] - 570s 3us/sample - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 10/250\n",
      "191000000/191409589 [============================>.] - ETA: 1s - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 00010: val_loss improved from inf to 0.00601, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models//dnnregressor_ornstein_uhlenbeck_06_28_19_00_43_25/ckpt_0_10\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f14cc4c4b38>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From /home/afengler/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "191409589/191409589 [==============================] - 571s 3us/sample - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 11/250\n",
      "191409589/191409589 [==============================] - 566s 3us/sample - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 12/250\n",
      "191409589/191409589 [==============================] - 569s 3us/sample - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 13/250\n",
      "191409589/191409589 [==============================] - 558s 3us/sample - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 14/250\n",
      "191409589/191409589 [==============================] - 561s 3us/sample - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
      "Epoch 15/250\n",
      "191409589/191409589 [==============================] - 553s 3us/sample - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 16/250\n",
      "191409589/191409589 [==============================] - 556s 3us/sample - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
      "Epoch 17/250\n",
      "191409589/191409589 [==============================] - 548s 3us/sample - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 18/250\n",
      "191409589/191409589 [==============================] - 551s 3us/sample - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 19/250\n",
      "191409589/191409589 [==============================] - 558s 3us/sample - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 20/250\n",
      "191000000/191409589 [============================>.] - ETA: 1s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 00020: val_loss improved from 0.00601 to 0.00339, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models//dnnregressor_ornstein_uhlenbeck_06_28_19_00_43_25/ckpt_0_20\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f14cc4c4b38>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "191409589/191409589 [==============================] - 563s 3us/sample - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 21/250\n",
      "191409589/191409589 [==============================] - 563s 3us/sample - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 22/250\n",
      "191409589/191409589 [==============================] - 555s 3us/sample - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 23/250\n",
      "191409589/191409589 [==============================] - 555s 3us/sample - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 24/250\n",
      "191409589/191409589 [==============================] - 545s 3us/sample - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 25/250\n",
      "191409589/191409589 [==============================] - 539s 3us/sample - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 26/250\n",
      "191409589/191409589 [==============================] - 541s 3us/sample - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 27/250\n",
      "191409589/191409589 [==============================] - 545s 3us/sample - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 28/250\n",
      "191409589/191409589 [==============================] - 538s 3us/sample - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 29/250\n",
      "191409589/191409589 [==============================] - 534s 3us/sample - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 30/250\n",
      "191000000/191409589 [============================>.] - ETA: 1s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 00030: val_loss did not improve from 0.00339\n",
      "191409589/191409589 [==============================] - 531s 3us/sample - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 31/250\n",
      "191409589/191409589 [==============================] - 541s 3us/sample - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 32/250\n",
      "191409589/191409589 [==============================] - 532s 3us/sample - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 33/250\n",
      "191409589/191409589 [==============================] - 550s 3us/sample - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191409589/191409589 [==============================] - 568s 3us/sample - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 35/250\n",
      "191409589/191409589 [==============================] - 565s 3us/sample - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 36/250\n",
      "191409589/191409589 [==============================] - 561s 3us/sample - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 37/250\n",
      "191409589/191409589 [==============================] - 571s 3us/sample - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 38/250\n",
      "191409589/191409589 [==============================] - 569s 3us/sample - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 39/250\n",
      "191409589/191409589 [==============================] - 570s 3us/sample - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 40/250\n",
      "191000000/191409589 [============================>.] - ETA: 1s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 00040: val_loss improved from 0.00339 to 0.00297, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models//dnnregressor_ornstein_uhlenbeck_06_28_19_00_43_25/ckpt_0_40\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f14cc4c4b38>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "191409589/191409589 [==============================] - 563s 3us/sample - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 41/250\n",
      "191409589/191409589 [==============================] - 560s 3us/sample - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 42/250\n",
      "191409589/191409589 [==============================] - 537s 3us/sample - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 43/250\n",
      "191409589/191409589 [==============================] - 556s 3us/sample - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 44/250\n",
      "191409589/191409589 [==============================] - 549s 3us/sample - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 45/250\n",
      "191409589/191409589 [==============================] - 559s 3us/sample - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 46/250\n",
      "191409589/191409589 [==============================] - 560s 3us/sample - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 47/250\n",
      "191409589/191409589 [==============================] - 563s 3us/sample - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 48/250\n",
      "191409589/191409589 [==============================] - 547s 3us/sample - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 49/250\n",
      "191409589/191409589 [==============================] - 538s 3us/sample - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 50/250\n",
      "191000000/191409589 [============================>.] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00050: val_loss improved from 0.00297 to 0.00203, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models//dnnregressor_ornstein_uhlenbeck_06_28_19_00_43_25/ckpt_0_50\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f14cc4c4b38>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "191409589/191409589 [==============================] - 529s 3us/sample - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 51/250\n",
      "191409589/191409589 [==============================] - 558s 3us/sample - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 52/250\n",
      "191409589/191409589 [==============================] - 551s 3us/sample - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 53/250\n",
      "191409589/191409589 [==============================] - 552s 3us/sample - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 54/250\n",
      "191409589/191409589 [==============================] - 552s 3us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 55/250\n",
      "191409589/191409589 [==============================] - 551s 3us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 56/250\n",
      "191409589/191409589 [==============================] - 557s 3us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 57/250\n",
      "191409589/191409589 [==============================] - 558s 3us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 58/250\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "cpm.run_training(save_history = True, \n",
    "                 warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
