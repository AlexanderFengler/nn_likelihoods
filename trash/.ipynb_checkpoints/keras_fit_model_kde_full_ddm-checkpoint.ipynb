{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "from kde_training_utilities import kde_load_data\n",
    "from kde_training_utilities import kde_make_train_test_split\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 517495730777844184\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2763179331810708776\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 12048773940\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11339983372263015286\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 384169191045836116\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Handle some cuda business\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "\n",
    "# Define folder in which dataset lies\n",
    "data_folder = '/media/data_cifs/afengler/data/kde/linear_collapse/train_test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train test split\n",
    "kde_make_train_test_split(folder = data_folder,\n",
    "                          p_train = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train test split\n",
    "cpm.data['train_features'], cpm.data['train_labels'], cpm.data['test_features'], cpm.data['test_labels'] = kde_load_data(folder = data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['test_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].iloc[171247010, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']['log_l'] = cpm.data['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].sort_values(by = 'log_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_features'].iloc[22428, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.data['train_labels'][22428, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 7,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'linear',\n",
       " 'hidden_layers': [20, 40, 60, 80, 100, 120],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 200,\n",
       " 'batch_size': 200000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'kde',\n",
       " 'model_directory': '/media/data_cifs/afengler/data/kde/linear_collapse/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_ddm_linear_collapse_',\n",
       " 'timestamp': '06_22_19_23_20_30',\n",
       " 'training_data_size': 143268157,\n",
       " 'timestep': '06_22_19_23_16_39'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, specify new set of parameters here:\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['hidden_layers'] = [20, 40, 60, 80, 100, 120]\n",
    "cpm.model_params['hidden_activations'] = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "cpm.model_params['input_shape'] = cpm.data['train_features'].shape[1]\n",
    "# cpm.model_params['l1_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "# cpm.model_params['l2_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l1_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l2_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "# Train params\n",
    "cpm.train_params['batch_size'] = 1000000\n",
    "cpm.train_params['max_train_epochs'] = 250\n",
    "cpm.train_params['min_delta'] = 0.00001\n",
    "\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'kde'\n",
    "cpm.data_params['data_type_signature'] = '_ddm_linear_collapse_'\n",
    "cpm.data_params['training_data_size'] = cpm.data['train_features'].shape[0]\n",
    "cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "cpm.data_params['model_directory'] = '/media/data_cifs/afengler/data/kde/linear_collapse/keras_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143268157 samples, validate on 35823203 samples\n",
      "Epoch 1/250\n",
      "143268157/143268157 [==============================] - 284s 2us/sample - loss: 0.1071 - mean_squared_error: 0.1071 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "Epoch 2/250\n",
      "143268157/143268157 [==============================] - 249s 2us/sample - loss: 0.0412 - mean_squared_error: 0.0412 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "Epoch 3/250\n",
      "143268157/143268157 [==============================] - 278s 2us/sample - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 4/250\n",
      "143268157/143268157 [==============================] - 260s 2us/sample - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 5/250\n",
      "143268157/143268157 [==============================] - 417s 3us/sample - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 7/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 8/250\n",
      "143268157/143268157 [==============================] - 249s 2us/sample - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Epoch 9/250\n",
      "143268157/143268157 [==============================] - 246s 2us/sample - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 10/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 00010: val_loss improved from inf to 0.00936, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_10\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From /home/afengler/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 11/250\n",
      "143268157/143268157 [==============================] - 238s 2us/sample - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
      "Epoch 12/250\n",
      "143268157/143268157 [==============================] - 237s 2us/sample - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
      "Epoch 13/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 14/250\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 15/250\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 16/250\n",
      "143268157/143268157 [==============================] - 254s 2us/sample - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 17/250\n",
      "143268157/143268157 [==============================] - 256s 2us/sample - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 18/250\n",
      "143268157/143268157 [==============================] - 259s 2us/sample - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 19/250\n",
      "143268157/143268157 [==============================] - 260s 2us/sample - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 20/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 00020: val_loss improved from 0.00936 to 0.00392, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_20\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 271s 2us/sample - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 21/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 22/250\n",
      "143268157/143268157 [==============================] - 240s 2us/sample - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 23/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 24/250\n",
      "143268157/143268157 [==============================] - 371s 3us/sample - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 25/250\n",
      "143268157/143268157 [==============================] - 366s 3us/sample - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 26/250\n",
      "143268157/143268157 [==============================] - 392s 3us/sample - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 27/250\n",
      "143268157/143268157 [==============================] - 387s 3us/sample - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
      "Epoch 28/250\n",
      "143268157/143268157 [==============================] - 389s 3us/sample - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 29/250\n",
      "143268157/143268157 [==============================] - 385s 3us/sample - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 30/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 00030: val_loss improved from 0.00392 to 0.00318, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_30\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 367s 3us/sample - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 31/250\n",
      "143268157/143268157 [==============================] - 386s 3us/sample - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 32/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143268157/143268157 [==============================] - 380s 3us/sample - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 33/250\n",
      "143268157/143268157 [==============================] - 387s 3us/sample - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 34/250\n",
      "143268157/143268157 [==============================] - 373s 3us/sample - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 35/250\n",
      "143268157/143268157 [==============================] - 384s 3us/sample - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 36/250\n",
      "143268157/143268157 [==============================] - 367s 3us/sample - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 37/250\n",
      "143268157/143268157 [==============================] - 377s 3us/sample - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 38/250\n",
      "143268157/143268157 [==============================] - 378s 3us/sample - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 39/250\n",
      "143268157/143268157 [==============================] - 369s 3us/sample - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 40/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 00040: val_loss did not improve from 0.00318\n",
      "143268157/143268157 [==============================] - 353s 2us/sample - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.1062 - val_mean_squared_error: 0.1062\n",
      "Epoch 41/250\n",
      "143268157/143268157 [==============================] - 267s 2us/sample - loss: 0.0945 - mean_squared_error: 0.0945 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 42/250\n",
      "143268157/143268157 [==============================] - 240s 2us/sample - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 43/250\n",
      "143268157/143268157 [==============================] - 237s 2us/sample - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 44/250\n",
      "143268157/143268157 [==============================] - 238s 2us/sample - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 45/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 46/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 47/250\n",
      "143268157/143268157 [==============================] - 240s 2us/sample - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 48/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 49/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 50/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00050: val_loss improved from 0.00318 to 0.00216, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_50\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 51/250\n",
      "143268157/143268157 [==============================] - 246s 2us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 52/250\n",
      "143268157/143268157 [==============================] - 254s 2us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 53/250\n",
      "143268157/143268157 [==============================] - 261s 2us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 54/250\n",
      "143268157/143268157 [==============================] - 263s 2us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 55/250\n",
      "143268157/143268157 [==============================] - 263s 2us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 56/250\n",
      "143268157/143268157 [==============================] - 262s 2us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 57/250\n",
      "143268157/143268157 [==============================] - 264s 2us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 58/250\n",
      "143268157/143268157 [==============================] - 289s 2us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 59/250\n",
      "143268157/143268157 [==============================] - 239s 2us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 60/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 00060: val_loss improved from 0.00216 to 0.00188, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_60\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 61/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 62/250\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 63/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 64/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 65/250\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 66/250\n",
      "143268157/143268157 [==============================] - 241s 2us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 67/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 69/250\n",
      "143268157/143268157 [==============================] - 258s 2us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 70/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 00070: val_loss improved from 0.00188 to 0.00157, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_70\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 259s 2us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 71/250\n",
      "143268157/143268157 [==============================] - 283s 2us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 72/250\n",
      "143268157/143268157 [==============================] - 264s 2us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 73/250\n",
      "143268157/143268157 [==============================] - 276s 2us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 74/250\n",
      "143268157/143268157 [==============================] - 266s 2us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 75/250\n",
      "143268157/143268157 [==============================] - 267s 2us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 76/250\n",
      "143268157/143268157 [==============================] - 275s 2us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 77/250\n",
      "143268157/143268157 [==============================] - 267s 2us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 78/250\n",
      "143268157/143268157 [==============================] - 267s 2us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 79/250\n",
      "143268157/143268157 [==============================] - 268s 2us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 80/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 00080: val_loss improved from 0.00157 to 0.00126, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_80\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 238s 2us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 81/250\n",
      "143268157/143268157 [==============================] - 241s 2us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 82/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 83/250\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 84/250\n",
      "143268157/143268157 [==============================] - 248s 2us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 85/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 86/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 87/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 88/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 89/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 90/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 00090: val_loss improved from 0.00126 to 0.00104, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_90\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 91/250\n",
      "143268157/143268157 [==============================] - 260s 2us/sample - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 92/250\n",
      "143268157/143268157 [==============================] - 261s 2us/sample - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 9.9239e-04 - val_mean_squared_error: 9.9239e-04\n",
      "Epoch 93/250\n",
      "143268157/143268157 [==============================] - 264s 2us/sample - loss: 9.9707e-04 - mean_squared_error: 9.9707e-04 - val_loss: 9.8257e-04 - val_mean_squared_error: 9.8257e-04\n",
      "Epoch 94/250\n",
      "143268157/143268157 [==============================] - 261s 2us/sample - loss: 9.7806e-04 - mean_squared_error: 9.7806e-04 - val_loss: 9.6165e-04 - val_mean_squared_error: 9.6165e-04\n",
      "Epoch 95/250\n",
      "143268157/143268157 [==============================] - 267s 2us/sample - loss: 9.6212e-04 - mean_squared_error: 9.6212e-04 - val_loss: 9.7525e-04 - val_mean_squared_error: 9.7525e-04\n",
      "Epoch 96/250\n",
      "143268157/143268157 [==============================] - 264s 2us/sample - loss: 9.4928e-04 - mean_squared_error: 9.4928e-04 - val_loss: 9.3857e-04 - val_mean_squared_error: 9.3857e-04\n",
      "Epoch 97/250\n",
      "143268157/143268157 [==============================] - 270s 2us/sample - loss: 9.3876e-04 - mean_squared_error: 9.3876e-04 - val_loss: 9.2744e-04 - val_mean_squared_error: 9.2744e-04\n",
      "Epoch 98/250\n",
      "143268157/143268157 [==============================] - 266s 2us/sample - loss: 9.2208e-04 - mean_squared_error: 9.2208e-04 - val_loss: 9.3204e-04 - val_mean_squared_error: 9.3204e-04\n",
      "Epoch 99/250\n",
      "143268157/143268157 [==============================] - 269s 2us/sample - loss: 9.1366e-04 - mean_squared_error: 9.1366e-04 - val_loss: 9.1791e-04 - val_mean_squared_error: 9.1791e-04\n",
      "Epoch 100/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 9.0068e-04 - mean_squared_error: 9.0068e-04\n",
      "Epoch 00100: val_loss improved from 0.00104 to 0.00089, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_100\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143268157/143268157 [==============================] - 270s 2us/sample - loss: 9.0061e-04 - mean_squared_error: 9.0061e-04 - val_loss: 8.9227e-04 - val_mean_squared_error: 8.9227e-04\n",
      "Epoch 101/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 8.8658e-04 - mean_squared_error: 8.8658e-04 - val_loss: 9.1677e-04 - val_mean_squared_error: 9.1677e-04\n",
      "Epoch 102/250\n",
      "143268157/143268157 [==============================] - 240s 2us/sample - loss: 8.7674e-04 - mean_squared_error: 8.7674e-04 - val_loss: 8.6740e-04 - val_mean_squared_error: 8.6740e-04\n",
      "Epoch 103/250\n",
      "143268157/143268157 [==============================] - 238s 2us/sample - loss: 8.7388e-04 - mean_squared_error: 8.7388e-04 - val_loss: 8.7592e-04 - val_mean_squared_error: 8.7592e-04\n",
      "Epoch 104/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 8.5673e-04 - mean_squared_error: 8.5673e-04 - val_loss: 8.4583e-04 - val_mean_squared_error: 8.4583e-04\n",
      "Epoch 105/250\n",
      "143268157/143268157 [==============================] - 241s 2us/sample - loss: 8.4765e-04 - mean_squared_error: 8.4765e-04 - val_loss: 8.4998e-04 - val_mean_squared_error: 8.4998e-04\n",
      "Epoch 106/250\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 8.4156e-04 - mean_squared_error: 8.4156e-04 - val_loss: 8.3013e-04 - val_mean_squared_error: 8.3013e-04\n",
      "Epoch 107/250\n",
      "143268157/143268157 [==============================] - 245s 2us/sample - loss: 8.3273e-04 - mean_squared_error: 8.3273e-04 - val_loss: 8.2665e-04 - val_mean_squared_error: 8.2665e-04\n",
      "Epoch 108/250\n",
      "143268157/143268157 [==============================] - 246s 2us/sample - loss: 8.2208e-04 - mean_squared_error: 8.2208e-04 - val_loss: 8.1612e-04 - val_mean_squared_error: 8.1612e-04\n",
      "Epoch 109/250\n",
      "143268157/143268157 [==============================] - 244s 2us/sample - loss: 8.1715e-04 - mean_squared_error: 8.1715e-04 - val_loss: 8.0959e-04 - val_mean_squared_error: 8.0959e-04\n",
      "Epoch 110/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 8.0600e-04 - mean_squared_error: 8.0600e-04\n",
      "Epoch 00110: val_loss improved from 0.00089 to 0.00081, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_110\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 252s 2us/sample - loss: 8.0599e-04 - mean_squared_error: 8.0599e-04 - val_loss: 8.0916e-04 - val_mean_squared_error: 8.0916e-04\n",
      "Epoch 111/250\n",
      "143268157/143268157 [==============================] - 256s 2us/sample - loss: 8.0040e-04 - mean_squared_error: 8.0040e-04 - val_loss: 8.0618e-04 - val_mean_squared_error: 8.0618e-04\n",
      "Epoch 112/250\n",
      "143268157/143268157 [==============================] - 262s 2us/sample - loss: 7.9380e-04 - mean_squared_error: 7.9380e-04 - val_loss: 7.8628e-04 - val_mean_squared_error: 7.8628e-04\n",
      "Epoch 113/250\n",
      "143268157/143268157 [==============================] - 261s 2us/sample - loss: 7.8368e-04 - mean_squared_error: 7.8368e-04 - val_loss: 7.7440e-04 - val_mean_squared_error: 7.7440e-04\n",
      "Epoch 114/250\n",
      "143268157/143268157 [==============================] - 266s 2us/sample - loss: 7.7922e-04 - mean_squared_error: 7.7922e-04 - val_loss: 7.8140e-04 - val_mean_squared_error: 7.8140e-04\n",
      "Epoch 115/250\n",
      "143268157/143268157 [==============================] - 261s 2us/sample - loss: 7.7482e-04 - mean_squared_error: 7.7482e-04 - val_loss: 7.9553e-04 - val_mean_squared_error: 7.9553e-04\n",
      "Epoch 116/250\n",
      "143268157/143268157 [==============================] - 263s 2us/sample - loss: 7.6501e-04 - mean_squared_error: 7.6501e-04 - val_loss: 7.6296e-04 - val_mean_squared_error: 7.6296e-04\n",
      "Epoch 117/250\n",
      "143268157/143268157 [==============================] - 265s 2us/sample - loss: 7.5834e-04 - mean_squared_error: 7.5834e-04 - val_loss: 7.7526e-04 - val_mean_squared_error: 7.7526e-04\n",
      "Epoch 118/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 7.5189e-04 - mean_squared_error: 7.5189e-04\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "143268157/143268157 [==============================] - 281s 2us/sample - loss: 7.5182e-04 - mean_squared_error: 7.5182e-04 - val_loss: 7.4344e-04 - val_mean_squared_error: 7.4344e-04\n",
      "Epoch 119/250\n",
      "143268157/143268157 [==============================] - 269s 2us/sample - loss: 7.3669e-04 - mean_squared_error: 7.3669e-04 - val_loss: 7.3804e-04 - val_mean_squared_error: 7.3804e-04\n",
      "Epoch 120/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 7.3583e-04 - mean_squared_error: 7.3583e-04\n",
      "Epoch 00120: val_loss improved from 0.00081 to 0.00074, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_120\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "143268157/143268157 [==============================] - 271s 2us/sample - loss: 7.3581e-04 - mean_squared_error: 7.3581e-04 - val_loss: 7.3736e-04 - val_mean_squared_error: 7.3736e-04\n",
      "Epoch 121/250\n",
      "143268157/143268157 [==============================] - 238s 2us/sample - loss: 7.3509e-04 - mean_squared_error: 7.3509e-04 - val_loss: 7.3700e-04 - val_mean_squared_error: 7.3700e-04\n",
      "Epoch 122/250\n",
      "143268157/143268157 [==============================] - 239s 2us/sample - loss: 7.3442e-04 - mean_squared_error: 7.3442e-04 - val_loss: 7.3614e-04 - val_mean_squared_error: 7.3614e-04\n",
      "Epoch 123/250\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 7.3372e-04 - mean_squared_error: 7.3372e-04 - val_loss: 7.3531e-04 - val_mean_squared_error: 7.3531e-04\n",
      "Epoch 124/250\n",
      "143268157/143268157 [==============================] - 243s 2us/sample - loss: 7.3290e-04 - mean_squared_error: 7.3290e-04 - val_loss: 7.3433e-04 - val_mean_squared_error: 7.3433e-04\n",
      "Epoch 125/250\n",
      "143268157/143268157 [==============================] - 246s 2us/sample - loss: 7.3204e-04 - mean_squared_error: 7.3204e-04 - val_loss: 7.3356e-04 - val_mean_squared_error: 7.3356e-04\n",
      "Epoch 126/250\n",
      "143268157/143268157 [==============================] - 266s 2us/sample - loss: 7.3120e-04 - mean_squared_error: 7.3120e-04 - val_loss: 7.3291e-04 - val_mean_squared_error: 7.3291e-04\n",
      "Epoch 127/250\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 7.3028e-04 - mean_squared_error: 7.3028e-04 - val_loss: 7.3200e-04 - val_mean_squared_error: 7.3200e-04\n",
      "Epoch 128/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 7.2934e-04 - mean_squared_error: 7.2934e-04\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "143268157/143268157 [==============================] - 242s 2us/sample - loss: 7.2940e-04 - mean_squared_error: 7.2940e-04 - val_loss: 7.3134e-04 - val_mean_squared_error: 7.3134e-04\n",
      "Epoch 129/250\n",
      "143268157/143268157 [==============================] - 247s 2us/sample - loss: 7.2859e-04 - mean_squared_error: 7.2859e-04 - val_loss: 7.3046e-04 - val_mean_squared_error: 7.3046e-04\n",
      "Epoch 130/250\n",
      "143000000/143268157 [============================>.] - ETA: 0s - loss: 7.2843e-04 - mean_squared_error: 7.2843e-04\n",
      "Epoch 00130: val_loss improved from 0.00074 to 0.00073, saving model to /media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_130\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Nadam object at 0x7f60568d7668>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143268157/143268157 [==============================] - 246s 2us/sample - loss: 7.2840e-04 - mean_squared_error: 7.2840e-04 - val_loss: 7.3034e-04 - val_mean_squared_error: 7.3034e-04\n",
      "Epoch 131/250\n",
      "143268157/143268157 [==============================] - 254s 2us/sample - loss: 7.2829e-04 - mean_squared_error: 7.2829e-04 - val_loss: 7.3026e-04 - val_mean_squared_error: 7.3026e-04\n",
      "Epoch 132/250\n",
      "143268157/143268157 [==============================] - 255s 2us/sample - loss: 7.2818e-04 - mean_squared_error: 7.2818e-04 - val_loss: 7.3011e-04 - val_mean_squared_error: 7.3011e-04\n",
      "Epoch 133/250\n",
      "111000000/143268157 [======================>.......] - ETA: 52s - loss: 7.2793e-04 - mean_squared_error: 7.2793e-04"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "cpm.run_training(save_history = True, \n",
    "                 warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
