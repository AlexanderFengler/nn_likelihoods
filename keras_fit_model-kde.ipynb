{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "from kde_training_utilities import kde_load_data\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6-tf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "\n",
    "# Load data\n",
    "data_folder = os.getcwd() + '/data_storage/kde/kde_ddm_flexbound_train_test_extended_params/'\n",
    "\n",
    "# rt_choice\n",
    "cpm.data['train_features'], cpm.data['train_labels'], cpm.data['test_features'], cpm.data['test_labels'] = kde_load_data(folder = data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 3,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'sigmoid',\n",
       " 'hidden_layers': [20, 20, 20, 20],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 2000,\n",
       " 'batch_size': 10000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'choice_probabilities',\n",
       " 'model_directory': '/home/afengler/git_repos/nn_likelihoods/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_choice_probabilities_analytic_',\n",
       " 'timestamp': '06_03_19_11_22_22',\n",
       " 'training_data_size': 2500000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, specify new set of parameters here:\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['hidden_layers'] = [10, 20, 40, 60, 80, 100, 120]\n",
    "cpm.model_params['hidden_activations'] = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "cpm.model_params['input_shape'] = cpm.data['train_features'].shape[1]\n",
    "cpm.model_params['l1_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l2_activation'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l1_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "cpm.model_params['l2_kernel'] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "# Train params\n",
    "cpm.train_params['batch_size'] = 200000\n",
    "cpm.train_params['max_train_epochs'] = 200\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'wfpt'\n",
    "cpm.data_params['data_type_signature'] = '_kde_ddm_flexbnd_c1_c2_'\n",
    "cpm.data_params['training_data_size'] = cpm.data['train_features'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 197646506 samples, validate on 21961430 samples\n",
      "Epoch 1/200\n",
      "197646506/197646506 [==============================] - 298s 2us/step - loss: 0.1485 - mean_squared_error: 0.1485 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
      "Epoch 2/200\n",
      "197646506/197646506 [==============================] - 298s 2us/step - loss: 0.0503 - mean_squared_error: 0.0503 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
      "Epoch 3/200\n",
      "197646506/197646506 [==============================] - 298s 2us/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
      "Epoch 4/200\n",
      "197646506/197646506 [==============================] - 298s 2us/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 5/200\n",
      "197646506/197646506 [==============================] - 328s 2us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
      "Epoch 6/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 8/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 9/200\n",
      "197646506/197646506 [==============================] - 332s 2us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 10/200\n",
      "197646506/197646506 [==============================] - 333s 2us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.01022, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models/dnnregressor_kde_ddm_flexbnd_c1_c2_06_03_19_11_22_22/ckpt_0_10\n",
      "Epoch 11/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 12/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
      "Epoch 13/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 14/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 15/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 16/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 17/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Epoch 18/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 19/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 20/200\n",
      "197646506/197646506 [==============================] - 333s 2us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01022 to 0.00445, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models/dnnregressor_kde_ddm_flexbnd_c1_c2_06_03_19_11_22_22/ckpt_0_20\n",
      "Epoch 21/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 22/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 23/200\n",
      "197646506/197646506 [==============================] - 338s 2us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 24/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 25/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 26/200\n",
      "197646506/197646506 [==============================] - 333s 2us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 27/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 28/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 29/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 30/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00445\n",
      "Epoch 31/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 32/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 33/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 34/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 35/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 36/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 37/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 38/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 39/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 40/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00445\n",
      "Epoch 41/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 42/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
      "Epoch 43/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 45/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "Epoch 46/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 47/200\n",
      "197646506/197646506 [==============================] - 333s 2us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 48/200\n",
      "197646506/197646506 [==============================] - 337s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 49/200\n",
      "197646506/197646506 [==============================] - 339s 2us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 50/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00445\n",
      "Epoch 51/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 52/200\n",
      "197646506/197646506 [==============================] - 335s 2us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 53/200\n",
      "197646506/197646506 [==============================] - 336s 2us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 54/200\n",
      "197646506/197646506 [==============================] - 328s 2us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
      "Epoch 55/200\n",
      "197646506/197646506 [==============================] - 334s 2us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 56/200\n",
      "  6800000/197646506 [>.............................] - ETA: 9:54 - loss: 0.0051 - mean_squared_error: 0.0051 "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "cpm.run_training(save_history = True, \n",
    "                 warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
