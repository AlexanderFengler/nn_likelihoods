{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_to_numpy as ktnp\n",
    "import pickle\n",
    "import cddm_data_simulation as cds\n",
    "import boundary_functions as bf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = '/users/afengler/OneDrive/project_nn_likelihoods/data/kde/ddm/keras_models/dnnregressor_ddm_03_29_20_17_38_58/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = pickle.load(open(my_dir + 'biases.pickle', 'rb'))\n",
    "weights = pickle.load(open(my_dir + 'weights.pickle', 'rb'))\n",
    "activations = pickle.load(open(my_dir + 'activations.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 100\n",
    "\n",
    "# Make dataset\n",
    "out = cds.ddm_flexbound(n_samples = 1024,\n",
    "                        boundary_fun = bf.constant,\n",
    "                        boundary_multiplicative = True,\n",
    "                        a = 2)\n",
    "out = np.concatenate([out[0], out[1]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rep = [0, 1, 0.5, 0.]\n",
    "keras_input_batch = np.zeros((out.shape[0], 6))\n",
    "keras_input_batch[:, :4] = params_rep\n",
    "keras_input_batch[:, 4:] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_target(params, data, ll_min = -16.11809):\n",
    "    mlp_input_batch = np.zeros((data.shape[0], 6))\n",
    "    mlp_input_batch[:, :4] = params\n",
    "    mlp_input_batch[:, 4:] = data\n",
    "    out = np.maximum(ktnp.predict(mlp_input_batch, weights, biases, activations, n_layers = 4), ll_min)\n",
    "    return np.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_target_class:\n",
    "    def __init__(self, \n",
    "                 data = [],\n",
    "                 weights = [],\n",
    "                 biases = [],\n",
    "                 activations = [],\n",
    "                 ll_min = -16.11809,\n",
    "                 n_params = 4):\n",
    "        \n",
    "        self.n_params = n_params\n",
    "        self.data = data\n",
    "        self.ll_min = ll_min\n",
    "        self.batch = np.zeros((self.data.shape[0], n_params + 2))\n",
    "        self.batch[:, self.n_params:] = data\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        self.activations = activations\n",
    "        \n",
    "    \n",
    "    def target(self, \n",
    "               params):\n",
    "        self.batch[:, :self.n_params] = np.tile(params, (self.data.shape[0], 1))\n",
    "        return np.sum(np.maximum(ktnp.predict(self.batch, self.weights, self.biases, self.activations, n_layers = 4), self.ll_min))\n",
    "    \n",
    "mlp = mlp_target_class(data = out,\n",
    "                       weights = weights,\n",
    "                       biases = biases,\n",
    "                       activations = activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.68 ms ± 1.5 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100 \n",
    "mlp_target(params_rep, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.93 ms ± 915 µs per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "mlp.target(params_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(my_dir + 'model_final.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.7 ms ± 5.95 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "\n",
    "model.predict(keras_input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              loss = 'mse',\n",
    "              metrics = ['mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3081bae4b49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit(data, labels, epochs = 10, \n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           validation_data = (val_data, val_labels))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs = 10, \n",
    "          batch_size = 32,\n",
    "          validation_data = (val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_data, val_labels, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data, labels, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath = my_dir + 'test1', save_format = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(my_dir + 'test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath = my_dir + 'test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  keras.models.load_model(my_dir + 'test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              loss = 'mse',\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint 0 generated\n",
      "datapoint 1000 generated\n",
      "datapoint 2000 generated\n",
      "datapoint 3000 generated\n",
      "datapoint 4000 generated\n",
      "datapoint 5000 generated\n",
      "datapoint 6000 generated\n",
      "datapoint 7000 generated\n",
      "datapoint 8000 generated\n",
      "datapoint 9000 generated\n",
      "datapoint 10000 generated\n",
      "datapoint 11000 generated\n",
      "datapoint 12000 generated\n",
      "datapoint 13000 generated\n",
      "datapoint 14000 generated\n",
      "datapoint 15000 generated\n",
      "datapoint 16000 generated\n",
      "datapoint 17000 generated\n",
      "datapoint 18000 generated\n",
      "datapoint 19000 generated\n"
     ]
    }
   ],
   "source": [
    "#### Let's try with what I have\n",
    "import make_data_wfpt as mdw\n",
    "\n",
    "data, _, __ = mdw.make_data_choice_probabilities(w_range = [0.5, 0.5], n_samples = 20000, write_to_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f, train_l, test_f, test_l = mdw.train_test_split_choice_probabilities(data = data, \n",
    "                                                                             write_to_file = False, \n",
    "                                                                             p_train = 0.5,\n",
    "                                                                             from_file = False,\n",
    "                                                                             backend = 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[6.97324307e-01],\n",
       "        [1.91735046e-01],\n",
       "        [9.82050363e-01],\n",
       "        ...,\n",
       "        [9.90762653e-01],\n",
       "        [3.31784413e-02],\n",
       "        [1.75328882e-04]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(20, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(20, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(20, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(20, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              loss = 'mse',\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 3.5339e-04 - mean_squared_error: 3.5339e-04\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 8.1693e-05 - mean_squared_error: 8.1693e-05\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 4.6798e-05 - mean_squared_error: 4.6798e-05\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 3.5434e-05 - mean_squared_error: 3.5434e-05\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 2.5602e-05 - mean_squared_error: 2.5602e-05\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 2.1532e-05 - mean_squared_error: 2.1532e-05\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 1.7687e-05 - mean_squared_error: 1.7687e-05\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 1.4976e-05 - mean_squared_error: 1.4976e-05\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 1.2238e-05 - mean_squared_error: 1.2238e-05\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 1.2078e-05 - mean_squared_error: 1.2078e-05\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 1.1060e-05 - mean_squared_error: 1.1060e-05\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 1.0958e-05 - mean_squared_error: 1.0958e-05\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 9.4156e-06 - mean_squared_error: 9.4156e-06\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 9.1004e-06 - mean_squared_error: 9.1004e-06\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 1.0303e-05 - mean_squared_error: 1.0303e-05\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 9.0057e-06 - mean_squared_error: 9.0057e-06\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 8.2336e-06 - mean_squared_error: 8.2336e-06\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 9.1368e-06 - mean_squared_error: 9.1368e-06\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 7.8587e-06 - mean_squared_error: 7.8587e-06\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 9.3896e-06 - mean_squared_error: 9.3896e-06\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 1.0161e-05 - mean_squared_error: 1.0161e-05\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 7.7062e-06 - mean_squared_error: 7.7062e-06\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 1s 25us/step - loss: 7.3010e-06 - mean_squared_error: 7.3010e-06\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 6.2864e-06 - mean_squared_error: 6.2864e-06\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 8.5238e-06 - mean_squared_error: 8.5238e-06\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 6.7699e-06 - mean_squared_error: 6.7699e-06\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 1.0933e-05 - mean_squared_error: 1.0933e-05\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 7.5030e-06 - mean_squared_error: 7.5030e-06\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 1.0230e-05 - mean_squared_error: 1.0230e-05\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 9.0209e-06 - mean_squared_error: 9.0209e-06\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 7.1486e-06 - mean_squared_error: 7.1486e-06\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 5.5791e-06 - mean_squared_error: 5.5791e-06\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 9.4563e-06 - mean_squared_error: 9.4563e-06\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 6.1990e-06 - mean_squared_error: 6.1990e-06\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 5.4843e-06 - mean_squared_error: 5.4843e-06\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 6.1082e-06 - mean_squared_error: 6.1082e-06\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 6.9710e-06 - mean_squared_error: 6.9710e-06\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 6.0230e-06 - mean_squared_error: 6.0230e-06\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 6.5041e-06 - mean_squared_error: 6.5041e-06\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 7.3843e-06 - mean_squared_error: 7.3843e-06\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 5.9377e-06 - mean_squared_error: 5.9377e-06\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.2620e-06 - mean_squared_error: 5.2620e-06\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 1.0194e-05 - mean_squared_error: 1.0194e-05\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 5.2257e-06 - mean_squared_error: 5.2257e-06\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 6.6760e-06 - mean_squared_error: 6.6760e-06\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 5.2999e-06 - mean_squared_error: 5.2999e-06\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.1537e-06 - mean_squared_error: 5.1537e-06\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 5.8192e-06 - mean_squared_error: 5.8192e-06\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 4.7408e-06 - mean_squared_error: 4.7408e-06 0s - loss: 4.4697e-06 - mean_squared_error: 4.46\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 7.5299e-06 - mean_squared_error: 7.5299e-06\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 6.7193e-06 - mean_squared_error: 6.7193e-06\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 5.9322e-06 - mean_squared_error: 5.9322e-06\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 6.3712e-06 - mean_squared_error: 6.3712e-06\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 6.1544e-06 - mean_squared_error: 6.1544e-06\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 0s 24us/step - loss: 4.9888e-06 - mean_squared_error: 4.9888e-06\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 1s 25us/step - loss: 5.5239e-06 - mean_squared_error: 5.5239e-06\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 5.2724e-06 - mean_squared_error: 5.2724e-06\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 4.5586e-06 - mean_squared_error: 4.5586e-06\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 5.6226e-06 - mean_squared_error: 5.6226e-06\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 4.4612e-06 - mean_squared_error: 4.4612e-06\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 7.9069e-06 - mean_squared_error: 7.9069e-06\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 0s 25us/step - loss: 8.3864e-06 - mean_squared_error: 8.3864e-06\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 3.7427e-06 - mean_squared_error: 3.7427e-06\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 3.9248e-06 - mean_squared_error: 3.9248e-06\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 1s 25us/step - loss: 4.9552e-06 - mean_squared_error: 4.9552e-06\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 5.4792e-06 - mean_squared_error: 5.4792e-06\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 4.0999e-06 - mean_squared_error: 4.0999e-06\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 4.0137e-06 - mean_squared_error: 4.0137e-06\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 5.3558e-06 - mean_squared_error: 5.3558e-06\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 5.1630e-06 - mean_squared_error: 5.1630e-06\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 8.3517e-06 - mean_squared_error: 8.3517e-06\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 4.4971e-06 - mean_squared_error: 4.4971e-06\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 4.4519e-06 - mean_squared_error: 4.4519e-06\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 7.1112e-06 - mean_squared_error: 7.1112e-06\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 4.2722e-06 - mean_squared_error: 4.2722e-06\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.4057e-06 - mean_squared_error: 3.4057e-06\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.7725e-06 - mean_squared_error: 3.7725e-06\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 5.5091e-06 - mean_squared_error: 5.5091e-06\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 5.7818e-06 - mean_squared_error: 5.7818e-06\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 3.4875e-06 - mean_squared_error: 3.4875e-06\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 4.1454e-06 - mean_squared_error: 4.1454e-06\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 8.5366e-06 - mean_squared_error: 8.5366e-06\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 4.3796e-06 - mean_squared_error: 4.3796e-06\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 4.1252e-06 - mean_squared_error: 4.1252e-06\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 3.4937e-06 - mean_squared_error: 3.4937e-06\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 4.1853e-06 - mean_squared_error: 4.1853e-06\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 9.6535e-06 - mean_squared_error: 9.6535e-06\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 3.2211e-06 - mean_squared_error: 3.2211e-06\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 3.1911e-06 - mean_squared_error: 3.1911e-06\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 4.3274e-06 - mean_squared_error: 4.3274e-06\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 3.2458e-06 - mean_squared_error: 3.2458e-06\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 5.0425e-06 - mean_squared_error: 5.0425e-06\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 3.3164e-06 - mean_squared_error: 3.3164e-06\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 4.6126e-06 - mean_squared_error: 4.6126e-06\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 5.9171e-06 - mean_squared_error: 5.9171e-06\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 4.0133e-06 - mean_squared_error: 4.0133e-06\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 4.7618e-06 - mean_squared_error: 4.7618e-06\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 4.6384e-06 - mean_squared_error: 4.6384e-06\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 3.1363e-06 - mean_squared_error: 3.1363e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x182d74fcc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_f, train_l, epochs = 100, \n",
    "          batch_size = 100)\n",
    "          #validation_data = (val_data, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = model.predict(train_f, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = data['p_lower_barrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['p_lower_barrier_predicted'] = my_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keras_model(hidden_layers = [1,1,1], \n",
    "                     hidden_activations = ['relu', 'relu', 'relu'],\n",
    "                     output_layer = 1,\n",
    "                     output_activation = 'sigmoid'\n",
    "                     model_directory = ''):\n",
    "    \n",
    "    assert len(hidden_layers) == len(hidden_activation) or len(hidden_activations) == 1, 'Check that your layers and activations are of the correct dimensions'\n",
    "    if len(hidden_activations) == 1 and len(hidden_layers) > 1:\n",
    "        tmp  = hidden_activations[0]\n",
    "        for _ in range(0, len(hidden_layers) - 1, 1):\n",
    "            hidden_activations.append(tmp)\n",
    "    \n",
    "    # Defining the model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Hidden Layers\n",
    "    for cnt in range(0, len(layers), 1):\n",
    "        model.add(keras.layers.Dense(layers[cnt], activation = activations[cnt]))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(keras.layers.Dense(output_layer, activation = output_activation))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = keras.,\n",
    "                  loss = 'mse',\n",
    "                  metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'data_type': 'choice_probabilities',\n",
    "          'input_shape': 3,\n",
    "          'output_shape': 1,\n",
    "          'output_activation': 'sigmoid',\n",
    "          'hidden_layers': [20, 20, 20],\n",
    "          'hidden_activations': ['relu', 'relu', 'relu'], \n",
    "          'l1_activation': [0.0, 0.0, 0.0], \n",
    "          'l2_activation': [0.0, 0.0, 0.0],\n",
    "          'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
    "          'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
    "          'optimizer': 'Nadam',\n",
    "          'loss': 'mse',\n",
    "          'metrics': ['mse'],\n",
    "          'batch_size': 100,\n",
    "          'max_epoch': 1000,\n",
    "          'eval_after_n_epochs': 10,\n",
    "          'model_directory': '',\n",
    "          'training_data_size': 'online'\n",
    "          }\n",
    "\n",
    "def keras_model_fun(params):\n",
    "    \n",
    "    # This returns a tensor\n",
    "    inputs = keras.layers.Input(shape = (params['input_shape'], ))\n",
    "    \n",
    "    # Model hidden\n",
    "    op = keras.layers.Dense(params['hidden_layers'][0], \n",
    "                            activation = params['hidden_activations'][0],\n",
    "                            kernel_regularizer = keras.regularizers.l1_l2(l1 = params['l1_kernel'][0], \n",
    "                                                                          l2 = params['l2_kernel'][0]),\n",
    "                            activity_regularizer = keras.regularizers.l1_l2(l1 = params['l1_activation'][0], \n",
    "                                                                            l2 = params['l2_activation'][0])\n",
    "                           )(inputs)\n",
    "    \n",
    "    for cnt in range(1, len(params['hidden_layers']), 1):\n",
    "        op = keras.layers.Dense(params['hidden_layers'][cnt], \n",
    "                                activation = params['hidden_activations'][cnt],\n",
    "                                kernel_regularizer = keras.regularizers.l1_l2(l1 = params['l1_kernel'][cnt], \n",
    "                                                                          l2 = params['l2_kernel'][cnt]),\n",
    "                                activity_regularizer = keras.regularizers.l1_l2(l1 = params['l1_activation'][cnt], \n",
    "                                                                            l2 = params['l2_activation'][cnt]))(op)\n",
    "    \n",
    "    # Model output \n",
    "    outputs = keras.layers.Dense(params['output_shape'], params['output_activation'])(op)\n",
    "    \n",
    "    return keras.models.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = keras_model_fun(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = params['optimizer'],\n",
    "                 loss = params['loss'],\n",
    "                 metrics = params['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9991 samples, validate on 10009 samples\n",
      "Epoch 1/100\n",
      "9991/9991 [==============================] - 1s 141us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 2/100\n",
      "9991/9991 [==============================] - 0s 31us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 6.0047e-04 - val_mean_squared_error: 6.0047e-04\n",
      "Epoch 3/100\n",
      "9991/9991 [==============================] - 0s 32us/step - loss: 4.0163e-04 - mean_squared_error: 4.0163e-04 - val_loss: 3.0201e-04 - val_mean_squared_error: 3.0201e-04\n",
      "Epoch 4/100\n",
      "9991/9991 [==============================] - 0s 35us/step - loss: 2.1587e-04 - mean_squared_error: 2.1587e-04 - val_loss: 3.6825e-04 - val_mean_squared_error: 3.6825e-04\n",
      "Epoch 5/100\n",
      "9991/9991 [==============================] - 0s 35us/step - loss: 2.0793e-04 - mean_squared_error: 2.0793e-04 - val_loss: 1.1943e-04 - val_mean_squared_error: 1.1943e-04\n",
      "Epoch 6/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 1.8384e-04 - mean_squared_error: 1.8384e-04 - val_loss: 9.6840e-05 - val_mean_squared_error: 9.6840e-05\n",
      "Epoch 7/100\n",
      "9991/9991 [==============================] - 0s 36us/step - loss: 1.6131e-04 - mean_squared_error: 1.6131e-04 - val_loss: 1.0652e-04 - val_mean_squared_error: 1.0652e-04\n",
      "Epoch 8/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 1.5731e-04 - mean_squared_error: 1.5731e-04 - val_loss: 3.6507e-04 - val_mean_squared_error: 3.6507e-04\n",
      "Epoch 9/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 1.1075e-04 - mean_squared_error: 1.1075e-04 - val_loss: 9.8096e-05 - val_mean_squared_error: 9.8096e-05\n",
      "Epoch 10/100\n",
      "9991/9991 [==============================] - 0s 36us/step - loss: 1.8342e-04 - mean_squared_error: 1.8342e-04 - val_loss: 5.1885e-05 - val_mean_squared_error: 5.1885e-05\n",
      "Epoch 11/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 1.2350e-04 - mean_squared_error: 1.2350e-04 - val_loss: 1.0007e-04 - val_mean_squared_error: 1.0007e-04\n",
      "Epoch 12/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 1.0214e-04 - mean_squared_error: 1.0214e-04 - val_loss: 4.5587e-05 - val_mean_squared_error: 4.5587e-05\n",
      "Epoch 13/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 1.7131e-04 - mean_squared_error: 1.7131e-04 - val_loss: 6.9521e-04 - val_mean_squared_error: 6.9521e-04\n",
      "Epoch 14/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 6.5693e-05 - mean_squared_error: 6.5693e-05 - val_loss: 3.5756e-05 - val_mean_squared_error: 3.5756e-05\n",
      "Epoch 15/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 9.2324e-05 - mean_squared_error: 9.2324e-05 - val_loss: 3.3988e-05 - val_mean_squared_error: 3.3988e-05\n",
      "Epoch 16/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 3.1838e-05 - mean_squared_error: 3.1838e-05 - val_loss: 3.2167e-05 - val_mean_squared_error: 3.2167e-05\n",
      "Epoch 17/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 3.0761e-05 - mean_squared_error: 3.0761e-05 - val_loss: 3.1767e-05 - val_mean_squared_error: 3.1767e-05\n",
      "Epoch 18/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.9948e-05 - mean_squared_error: 2.9948e-05 - val_loss: 3.0337e-05 - val_mean_squared_error: 3.0337e-05\n",
      "Epoch 19/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.9261e-05 - mean_squared_error: 2.9261e-05 - val_loss: 2.9911e-05 - val_mean_squared_error: 2.9911e-05\n",
      "Epoch 20/100\n",
      "9991/9991 [==============================] - 0s 43us/step - loss: 2.8855e-05 - mean_squared_error: 2.8855e-05 - val_loss: 2.9221e-05 - val_mean_squared_error: 2.9221e-05\n",
      "Epoch 21/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.8245e-05 - mean_squared_error: 2.8245e-05 - val_loss: 2.8631e-05 - val_mean_squared_error: 2.8631e-05\n",
      "Epoch 22/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.7806e-05 - mean_squared_error: 2.7806e-05 - val_loss: 2.8115e-05 - val_mean_squared_error: 2.8115e-05\n",
      "Epoch 23/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.7308e-05 - mean_squared_error: 2.7308e-05 - val_loss: 2.7670e-05 - val_mean_squared_error: 2.7670e-05\n",
      "Epoch 24/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.6926e-05 - mean_squared_error: 2.6926e-05 - val_loss: 2.7381e-05 - val_mean_squared_error: 2.7381e-05\n",
      "Epoch 25/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.6507e-05 - mean_squared_error: 2.6507e-05 - val_loss: 2.7588e-05 - val_mean_squared_error: 2.7588e-05\n",
      "Epoch 26/100\n",
      "9991/9991 [==============================] - 0s 45us/step - loss: 2.6080e-05 - mean_squared_error: 2.6080e-05 - val_loss: 2.6586e-05 - val_mean_squared_error: 2.6586e-05\n",
      "Epoch 27/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.5931e-05 - mean_squared_error: 2.5931e-05 - val_loss: 2.6541e-05 - val_mean_squared_error: 2.6541e-05\n",
      "Epoch 28/100\n",
      "9991/9991 [==============================] - 0s 43us/step - loss: 2.5873e-05 - mean_squared_error: 2.5873e-05 - val_loss: 2.6551e-05 - val_mean_squared_error: 2.6551e-05\n",
      "Epoch 29/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.5837e-05 - mean_squared_error: 2.5837e-05 - val_loss: 2.6441e-05 - val_mean_squared_error: 2.6441e-05\n",
      "Epoch 30/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.5784e-05 - mean_squared_error: 2.5784e-05 - val_loss: 2.6312e-05 - val_mean_squared_error: 2.6312e-05\n",
      "Epoch 31/100\n",
      "9991/9991 [==============================] - 0s 47us/step - loss: 2.5723e-05 - mean_squared_error: 2.5723e-05 - val_loss: 2.6253e-05 - val_mean_squared_error: 2.6253e-05\n",
      "Epoch 32/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.5686e-05 - mean_squared_error: 2.5686e-05 - val_loss: 2.6285e-05 - val_mean_squared_error: 2.6285e-05\n",
      "Epoch 33/100\n",
      "9991/9991 [==============================] - 0s 48us/step - loss: 2.5609e-05 - mean_squared_error: 2.5609e-05 - val_loss: 2.6171e-05 - val_mean_squared_error: 2.6171e-05\n",
      "Epoch 34/100\n",
      "9991/9991 [==============================] - 0s 45us/step - loss: 2.5552e-05 - mean_squared_error: 2.5552e-05 - val_loss: 2.6058e-05 - val_mean_squared_error: 2.6058e-05\n",
      "Epoch 35/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.5497e-05 - mean_squared_error: 2.5497e-05 - val_loss: 2.6011e-05 - val_mean_squared_error: 2.6011e-05\n",
      "Epoch 36/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.5399e-05 - mean_squared_error: 2.5399e-05 - val_loss: 2.5910e-05 - val_mean_squared_error: 2.5910e-05\n",
      "Epoch 37/100\n",
      "9991/9991 [==============================] - 0s 44us/step - loss: 2.5377e-05 - mean_squared_error: 2.5377e-05 - val_loss: 2.5960e-05 - val_mean_squared_error: 2.5960e-05\n",
      "Epoch 38/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.5340e-05 - mean_squared_error: 2.5340e-05 - val_loss: 2.5858e-05 - val_mean_squared_error: 2.5858e-05\n",
      "Epoch 39/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.5301e-05 - mean_squared_error: 2.5301e-05 - val_loss: 2.5820e-05 - val_mean_squared_error: 2.5820e-05\n",
      "Epoch 40/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.5255e-05 - mean_squared_error: 2.5255e-05 - val_loss: 2.5793e-05 - val_mean_squared_error: 2.5793e-05\n",
      "Epoch 41/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.5239e-05 - mean_squared_error: 2.5239e-05 - val_loss: 2.5756e-05 - val_mean_squared_error: 2.5756e-05\n",
      "Epoch 42/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.5187e-05 - mean_squared_error: 2.5187e-05 - val_loss: 2.5733e-05 - val_mean_squared_error: 2.5733e-05\n",
      "Epoch 43/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.5122e-05 - mean_squared_error: 2.5122e-05 - val_loss: 2.5711e-05 - val_mean_squared_error: 2.5711e-05\n",
      "Epoch 44/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.5095e-05 - mean_squared_error: 2.5095e-05 - val_loss: 2.5707e-05 - val_mean_squared_error: 2.5707e-05\n",
      "Epoch 45/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.5062e-05 - mean_squared_error: 2.5062e-05 - val_loss: 2.5614e-05 - val_mean_squared_error: 2.5614e-05\n",
      "Epoch 46/100\n",
      "9991/9991 [==============================] - 0s 34us/step - loss: 2.5003e-05 - mean_squared_error: 2.5003e-05 - val_loss: 2.5466e-05 - val_mean_squared_error: 2.5466e-05\n",
      "Epoch 47/100\n",
      "9991/9991 [==============================] - 0s 36us/step - loss: 2.4972e-05 - mean_squared_error: 2.4972e-05 - val_loss: 2.5411e-05 - val_mean_squared_error: 2.5411e-05\n",
      "Epoch 48/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.4893e-05 - mean_squared_error: 2.4893e-05 - val_loss: 2.5345e-05 - val_mean_squared_error: 2.5345e-05\n",
      "Epoch 49/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.4858e-05 - mean_squared_error: 2.4858e-05 - val_loss: 2.5334e-05 - val_mean_squared_error: 2.5334e-05\n",
      "Epoch 50/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.4814e-05 - mean_squared_error: 2.4814e-05 - val_loss: 2.5285e-05 - val_mean_squared_error: 2.5285e-05\n",
      "Epoch 51/100\n",
      "9991/9991 [==============================] - 0s 45us/step - loss: 2.4755e-05 - mean_squared_error: 2.4755e-05 - val_loss: 2.5189e-05 - val_mean_squared_error: 2.5189e-05\n",
      "Epoch 52/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.4698e-05 - mean_squared_error: 2.4698e-05 - val_loss: 2.5132e-05 - val_mean_squared_error: 2.5132e-05\n",
      "Epoch 53/100\n",
      "9991/9991 [==============================] - 0s 36us/step - loss: 2.4642e-05 - mean_squared_error: 2.4642e-05 - val_loss: 2.5057e-05 - val_mean_squared_error: 2.5057e-05\n",
      "Epoch 54/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.4561e-05 - mean_squared_error: 2.4561e-05 - val_loss: 2.4987e-05 - val_mean_squared_error: 2.4987e-05\n",
      "Epoch 55/100\n",
      "9991/9991 [==============================] - 0s 46us/step - loss: 2.4521e-05 - mean_squared_error: 2.4521e-05 - val_loss: 2.4945e-05 - val_mean_squared_error: 2.4945e-05\n",
      "Epoch 56/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.4459e-05 - mean_squared_error: 2.4459e-05 - val_loss: 2.4841e-05 - val_mean_squared_error: 2.4841e-05\n",
      "Epoch 57/100\n",
      "9991/9991 [==============================] - 1s 57us/step - loss: 2.4390e-05 - mean_squared_error: 2.4390e-05 - val_loss: 2.4744e-05 - val_mean_squared_error: 2.4744e-05\n",
      "Epoch 58/100\n",
      "9991/9991 [==============================] - 0s 49us/step - loss: 2.4324e-05 - mean_squared_error: 2.4324e-05 - val_loss: 2.4647e-05 - val_mean_squared_error: 2.4647e-05\n",
      "Epoch 59/100\n",
      "9991/9991 [==============================] - 0s 48us/step - loss: 2.4265e-05 - mean_squared_error: 2.4265e-05 - val_loss: 2.4649e-05 - val_mean_squared_error: 2.4649e-05\n",
      "Epoch 60/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.4196e-05 - mean_squared_error: 2.4196e-05 - val_loss: 2.4622e-05 - val_mean_squared_error: 2.4622e-05\n",
      "Epoch 61/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.4121e-05 - mean_squared_error: 2.4121e-05 - val_loss: 2.4519e-05 - val_mean_squared_error: 2.4519e-05\n",
      "Epoch 62/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.4047e-05 - mean_squared_error: 2.4047e-05 - val_loss: 2.4350e-05 - val_mean_squared_error: 2.4350e-05\n",
      "Epoch 63/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.3983e-05 - mean_squared_error: 2.3983e-05 - val_loss: 2.4466e-05 - val_mean_squared_error: 2.4466e-05\n",
      "Epoch 64/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.3918e-05 - mean_squared_error: 2.3918e-05 - val_loss: 2.4255e-05 - val_mean_squared_error: 2.4255e-05\n",
      "Epoch 65/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.3829e-05 - mean_squared_error: 2.3829e-05 - val_loss: 2.4160e-05 - val_mean_squared_error: 2.4160e-05\n",
      "Epoch 66/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.3770e-05 - mean_squared_error: 2.3770e-05 - val_loss: 2.4101e-05 - val_mean_squared_error: 2.4101e-05\n",
      "Epoch 67/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.3700e-05 - mean_squared_error: 2.3700e-05 - val_loss: 2.3986e-05 - val_mean_squared_error: 2.3986e-05\n",
      "Epoch 68/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.3609e-05 - mean_squared_error: 2.3609e-05 - val_loss: 2.3871e-05 - val_mean_squared_error: 2.3871e-05\n",
      "Epoch 69/100\n",
      "9991/9991 [==============================] - 0s 35us/step - loss: 2.3540e-05 - mean_squared_error: 2.3540e-05 - val_loss: 2.3874e-05 - val_mean_squared_error: 2.3874e-05\n",
      "Epoch 70/100\n",
      "9991/9991 [==============================] - 0s 45us/step - loss: 2.3450e-05 - mean_squared_error: 2.3450e-05 - val_loss: 2.3752e-05 - val_mean_squared_error: 2.3752e-05\n",
      "Epoch 71/100\n",
      "9991/9991 [==============================] - 0s 44us/step - loss: 2.3359e-05 - mean_squared_error: 2.3359e-05 - val_loss: 2.3679e-05 - val_mean_squared_error: 2.3679e-05\n",
      "Epoch 72/100\n",
      "9991/9991 [==============================] - 1s 54us/step - loss: 2.3306e-05 - mean_squared_error: 2.3306e-05 - val_loss: 2.3621e-05 - val_mean_squared_error: 2.3621e-05\n",
      "Epoch 73/100\n",
      "9991/9991 [==============================] - 1s 51us/step - loss: 2.3228e-05 - mean_squared_error: 2.3228e-05 - val_loss: 2.3448e-05 - val_mean_squared_error: 2.3448e-05\n",
      "Epoch 74/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.3145e-05 - mean_squared_error: 2.3145e-05 - val_loss: 2.3397e-05 - val_mean_squared_error: 2.3397e-05\n",
      "Epoch 75/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.3052e-05 - mean_squared_error: 2.3052e-05 - val_loss: 2.3301e-05 - val_mean_squared_error: 2.3301e-05\n",
      "Epoch 76/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.2986e-05 - mean_squared_error: 2.2986e-05 - val_loss: 2.3218e-05 - val_mean_squared_error: 2.3218e-05\n",
      "Epoch 77/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.2884e-05 - mean_squared_error: 2.2884e-05 - val_loss: 2.3257e-05 - val_mean_squared_error: 2.3257e-05\n",
      "Epoch 78/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.2845e-05 - mean_squared_error: 2.2845e-05 - val_loss: 2.3048e-05 - val_mean_squared_error: 2.3048e-05\n",
      "Epoch 79/100\n",
      "9991/9991 [==============================] - 0s 43us/step - loss: 2.2743e-05 - mean_squared_error: 2.2743e-05 - val_loss: 2.2922e-05 - val_mean_squared_error: 2.2922e-05\n",
      "Epoch 80/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.2638e-05 - mean_squared_error: 2.2638e-05 - val_loss: 2.2825e-05 - val_mean_squared_error: 2.2825e-05\n",
      "Epoch 81/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.2580e-05 - mean_squared_error: 2.2580e-05 - val_loss: 2.2798e-05 - val_mean_squared_error: 2.2798e-05\n",
      "Epoch 82/100\n",
      "9991/9991 [==============================] - 0s 47us/step - loss: 2.2533e-05 - mean_squared_error: 2.2533e-05 - val_loss: 2.2615e-05 - val_mean_squared_error: 2.2615e-05\n",
      "Epoch 83/100\n",
      "9991/9991 [==============================] - 0s 42us/step - loss: 2.2413e-05 - mean_squared_error: 2.2413e-05 - val_loss: 2.2543e-05 - val_mean_squared_error: 2.2543e-05\n",
      "Epoch 84/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.2321e-05 - mean_squared_error: 2.2321e-05 - val_loss: 2.2445e-05 - val_mean_squared_error: 2.2445e-05\n",
      "Epoch 85/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.2259e-05 - mean_squared_error: 2.2259e-05 - val_loss: 2.2407e-05 - val_mean_squared_error: 2.2407e-05\n",
      "Epoch 86/100\n",
      "9991/9991 [==============================] - 0s 35us/step - loss: 2.2158e-05 - mean_squared_error: 2.2158e-05 - val_loss: 2.2397e-05 - val_mean_squared_error: 2.2397e-05\n",
      "Epoch 87/100\n",
      "9991/9991 [==============================] - 0s 36us/step - loss: 2.2064e-05 - mean_squared_error: 2.2064e-05 - val_loss: 2.2306e-05 - val_mean_squared_error: 2.2306e-05\n",
      "Epoch 88/100\n",
      "9991/9991 [==============================] - 0s 43us/step - loss: 2.2016e-05 - mean_squared_error: 2.2016e-05 - val_loss: 2.2124e-05 - val_mean_squared_error: 2.2124e-05\n",
      "Epoch 89/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.1920e-05 - mean_squared_error: 2.1920e-05 - val_loss: 2.2101e-05 - val_mean_squared_error: 2.2101e-05\n",
      "Epoch 90/100\n",
      "9991/9991 [==============================] - 0s 37us/step - loss: 2.1844e-05 - mean_squared_error: 2.1844e-05 - val_loss: 2.2105e-05 - val_mean_squared_error: 2.2105e-05\n",
      "Epoch 91/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.1755e-05 - mean_squared_error: 2.1755e-05 - val_loss: 2.2044e-05 - val_mean_squared_error: 2.2044e-05\n",
      "Epoch 92/100\n",
      "9991/9991 [==============================] - 0s 40us/step - loss: 2.1695e-05 - mean_squared_error: 2.1695e-05 - val_loss: 2.1781e-05 - val_mean_squared_error: 2.1781e-05\n",
      "Epoch 93/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.1594e-05 - mean_squared_error: 2.1594e-05 - val_loss: 2.1791e-05 - val_mean_squared_error: 2.1791e-05\n",
      "Epoch 94/100\n",
      "9991/9991 [==============================] - 0s 46us/step - loss: 2.1528e-05 - mean_squared_error: 2.1528e-05 - val_loss: 2.1759e-05 - val_mean_squared_error: 2.1759e-05\n",
      "Epoch 95/100\n",
      "9991/9991 [==============================] - 0s 41us/step - loss: 2.1467e-05 - mean_squared_error: 2.1467e-05 - val_loss: 2.1551e-05 - val_mean_squared_error: 2.1551e-05\n",
      "Epoch 96/100\n",
      "9991/9991 [==============================] - 0s 48us/step - loss: 2.1370e-05 - mean_squared_error: 2.1370e-05 - val_loss: 2.1566e-05 - val_mean_squared_error: 2.1566e-05\n",
      "Epoch 97/100\n",
      "9991/9991 [==============================] - 0s 38us/step - loss: 2.1267e-05 - mean_squared_error: 2.1267e-05 - val_loss: 2.1386e-05 - val_mean_squared_error: 2.1386e-05\n",
      "Epoch 98/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.1218e-05 - mean_squared_error: 2.1218e-05 - val_loss: 2.1354e-05 - val_mean_squared_error: 2.1354e-05\n",
      "Epoch 99/100\n",
      "9991/9991 [==============================] - 0s 35us/step - loss: 2.1161e-05 - mean_squared_error: 2.1161e-05 - val_loss: 2.1349e-05 - val_mean_squared_error: 2.1349e-05\n",
      "Epoch 100/100\n",
      "9991/9991 [==============================] - 0s 39us/step - loss: 2.1055e-05 - mean_squared_error: 2.1055e-05 - val_loss: 2.1219e-05 - val_mean_squared_error: 2.1219e-05\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(x = train_f, \n",
    "                       y = train_l,\n",
    "                       epochs = 100, \n",
    "                       batch_size = 100,\n",
    "                       validation_data = (test_f, test_l),\n",
    "                       callbacks = [keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                                                      factor = 0.1, \n",
    "                                                                      patience = 10, \n",
    "                                                                      min_lr = 1e-5),\n",
    "                                    keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 100),\n",
    "                                    keras.callbacks.ModelCheckpoint(filepath = my_dir + 'train_with_callbacks/ckpt',\n",
    "                                                                    save_best_only = True,\n",
    "                                                                    save_weights_only = True,\n",
    "                                                                    period = 10)\n",
    "                                   ]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x183140a1d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = keras_model_fun(params)\n",
    "my_model.compile(optimizer = params['optimizer'],\n",
    "                 loss = params['loss'],\n",
    "                 metrics = params['metrics'])\n",
    "my_model.load_weights(my_dir + 'train_with_callbacks/ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(my_dir + 'test_model2')\n",
    "my_model.save(filepath = my_dir + 'test_model2/test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  keras.models.load_model(my_dir + 'test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5.3501878e-02, -3.8291290e-01, -1.3873402e-04,  2.3711506e-02,\n",
       "         -5.6793118e-01, -3.7288409e-01, -4.4723815e-01,  3.0313849e-02,\n",
       "         -4.2380476e-01,  1.5921164e-01,  4.1881356e-01,  2.7000260e-01,\n",
       "          5.3909600e-01,  2.4060175e-02,  5.6342459e-01, -3.5284624e-01,\n",
       "         -3.2442370e-01, -4.2525742e-02,  1.8000557e-01,  4.1187021e-05],\n",
       "        [-8.8643292e-03,  2.5059929e-01, -9.2452914e-02, -1.2087687e-01,\n",
       "          5.1967257e-01,  2.8264743e-01, -7.8053361e-01, -2.4981338e-01,\n",
       "          3.2317790e-01,  2.8609073e-01, -7.5223631e-01,  1.6052245e-01,\n",
       "          3.7155911e-01, -5.9382163e-02,  2.8766555e-01,  2.1582919e-01,\n",
       "         -3.3368656e-01, -2.4818176e-01, -5.8487844e-02,  4.3979704e-01],\n",
       "        [-1.2427950e-01, -6.9166034e-01,  1.8783206e-01, -1.3588461e-01,\n",
       "          3.7705887e-02, -4.9139354e-01, -2.9214360e-02, -3.5200912e-01,\n",
       "         -8.4036559e-01, -2.2542517e-01, -8.9981571e-02,  3.8217396e-01,\n",
       "         -1.8241107e-01,  1.8269810e-01, -6.1910111e-01, -5.2983218e-01,\n",
       "          5.1193446e-01, -1.4991033e-02, -8.1867084e-02,  6.4732566e-02]],\n",
       "       dtype=float32),\n",
       " array([-0.19698335, -0.37711927, -0.08754428, -0.01165137, -0.08226121,\n",
       "        -0.1879976 ,  0.01820269,  0.        , -0.828851  , -0.43121907,\n",
       "         0.3300702 ,  0.06004297,  0.00203258,  0.04914565, -0.12425914,\n",
       "        -0.2728518 ,  0.18998453, -0.17871314,  0.08764067, -0.07701022],\n",
       "       dtype=float32),\n",
       " array([[-3.42190862e-02, -2.05413952e-01,  1.16766497e-01,\n",
       "         -7.46872276e-02, -2.67538100e-01,  2.06361338e-01,\n",
       "         -2.16684565e-01, -2.72017121e-01,  2.27070376e-01,\n",
       "         -2.63543755e-01,  2.06375182e-01,  2.72696346e-01,\n",
       "          1.34008437e-01,  1.68218166e-01,  2.30287254e-01,\n",
       "         -8.45826417e-02, -6.00615293e-02,  2.29341283e-01,\n",
       "          6.59839213e-01,  1.66574568e-01],\n",
       "        [ 6.43414021e-01,  3.61916721e-02, -2.55519152e-01,\n",
       "          1.15302503e+00,  4.43870008e-01,  6.74045384e-01,\n",
       "         -3.97007853e-01,  5.49179733e-01, -1.53372139e-02,\n",
       "          2.03774869e-01, -1.85787678e-04,  1.65930614e-01,\n",
       "         -2.02395275e-01,  5.29746890e-01,  3.46174598e-01,\n",
       "         -8.98990631e-02, -2.47036040e-01,  5.71634710e-01,\n",
       "         -2.26791818e-02,  3.08137268e-01],\n",
       "        [ 2.46399462e-01,  1.34896308e-01, -3.83054209e-03,\n",
       "         -3.52802187e-01,  7.06925169e-02,  3.97504747e-01,\n",
       "         -2.18805671e-01,  1.41887203e-01, -1.35083809e-01,\n",
       "         -2.83538640e-01, -4.12154257e-01,  2.78678745e-01,\n",
       "          4.53421324e-02, -3.90921831e-02, -1.81750044e-01,\n",
       "         -3.77821863e-01, -5.68835959e-02, -4.80819531e-02,\n",
       "          4.90910560e-02,  1.25395313e-01],\n",
       "        [-2.98839450e-01, -1.59867644e-01, -3.27911377e-01,\n",
       "         -1.64244056e-01, -1.23605162e-01, -5.37079163e-02,\n",
       "         -1.05556875e-01, -2.61641145e-01, -2.39462145e-02,\n",
       "         -3.69321071e-02, -2.88143843e-01,  9.98137295e-02,\n",
       "         -3.22009563e-01, -9.15954113e-02, -1.20411605e-01,\n",
       "         -2.83774287e-01,  1.86568707e-01, -2.88174242e-01,\n",
       "          2.16909885e-01, -2.98817694e-01],\n",
       "        [-2.23774731e-01,  1.18322827e-01, -1.52951494e-01,\n",
       "         -2.72746533e-01,  2.37042904e-01, -3.12863082e-01,\n",
       "         -1.56935990e-01, -2.28322178e-01,  2.90409118e-01,\n",
       "          3.69152874e-01, -7.87353367e-02,  2.66386211e-01,\n",
       "          4.90007579e-01,  5.47782660e-01, -1.55513555e-01,\n",
       "         -2.02162161e-01, -4.45598513e-02,  1.62222862e-01,\n",
       "          1.56015217e-01, -7.99892768e-02],\n",
       "        [ 9.05594677e-02,  8.92060921e-02,  6.81590617e-01,\n",
       "          1.83839560e-01,  1.19099595e-01,  1.50262013e-01,\n",
       "         -1.14559107e-01,  6.81610525e-01, -3.71922851e-01,\n",
       "         -2.83074360e-02,  3.81606743e-02, -1.86359629e-01,\n",
       "          2.90993363e-01,  3.12031806e-01, -2.01641366e-01,\n",
       "         -8.77441466e-02,  3.81723613e-01,  5.33027649e-01,\n",
       "          2.76344448e-01, -9.13537815e-02],\n",
       "        [-6.67659119e-02,  1.18483841e-01,  2.83050686e-01,\n",
       "         -3.01823586e-01, -5.58039308e-01,  7.18382895e-01,\n",
       "          4.04829830e-01, -3.86861920e-01,  1.66434944e-02,\n",
       "         -1.11922324e+00, -2.91523516e-01, -4.37536567e-01,\n",
       "         -4.57355559e-01, -8.86949450e-02, -8.18019688e-01,\n",
       "         -3.58566970e-01,  7.60699585e-02, -4.10447478e-01,\n",
       "         -8.82020116e-01,  8.55919778e-01],\n",
       "        [-1.93271339e-02,  1.16194367e-01, -3.57506245e-01,\n",
       "          2.63895333e-01,  1.29057467e-01,  2.33340204e-01,\n",
       "          3.39061022e-03, -1.01283550e-01,  3.17103088e-01,\n",
       "         -5.22272885e-02, -2.25148454e-01, -2.83572137e-01,\n",
       "          2.06942856e-01, -2.32413039e-01,  3.59128058e-01,\n",
       "         -4.84548509e-02,  1.85051501e-01,  9.99171138e-02,\n",
       "          3.82048249e-01, -1.65611506e-01],\n",
       "        [-7.41580315e-03, -2.19287872e-01, -2.54908185e-02,\n",
       "          7.22084880e-01, -9.28135455e-01,  6.90323472e-01,\n",
       "         -2.43745828e+00,  8.69549811e-01, -6.17859423e-01,\n",
       "          7.27931798e-01, -5.65626584e-02, -5.37183225e-01,\n",
       "         -8.86640847e-02,  3.83289754e-01, -2.85273641e-01,\n",
       "         -5.54534793e-03,  5.97140968e-01,  1.27738386e-01,\n",
       "          2.19985485e+00,  3.85570794e-01],\n",
       "        [ 3.25352699e-01, -4.14550155e-01,  7.70324051e-01,\n",
       "          6.41342282e-01, -6.11439943e-01,  4.29061288e-03,\n",
       "          2.75795907e-01, -2.94032991e-01, -1.27823204e-02,\n",
       "          5.11555411e-02,  2.13300213e-01, -7.65669525e-01,\n",
       "          2.67460376e-01, -2.08041370e-02,  1.64099470e-01,\n",
       "         -3.51203591e-01,  2.13539004e-01,  1.78379402e-01,\n",
       "         -6.55596614e-01,  3.28999072e-01],\n",
       "        [-2.94097513e-01, -1.73658177e-01, -2.15308055e-01,\n",
       "         -1.12395346e-01,  1.16381943e-01,  4.23315734e-01,\n",
       "         -9.47077811e-01,  5.67263484e-01,  2.70267010e-01,\n",
       "          4.00322080e-01,  6.36315465e-01, -2.20580306e-02,\n",
       "          7.76082873e-01,  1.03662066e-01, -4.51335371e-01,\n",
       "          9.06472132e-02, -8.65736008e-01,  1.73011541e-01,\n",
       "         -1.60230923e+00, -1.67084597e-02],\n",
       "        [-5.18289059e-02, -1.55658880e-03, -1.03440322e-01,\n",
       "         -3.45773607e-01, -1.02870059e+00, -1.46269873e-01,\n",
       "          3.87346059e-01, -2.12534249e-01,  1.67336419e-01,\n",
       "         -2.02648476e-01, -1.37914315e-01, -4.86371428e-01,\n",
       "         -3.03476423e-01, -2.57073075e-01, -3.41270529e-02,\n",
       "         -2.59250905e-02,  3.08292419e-01, -3.31283718e-01,\n",
       "         -5.24261594e-01,  3.77760798e-01],\n",
       "        [-1.78539250e-02,  1.90713480e-02,  2.79125959e-01,\n",
       "          2.80316919e-01,  1.44432232e-01,  2.69617796e-01,\n",
       "         -6.10658526e-01, -5.89019321e-02, -2.04472587e-01,\n",
       "         -2.02981606e-01, -9.12151784e-02,  3.36567849e-01,\n",
       "         -1.34526372e-01, -2.80152112e-01,  5.42506874e-01,\n",
       "          4.37807031e-02,  4.85088289e-01, -2.12068528e-01,\n",
       "          5.04231989e-01, -6.57624677e-02],\n",
       "        [ 4.39554080e-02, -3.35980415e-01, -9.05606329e-01,\n",
       "         -7.92478502e-01,  1.50974393e-01,  5.77702783e-02,\n",
       "          5.35095632e-01,  3.03235680e-01,  4.46998715e-01,\n",
       "          1.35801777e-01, -3.90132703e-02, -1.20741706e-02,\n",
       "         -1.14904232e-01,  1.40873849e-01, -1.21319285e-02,\n",
       "          2.39933819e-01,  3.31860662e-01, -4.27097350e-01,\n",
       "          2.14259565e-01,  1.87843636e-01],\n",
       "        [ 6.74977839e-01,  2.64456093e-01,  4.55283314e-01,\n",
       "          4.65421379e-01,  5.16265810e-01, -1.07380681e-01,\n",
       "          2.47304365e-01, -2.29635283e-01,  1.68239459e-01,\n",
       "          1.64941102e-02,  2.98759311e-01,  1.18994534e-01,\n",
       "          1.26810089e-01,  2.51086742e-01,  6.31252825e-01,\n",
       "         -2.47533396e-01,  4.68681365e-01, -8.76053423e-02,\n",
       "          3.56916618e-03, -3.97061169e-01],\n",
       "        [ 1.11766338e+00, -3.54375303e-01, -1.85019210e-01,\n",
       "         -1.06718190e-01,  3.63776356e-01,  8.55210602e-01,\n",
       "         -8.29292238e-01,  5.57198882e-01, -5.42300761e-01,\n",
       "          2.27964848e-01, -2.94794202e-01,  1.23735070e-02,\n",
       "         -2.03176752e-01,  3.70898604e-01,  7.42422417e-04,\n",
       "          6.57581091e-02,  2.39664450e-01,  4.43284214e-01,\n",
       "         -1.10984549e-01, -2.02397794e-01],\n",
       "        [-2.20620915e-01, -3.82441312e-01, -2.37281814e-01,\n",
       "         -5.09794429e-02,  5.87704144e-02, -6.31788224e-02,\n",
       "          3.01462919e-01, -1.32360503e-01,  1.73092768e-01,\n",
       "          4.59076136e-01,  4.22370315e-01,  2.23403826e-01,\n",
       "         -9.53988954e-02,  2.82450676e-01,  7.57463515e-01,\n",
       "          2.60963738e-02, -2.54380912e-01,  5.34781953e-03,\n",
       "          3.77590030e-01,  1.49795175e-01],\n",
       "        [ 4.92341407e-02, -1.64055377e-01,  2.75302559e-01,\n",
       "         -3.38312924e-01,  3.95465046e-02, -7.87110627e-02,\n",
       "         -2.41158530e-01,  3.72015566e-01, -2.95115658e-03,\n",
       "          5.29493950e-02,  2.26741359e-01,  9.26663503e-02,\n",
       "          1.88960761e-01, -3.09587955e-01,  1.27235875e-01,\n",
       "          3.08898479e-01, -3.73185277e-01, -1.02904253e-01,\n",
       "         -1.11150637e-01,  3.28392029e-01],\n",
       "        [-4.42625806e-02, -1.19450562e-01, -3.69031914e-02,\n",
       "         -3.84848416e-02,  3.26311588e-01,  1.69079021e-01,\n",
       "          3.83447409e-01,  1.41327485e-01,  1.91693202e-01,\n",
       "         -2.68546608e-03, -2.51043737e-02,  1.65688456e-03,\n",
       "          8.79710242e-02,  3.04376632e-01,  3.65532823e-02,\n",
       "          1.13439560e-01,  2.51585811e-01, -4.93568890e-02,\n",
       "          1.54685891e+00, -2.12288573e-01],\n",
       "        [ 4.00403351e-01, -2.02071577e-01, -1.33252636e-01,\n",
       "          3.32699686e-01,  2.02964798e-01,  1.94961771e-01,\n",
       "          3.33229274e-01,  4.77251142e-01, -3.45579177e-01,\n",
       "          2.41516784e-01, -1.26558101e+00,  3.47082317e-01,\n",
       "         -1.34106860e-01,  1.82657003e-01,  2.52743930e-01,\n",
       "         -4.12697732e-01,  1.11549318e-01,  5.22843301e-01,\n",
       "         -4.72663969e-01, -2.88638145e-01]], dtype=float32),\n",
       " array([-0.4499469 , -0.06432342, -0.7563362 , -0.5352553 , -0.19719297,\n",
       "        -0.0551387 ,  0.08795337,  0.02054262,  0.14885366, -0.040116  ,\n",
       "        -0.2867494 , -0.07179409, -0.11034403,  0.05030824,  0.07157329,\n",
       "        -0.13824818, -0.01108353, -0.09398589,  0.07098605,  0.3026551 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.66976207e-01,  3.31292212e-01,  2.41592973e-01,\n",
       "          7.20554233e-01,  3.96724083e-02,  1.45171374e-01,\n",
       "         -2.19447121e-01,  2.40311980e-01, -6.79628924e-02,\n",
       "         -2.57866919e-01, -3.57717484e-01,  5.04487269e-02,\n",
       "          2.18016788e-01, -4.83799994e-01, -6.50810778e-01,\n",
       "         -8.60947222e-02,  4.59726781e-01, -4.18312103e-01,\n",
       "          9.68766138e-02,  6.88548237e-02],\n",
       "        [ 1.45107791e-01, -5.96337058e-02,  2.27812901e-01,\n",
       "          2.98608303e-01,  3.19690794e-01, -1.73051909e-01,\n",
       "         -3.65994275e-02,  9.31000710e-03,  2.24225707e-02,\n",
       "          3.58541548e-01, -2.30732933e-01, -1.18615508e-01,\n",
       "          2.06041798e-01,  2.81333685e-01, -3.89141560e-01,\n",
       "         -3.03950936e-01,  2.61369079e-01,  1.18244164e-01,\n",
       "          1.90568089e-01, -2.67350435e-01],\n",
       "        [ 5.67451119e-01,  7.07427084e-01,  1.12861104e-01,\n",
       "          2.08247632e-01, -1.16767995e-02,  5.43439947e-02,\n",
       "         -1.70523942e-01, -1.06664717e-01,  5.14097512e-01,\n",
       "          3.54578376e-01,  3.18729192e-01, -1.53037682e-01,\n",
       "          1.08265623e-01,  4.50761467e-01,  5.18419266e-01,\n",
       "          5.71903884e-01, -5.20348430e-01, -4.58556861e-01,\n",
       "         -3.98039490e-01,  2.41555467e-01],\n",
       "        [ 6.92531943e-01,  7.11614728e-01,  4.13894415e-01,\n",
       "          5.64541340e-01, -2.68506676e-01,  6.06481172e-02,\n",
       "          2.41188407e-01, -3.46638262e-02,  4.18356359e-02,\n",
       "          1.90663338e-01, -5.43132797e-02, -5.64624071e-02,\n",
       "          2.01336622e-01, -6.60215437e-01,  7.41433427e-02,\n",
       "         -1.94424093e-01,  3.04414302e-01, -1.84469545e+00,\n",
       "         -2.05109328e-01,  1.34094119e-01],\n",
       "        [-1.76980913e-01,  5.91670096e-01,  7.78255705e-03,\n",
       "         -2.41335481e-01,  2.27991268e-01,  1.10087665e-02,\n",
       "          3.16116691e-01, -9.58960354e-02, -2.79958010e-01,\n",
       "          4.05458212e-02, -2.74085701e-01,  3.97650003e-02,\n",
       "          2.33997017e-01, -6.98381245e-01, -8.86297524e-01,\n",
       "          4.93595183e-01,  2.51355022e-01, -2.69588381e-01,\n",
       "          1.73040122e-01, -4.46916908e-01],\n",
       "        [-4.07403708e-01,  2.06814170e-01,  2.95379251e-01,\n",
       "         -1.86664596e-01,  1.75483644e-01, -2.97633469e-01,\n",
       "          2.72109866e-01, -1.79502174e-01,  4.68196869e-01,\n",
       "         -2.01186255e-01, -3.84199917e-01, -1.45314485e-01,\n",
       "          5.49861610e-01, -4.25448865e-01, -2.78244227e-01,\n",
       "         -2.41116121e-01,  4.62410420e-01,  3.27081501e-01,\n",
       "          8.72116610e-02,  8.80711898e-02],\n",
       "        [ 1.00995466e-01,  4.06948328e-01, -4.38819349e-01,\n",
       "          1.51595857e-03,  9.24933478e-02, -4.35386300e-01,\n",
       "         -8.76346789e-03, -1.98743612e-01,  2.67734140e-01,\n",
       "          2.57109791e-01, -9.86955762e-02, -1.25203043e-01,\n",
       "         -2.66657740e-01,  2.55030453e-01, -2.13843718e-01,\n",
       "         -1.93203047e-01, -2.01368611e-02, -4.60681289e-01,\n",
       "         -7.57445157e-01, -5.74967377e-02],\n",
       "        [ 3.54820490e-01, -5.36447704e-01, -1.45757779e-01,\n",
       "         -1.04976296e-01,  2.99624562e-01,  3.97159189e-01,\n",
       "          8.63489956e-02,  2.77361512e-01, -3.58320437e-02,\n",
       "         -2.17492983e-01, -2.40190804e-01,  2.65808970e-01,\n",
       "          5.96741676e-01, -1.80600643e-01, -4.81136739e-01,\n",
       "          1.52607262e-01,  2.55604088e-01,  3.56116116e-01,\n",
       "         -9.94091183e-02,  5.38398981e-01],\n",
       "        [-2.22984537e-01, -3.05587679e-01,  1.30215511e-02,\n",
       "          1.44798324e-01, -5.82508966e-02, -8.15474093e-02,\n",
       "          7.12702394e-01, -1.45565972e-01, -5.24533749e-01,\n",
       "         -3.79875004e-01,  1.79274470e-01,  4.96574268e-02,\n",
       "          1.89667776e-01,  5.08758053e-02,  3.86993855e-01,\n",
       "          2.76789844e-01, -4.13358480e-01,  6.50717169e-02,\n",
       "         -5.39896548e-01, -1.80221155e-01],\n",
       "        [-1.46643877e-01,  3.01465034e-01, -7.52939954e-02,\n",
       "         -1.41452461e-01,  4.47956145e-01,  5.67406714e-01,\n",
       "          1.10558709e-02,  4.31844294e-02, -2.53551286e-02,\n",
       "         -2.26665303e-01, -1.62258431e-01, -2.47220844e-01,\n",
       "          3.01885605e-01,  4.24125284e-01,  1.89271361e-01,\n",
       "          3.55503589e-01, -4.17985693e-02,  1.25881821e-01,\n",
       "          6.85161874e-02, -1.73734516e-01],\n",
       "        [ 5.44888526e-02, -2.41208114e-02, -1.16080754e-01,\n",
       "         -4.50467139e-01,  1.87819690e-01, -1.31566012e-02,\n",
       "         -1.72401577e-01, -2.45671555e-01, -1.55225232e-01,\n",
       "          1.23649836e-03, -3.03809106e-01,  3.83161306e-02,\n",
       "          1.92781750e-04, -4.43973452e-01,  1.63151920e-01,\n",
       "         -2.83940554e-01,  7.67428160e-01, -1.44996598e-01,\n",
       "         -2.01156020e-01, -2.71064609e-01],\n",
       "        [ 4.14156169e-01, -1.34447619e-01,  4.48349416e-01,\n",
       "         -2.73047388e-01,  4.21217412e-01,  2.25145206e-01,\n",
       "          5.76652437e-02, -3.20768178e-01,  2.40042489e-02,\n",
       "         -2.41740882e-01, -1.02896087e-01, -2.39059299e-01,\n",
       "          4.50900346e-01, -1.78401306e-01,  5.78431152e-02,\n",
       "          3.64096045e-01, -1.89407840e-01, -5.85045636e-01,\n",
       "         -1.29808009e-01,  1.84984542e-02],\n",
       "        [-1.58653766e-01, -7.95305669e-02, -1.41654387e-01,\n",
       "          1.19180076e-01,  2.02503964e-01, -1.53356344e-01,\n",
       "         -7.84719661e-02, -2.47947812e-01, -3.43773186e-01,\n",
       "         -1.66004315e-01, -2.91904658e-01, -3.54588121e-01,\n",
       "          4.98924643e-01, -1.81169152e-01,  3.21319640e-01,\n",
       "         -6.40024096e-02,  1.96915179e-01, -8.75436589e-02,\n",
       "          3.14858198e-01, -1.19335167e-01],\n",
       "        [-3.29609334e-01, -3.88162196e-01, -4.59249765e-01,\n",
       "          6.76081106e-02,  4.65309650e-01,  6.31438494e-01,\n",
       "         -6.39981866e-01, -2.73129702e-01,  1.27747938e-01,\n",
       "         -2.87398756e-01, -6.23842068e-02, -3.79575789e-01,\n",
       "          6.25235677e-01, -2.43437380e-01, -2.30454221e-01,\n",
       "         -1.54380083e-01,  4.80878502e-01,  9.66148078e-02,\n",
       "          7.82980099e-02, -4.89782169e-02],\n",
       "        [ 4.37232405e-01,  4.72361982e-01,  4.06017601e-01,\n",
       "          4.87041473e-01, -1.39285818e-01, -3.60562503e-01,\n",
       "         -5.43718815e-01, -3.71889442e-01,  4.48267251e-01,\n",
       "         -5.36937863e-02,  4.60800678e-02, -3.70565057e-01,\n",
       "         -3.53337497e-01,  2.87061602e-01,  2.23253489e-01,\n",
       "          5.06376803e-01, -9.94953066e-02,  3.37453723e-01,\n",
       "          1.05016851e+00,  9.70251784e-02],\n",
       "        [-1.88749865e-01,  2.54231811e-01, -3.58439207e-01,\n",
       "          3.55258822e-01,  2.12539942e-03, -1.37531264e-02,\n",
       "         -2.79138803e-01,  2.73686767e-01,  2.25276709e-01,\n",
       "         -3.60212892e-01, -2.20637962e-01, -1.31261617e-01,\n",
       "         -3.19596767e-01,  2.16444358e-01, -2.05074251e-02,\n",
       "         -3.33949119e-01, -2.32842252e-01, -1.21671259e-01,\n",
       "         -1.50029182e-01,  6.73818439e-02],\n",
       "        [ 4.95250404e-01,  1.86029732e-01,  2.82255530e-01,\n",
       "          2.05952004e-01,  1.81231782e-01,  2.39361659e-01,\n",
       "         -4.02713656e-01, -1.52368501e-01,  3.00368845e-01,\n",
       "         -2.21105162e-02,  1.00912824e-02, -2.50579476e-01,\n",
       "          3.41650732e-02,  9.29236561e-02, -1.47564150e-03,\n",
       "          1.07948728e-01, -2.30096236e-01,  1.55246332e-01,\n",
       "         -1.35574722e+00,  5.20856559e-01],\n",
       "        [-2.64268816e-02,  2.04900771e-01,  1.64287731e-01,\n",
       "         -2.80859947e-01,  7.91008845e-02,  3.67359430e-01,\n",
       "         -1.05360067e+00, -2.26622820e-01, -1.26665547e-01,\n",
       "         -2.01935872e-01,  3.16350728e-01,  2.48287916e-02,\n",
       "          1.82778895e-01,  4.67933230e-02, -3.48067641e-01,\n",
       "         -3.47153544e-01,  3.61578882e-01, -1.08898334e-01,\n",
       "         -3.06644738e-01,  7.28654908e-04],\n",
       "        [ 5.07167913e-03, -6.21816754e-01, -1.17628872e-01,\n",
       "          8.97525027e-02, -1.35607183e-01,  3.68744761e-01,\n",
       "         -1.98990002e-01,  3.05503130e-01,  8.32379144e-03,\n",
       "         -2.91820854e-01,  3.21351856e-01, -1.57614931e-01,\n",
       "         -4.19385225e-01,  2.33621076e-01, -2.03018501e-01,\n",
       "          2.00801417e-01,  4.48560148e-01,  4.97790307e-01,\n",
       "          6.74765587e-01, -5.66839635e-01],\n",
       "        [-3.58005285e-01, -7.41738498e-01, -2.56885916e-01,\n",
       "         -1.01343405e+00, -4.63547915e-01, -1.42425418e-01,\n",
       "          1.64482728e-01, -2.47198939e-01,  4.51508790e-01,\n",
       "         -1.30430758e-01, -4.31419283e-01,  6.21577762e-02,\n",
       "         -4.48661089e-01,  6.97089255e-01,  5.18181145e-01,\n",
       "         -1.74023092e-01, -7.26232409e-01,  4.72236484e-01,\n",
       "          5.63701630e-01,  5.91577411e-01]], dtype=float32),\n",
       " array([ 0.02603154, -0.3001035 ,  0.02598769, -0.12150355,  0.07449601,\n",
       "         0.16727225,  0.12946053,  0.        , -0.08987135, -0.00216144,\n",
       "        -0.07603785, -0.04265089,  0.05079197,  0.20414406,  0.08733946,\n",
       "         0.15600383, -0.0090415 ,  0.02278792, -0.29626283,  0.09172287],\n",
       "       dtype=float32),\n",
       " array([[-0.38026014],\n",
       "        [-0.29085004],\n",
       "        [-0.40997356],\n",
       "        [-0.28119412],\n",
       "        [ 0.19436522],\n",
       "        [ 0.41836482],\n",
       "        [-0.14186591],\n",
       "        [ 0.11962318],\n",
       "        [-0.20910694],\n",
       "        [ 0.39005864],\n",
       "        [ 0.05219225],\n",
       "        [ 0.45067358],\n",
       "        [ 0.31497994],\n",
       "        [ 0.25815657],\n",
       "        [ 0.07508345],\n",
       "        [-0.30125433],\n",
       "        [ 0.26978537],\n",
       "        [-0.25554946],\n",
       "        [-0.34834328],\n",
       "        [-0.3240059 ]], dtype=float32),\n",
       " array([0.07935091], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
