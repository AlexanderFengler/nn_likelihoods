{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import dnnregressor_predictor as dnn_pred\n",
    "import dnnregressor_model_and_input_fn as dnn_model_input\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pd.read_csv('/Users/admin/OneDrive/git_repos/nn_likelihoods/tensorflow_models/dnnregressor_mse_choice_probabilities_analytic_08_15_18_19_48_36/dnn_training_results_mse_choice_probabilities_analytic_08_15_18_19_48_36.csv',\n",
    "                          converters = {'hidden_units':eval,\n",
    "                                        'activations':eval})\n",
    "\n",
    "model_params = hyper_params.to_dict(orient = 'list')\n",
    "for key in model_params.keys():\n",
    "    model_params[key] = model_params[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint 0 generated\n",
      "datapoint 1000 generated\n",
      "datapoint 2000 generated\n",
      "datapoint 3000 generated\n",
      "datapoint 4000 generated\n",
      "datapoint 5000 generated\n",
      "datapoint 6000 generated\n",
      "datapoint 7000 generated\n",
      "datapoint 8000 generated\n",
      "datapoint 9000 generated\n"
     ]
    }
   ],
   "source": [
    "# Generate a dataset (choice_probabilities)\n",
    "dataset,_, __ = mdw.make_data_choice_probabilities(v_range = [-3, 3], # uniform [0.6, 0.6]\n",
    "                              a_range = [1.2, 1.2], # unifor\n",
    "                              w_range = [0.5, 0.5],  # uniform\n",
    "                              n_samples = 10000,\n",
    "                              write_to_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset feedable to tensorflow (wfpt)\n",
    "features, labels, __, ___ = mdw.train_test_split_choice_probabilities(data = dataset,\n",
    "                                                                      p_train = 1,\n",
    "                                                                      write_to_file = False,\n",
    "                                                                      from_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make feature columns (wfpt)\n",
    "feature_columns = dnn_model_input.make_feature_columns_numeric(features = features)\n",
    "model_params['feature_columns'] = feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstantiate model\n",
    "my_predictor = dnn_pred.get_dnnreg_predictor(model_directory = '/Users/admin/OneDrive/git_repos/nn_likelihoods/tensorflow_models/dnnregressor_mse_choice_probabilities_analytic_08_15_18_19_48_36/',\n",
    "                                             params = model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions (wfpt)\n",
    "my_checkpoint = 'model.ckpt-20000'\n",
    "my_predictions = dnn_pred.get_predictions(regressor = my_predictor,\n",
    "                                         features = features\n",
    "                                         checkpoint = \"/Users/admin/OneDrive/git_repos/nn_likelihoods/tensorflow_models/dnnregressor_mse_choice_probabilities_analytic_08_15_18_19_48_36/\" + my_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate predictions with dataset\n",
    "new_col = pd.DataFrame(my_predictions, columns = ['p_lower_barrier_predict'])\n",
    "data_pred = pd.concat([dataset, new_col], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plotting\n",
    "import seaborn as sns\n",
    "\n",
    "data_pred.sort_values('v', axis=0, ascending=True, inplace=True, kind='quicksort', na_position='last')\n",
    "data_pred_long = data_pred.melt(id_vars = ['v'], value_vars = ['p_lower_barrier', \n",
    "                                              'p_lower_barrier_predict'], \n",
    "                                               var_name = 'group', \n",
    "                                               value_name = 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = sns.lineplot(x = \"v\", \n",
    "                  y = \"p\", \n",
    "                  data = data_pred_long, \n",
    "                  hue = 'group',\n",
    "                  alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_dict(orient = 'list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
