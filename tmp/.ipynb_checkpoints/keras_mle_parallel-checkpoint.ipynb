{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'make_data_wfpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35010e42559d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Load my own functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#import dnnregressor_train_eval_keras as dnnk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmake_data_wfpt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkde_training_utilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkde_load_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mddm_data_simulation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mddm_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'make_data_wfpt'"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "import make_data_wfpt as mdw\n",
    "from kde_training_utilities import kde_load_data\n",
    "import ddm_data_simulation as ddm_sim\n",
    "from cddm_data_simulation import ddm_simulate\n",
    "import boundary_functions as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12327944884587819902\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10388041888953930546\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Handle some cuda business\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tony/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tony/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/tony/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_path = '/media/data_cifs/afengler/data/kde/ddm/keras_models/dnnregressor_ddm_06_28_19_00_58_26/model_0' \n",
    "ckpt_path = '/media/data_cifs/afengler/data/kde/ddm/keras_models/dnnregressor_ddm_06_28_19_00_58_26/ckpt_0_final''\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "model.load_weights(ckpt_path)\n",
    "\n",
    "# model_path = \"/home/tony/repos/temp_models/keras_models/dnnregressor_ddm_06_28_19_00_58_26/model_0\"\n",
    "# ckpt_path = \"/home/tony/repos/temp_models/keras_models/dnnregressor_ddm_06_28_19_00_58_26/ckpt_0_final\"\n",
    "\n",
    "# model = keras.models.load_model(model_path)\n",
    "# model.load_weights(ckpt_path)\n",
    "\n",
    "# network_path = \"/home/tony/repos/temp_models/keras_models/\\\n",
    "# dnnregressoranalytical_ddm_07_25_19_15_50_52/model.h5\"\n",
    "\n",
    "model = keras.models.load_model(network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2316325]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[0, 1, .5, 1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations -----\n",
    "n_runs = 100\n",
    "n_samples = 2500\n",
    "feature_file_path = '/media/data_cifs/afengler/data/kde/linear_collapse/train_test_data/test_features.pickle'\n",
    "mle_out_path = '/media/data_cifs/afengler/data/kde/linear_collapse/mle_runs'\n",
    "\n",
    "# NOTE PARAMETERS: \n",
    "# WEIBULL: [v, a, w, node, shape, scale]\n",
    "param_bounds = [(-1, 1), (0.3, 2), (0.3, 0.7), (0.01, 0.01), (0, np.pi / 2.2)]\n",
    "\n",
    "\n",
    "my_optim_columns = ['v_sim', 'a_sim', 'w_sim', 'node_sim', 'theta_sim',\n",
    "                    'v_mle', 'a_mle', 'w_mle', 'node_mle', 'theta_mle', 'n_samples']\n",
    "\n",
    "# Get parameter names in correct ordering:\n",
    "dat = pickle.load(open(feature_file_path, \n",
    "                       'rb'))\n",
    "\n",
    "parameter_names = list(dat.keys())[:-2] # :-1 to get rid of 'rt' and 'choice' here\n",
    "\n",
    "# Make columns for optimizer result table\n",
    "p_sim = []\n",
    "p_mle = []\n",
    "\n",
    "for parameter_name in parameter_names:\n",
    "    p_sim.append(parameter_name + '_sim')\n",
    "    p_mle.append(parameter_name + '_mle')\n",
    "    \n",
    "my_optim_columns = p_sim + p_mle + ['n_samples']\n",
    "\n",
    "# Initialize the data frame in which to store optimizer results\n",
    "optim_results = pd.DataFrame(np.zeros((n_runs, len(my_optim_columns))), columns = my_optim_columns)\n",
    "optim_results.iloc[:, 2 * len(parameter_names)] = n_samples\n",
    "\n",
    "# define boundary\n",
    "boundary = bf.linear_collapse\n",
    "boundary_multiplicative = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(model):\n",
    "    biases = []\n",
    "    activations = []\n",
    "    weights = []\n",
    "    for layer in model.layers:\n",
    "        if layer.name == \"input_1\":\n",
    "            continue\n",
    "        weights.append(layer.get_weights()[0])\n",
    "        biases.append(layer.get_weights()[1])\n",
    "        activations.append(layer.get_config()[\"activation\"])\n",
    "    return weights, biases, activations\n",
    "\n",
    "weights, biases, activations = extract_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.76513734]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "activation_fns = {\"relu\":relu, \"linear\":linear}\n",
    "\n",
    "def np_predict(x, weights, biases, activations):\n",
    "    for i in range(len(weights)):\n",
    "        x = activation_fns[activations[i]](\n",
    "            np.dot(x, weights[i]) + biases[i]\n",
    "        )\n",
    "    return x\n",
    "        \n",
    "np_predict(np.array([[0, 1, .5, 1, 1]]), weights, biases, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_p(params):\n",
    "    param_grid = np.tile(params, (data.shape[0], 1))\n",
    "    inp = np.concatenate([param_grid, data], axis = 1)\n",
    "    \n",
    "    out = np_predict(inp, weights, biases, activations)\n",
    "    \n",
    "    return -np.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the likelihood function\n",
    "def log_p(params = [0, 1, 0.9], model = [], data = [], parameter_names = []):\n",
    "    # Make feature array\n",
    "    feature_array = np.zeros((data[0].shape[0], len(parameter_names) + 2))\n",
    "    \n",
    "    # Store parameters\n",
    "    cnt = 0\n",
    "    for i in range(0, len(parameter_names), 1):\n",
    "        feature_array[:, i] = params[i]\n",
    "        cnt += 1\n",
    "    \n",
    "    # Store rts and choices\n",
    "    feature_array[:, cnt] = data[0].ravel() # rts\n",
    "    feature_array[:, cnt + 1] = data[1].ravel() # choices\n",
    "    \n",
    "    # Get model predictions\n",
    "    prediction = model.predict(feature_array)\n",
    "    \n",
    "    # Some post-processing of predictions\n",
    "    prediction[prediction < 1e-29] = 1e-29\n",
    "    \n",
    "    return(- np.sum(np.log(prediction)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_params(param_bounds = []):\n",
    "    params = np.zeros(len(param_bounds))\n",
    "    \n",
    "    for i in range(len(params)):\n",
    "        params[i] = np.random.uniform(low = param_bounds[i][0], high = param_bounds[i][1])\n",
    "        \n",
    "    return params\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.uniform(-1, 1)\n",
    "a = np.random.uniform(.5, 2)\n",
    "w = np.random.uniform()\n",
    "true_params = np.array([v, a, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts, choices, _ = ddm_simulate(v = true_params[0], a = true_params[1], \n",
    "                               w = true_params[2], n_samples = 2000)\n",
    "data = np.concatenate([rts, choices], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_params = [(-1, 1), (.5, 2), (0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 2150.11\n",
      "differential_evolution step 2: f(x)= 2133.01\n",
      "differential_evolution step 3: f(x)= 2133.01\n",
      "differential_evolution step 4: f(x)= 2133.01\n",
      "differential_evolution step 5: f(x)= 2131.04\n",
      "differential_evolution step 6: f(x)= 2124.09\n",
      "differential_evolution step 7: f(x)= 2123.94\n",
      "differential_evolution step 8: f(x)= 2122.16\n",
      "differential_evolution step 9: f(x)= 2121.65\n",
      "differential_evolution step 10: f(x)= 2121.65\n",
      "differential_evolution step 11: f(x)= 2121.65\n",
      "differential_evolution step 12: f(x)= 2121.65\n",
      "differential_evolution step 13: f(x)= 2121.37\n"
     ]
    }
   ],
   "source": [
    "out = differential_evolution(log_p, bounds = boundary_params,\n",
    "                             popsize = 60,\n",
    "                             disp = True, workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.96953528,  1.83671555,  0.67024903])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.92762071,  1.819984  ,  0.68183247])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1957.9302720365918"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = np.tile(true_params, (data.shape[0], 1))\n",
    "inp = np.concatenate([param_grid, data], axis=1)\n",
    "\n",
    "prediction = np_predict(inp, weights, biases, activations)\n",
    "prediction.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   3.,  11.,  20., 159., 385., 361., 141., 549., 368.]),\n",
       " array([-6.05935674, -5.3644443 , -4.66953187, -3.97461944, -3.279707  ,\n",
       "        -2.58479457, -1.88988213, -1.1949697 , -0.50005726,  0.19485517,\n",
       "         0.8897676 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop ----------- TD: Parallelize\n",
    "for i in range(0, n_runs, 1): \n",
    "    \n",
    "    # Get start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "#     # Sample parameters\n",
    "#     v_sim = np.random.uniform(high = v_range[1], low = v_range[0])\n",
    "#     a_sim = np.random.uniform(high = a_range[1], low = a_range[0])\n",
    "#     w_sim = np.random.uniform(high = w_range[1], low = w_range[0])\n",
    "\n",
    "#     #c1_sim = np.random.uniform(high = c1_range[1], low = c1_range[0])\n",
    "#     #c2_sim = np.random.uniform(high = c2_range[1], low = c2_range[0])\n",
    "#     node_sim = np.random.uniform(high = node_range[1], low = node_range[0])\n",
    "#     shape_sim = np.random.uniform(high = shape_range[1], low = shape_range[0])\n",
    "#     scale_sim = np.random.uniform(high = scale_range[1], low = scale_range[0])\n",
    "\n",
    "    tmp_params = make_params(param_bounds = param_bounds)\n",
    "    \n",
    "    # Store in output file\n",
    "    optim_results.iloc[i, :len(parameter_names)] = tmp_params\n",
    "    \n",
    "    # Print some info on run\n",
    "    print('Parameters for run ' + str(i) + ': ')\n",
    "    print(tmp_params)\n",
    "    \n",
    "    # Define boundary params\n",
    "    boundary_params = {'node': tmp_params[3],\n",
    "                       'theta': tmp_params[4]}\n",
    "    \n",
    "    # Run model simulations\n",
    "    ddm_dat_tmp = ddm_sim.ddm_flexbound_simulate(v = tmp_params[0],\n",
    "                                                 a = tmp_params[1],\n",
    "                                                 w = tmp_params[2],\n",
    "                                                 s = 1,\n",
    "                                                 delta_t = 0.001,\n",
    "                                                 max_t = 20,\n",
    "                                                 n_samples = n_samples,\n",
    "                                                 boundary_fun = boundary, # function of t (and potentially other parameters) that takes in (t, *args)\n",
    "                                                 boundary_multiplicative = boundary_multiplicative, # CAREFUL: CHECK IF BOUND\n",
    "                                                 boundary_params = boundary_params)\n",
    "        \n",
    "    # Print some info on run\n",
    "    print('Mean rt for current run: ')\n",
    "    print(np.mean(ddm_dat_tmp[0]))\n",
    "    \n",
    "    # Run optimizer\n",
    "    out = differential_evolution(log_p, \n",
    "                                 bounds = param_bounds, \n",
    "                                 args = (model, ddm_dat_tmp, parameter_names), \n",
    "                                 popsize = 30,\n",
    "                                 disp = True)\n",
    "    \n",
    "    # Print some info\n",
    "    print('Solution vector of current run: ')\n",
    "    print(out.x)\n",
    "    \n",
    "    print('The run took: ')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    # Store result in output file\n",
    "    optim_results.iloc[i, len(parameter_names):(2*len(parameter_names))] = out.x\n",
    "# -----------------------\n",
    "\n",
    "# Save optimization results to file\n",
    "optim_results.to_csv(mle_out_path + '/mle_results_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in results\n",
    "optim_results = pd.read_csv(os.getcwd() + '/experiments/ddm_flexbound_kde_mle_fix_v_0_c1_0_w_unbiased_arange_2_3/optim_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['v_sim'], optim_results['v_mle'], c = optim_results['c2_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for v\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['v_mle'], 1), np.expand_dims(optim_results['v_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['v_mle'], 1), np.expand_dims(optim_results['v_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['a_sim'], optim_results['a_mle'], c = optim_results['c2_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for a\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['a_mle'], 1), np.expand_dims(optim_results['a_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['a_mle'], 1), np.expand_dims(optim_results['a_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['w_sim'], optim_results['w_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for w\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['w_mle'], 1), np.expand_dims(optim_results['w_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['w_mle'], 1), np.expand_dims(optim_results['w_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['c1_sim'], optim_results['c1_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for c1\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['c1_mle'], 1), np.expand_dims(optim_results['c1_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['c1_mle'], 1), np.expand_dims(optim_results['c1_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['c2_sim'], optim_results['c2_mle'], c = optim_results['a_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for w\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['c2_mle'], 1), np.expand_dims(optim_results['c2_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['c2_mle'], 1), np.expand_dims(optim_results['c2_sim'], 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
