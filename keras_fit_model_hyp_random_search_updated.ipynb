{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "from datetime import datetime\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(os.getcwd() + '/data_storage/data_11000000_from_simulation_mix_09_12_18_18_20_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some cleaning of the data\n",
    "data = data[['v', 'a', 'w', 'rt', 'choice', 'nf_likelihood']]\n",
    "data = data.loc[data['w'] > 0.1]\n",
    "data = data.loc[data['w'] < 0.9]\n",
    "data = data.loc[data['a'] > 0.5]\n",
    "\n",
    "mini_data = data.loc[1:10000]\n",
    "\n",
    "\n",
    "train_f, train_l, test_f, test_l = mdw.train_test_split_rt_choice(data = data,\n",
    "                                                                  write_to_file = False,\n",
    "                                                                  from_file = False,\n",
    "                                                                  p_train = 0.8,\n",
    "                                                                  backend = 'keras')\n",
    "# Choice probabilities\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_choice_probabilities(n_samples = 2500000,\n",
    "#                                                             f_signature = '_choice_probabilities_analytic_',\n",
    "#                                                                                 backend = 'keras')\n",
    "\n",
    "# rt_choice\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_rt_choice(n_samples = 11000000,\n",
    "#                                                                       f_signature = '_from_simulation_mix_',\n",
    "#                                                                       backend = 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "cpm.data['train_features'] = train_f\n",
    "cpm.data['train_labels'] = train_l\n",
    "cpm.data['test_features'] = test_f\n",
    "cpm.data['test_labels'] = test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 3,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'sigmoid',\n",
       " 'hidden_layers': [20, 20, 20, 20],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 2000,\n",
       " 'batch_size': 10000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'choice_probabilities',\n",
       " 'model_directory': '/home/afengler/git_repos/nn_likelihoods/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_choice_probabilities_analytic_',\n",
       " 'timestamp': '09_19_18_23_17_39',\n",
       " 'training_data_size': 2500000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFYING META PARAMETERS THAT STAY CONSTANT DURING HYPERPARAMETER OPTIMIZATION\n",
    "\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['input_shape'] = 5\n",
    "\n",
    "# Training params\n",
    "# Meta\n",
    "cpm.train_params['early_stopping_patience'] = 5\n",
    "cpm.train_params['plateau_patience'] = 3\n",
    "cpm.train_params['min_delta'] = 0.002\n",
    "cpm.train_params['ckpt_period'] = 1\n",
    "cpm.train_params['model_cnt'] = 0\n",
    "cpm.train_params['max_train_epochs'] = 50\n",
    "\n",
    "# Hyper\n",
    "#cpm.train_params['l1_kernel']\n",
    "cpm.model_params['hidden_layers'] = [5, 5, 5, 5]\n",
    "#cpm.train_params['hidden_activations']\n",
    "#cpm.train_params['l2_kernel'] = [0.5, 0.5, 0.5, 0.5]\n",
    "#cpm.train_params['l2_activation'] = [0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'wfpt'\n",
    "cpm.data_params['data_type_signature'] = '_choice_rt_'\n",
    "cpm.data_params['training_data_size'] = 11000000\n",
    "\n",
    "# Update timestamp\n",
    "cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "# cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# cpm.run_training(save_history = True, \n",
    "#                  warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 236s 39us/step - loss: 2.4588 - mean_squared_error: 2.4588 - val_loss: 0.9254 - val_mean_squared_error: 0.9254\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92544, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 1.1166 - mean_squared_error: 1.1166 - val_loss: 3.0979 - val_mean_squared_error: 3.0979\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.92544\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.7893 - mean_squared_error: 0.7893 - val_loss: 0.4891 - val_mean_squared_error: 0.4891\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.92544 to 0.48911, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.6712 - mean_squared_error: 0.6712 - val_loss: 1.2850 - val_mean_squared_error: 1.2850\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48911\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.5632 - mean_squared_error: 0.5632 - val_loss: 0.4717 - val_mean_squared_error: 0.4717\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48911 to 0.47173, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.4961 - mean_squared_error: 0.4961 - val_loss: 0.2839 - val_mean_squared_error: 0.2839\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47173 to 0.28391, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_06\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.4655 - mean_squared_error: 0.4655 - val_loss: 0.3038 - val_mean_squared_error: 0.3038\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28391\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.4354 - mean_squared_error: 0.4354 - val_loss: 0.1837 - val_mean_squared_error: 0.1837\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28391 to 0.18368, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.4385 - mean_squared_error: 0.4385 - val_loss: 0.2680 - val_mean_squared_error: 0.2680\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18368\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.4414 - mean_squared_error: 0.4414 - val_loss: 0.5244 - val_mean_squared_error: 0.5244\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18368\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.4252 - mean_squared_error: 0.4252 - val_loss: 0.2560 - val_mean_squared_error: 0.2560\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18368\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.3921 - mean_squared_error: 0.3921 - val_loss: 0.1785 - val_mean_squared_error: 0.1785\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18368 to 0.17848, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3821 - mean_squared_error: 0.3821 - val_loss: 0.3646 - val_mean_squared_error: 0.3646\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17848\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.3647 - mean_squared_error: 0.3647 - val_loss: 0.2427 - val_mean_squared_error: 0.2427\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17848\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.3398 - mean_squared_error: 0.3398 - val_loss: 0.1749 - val_mean_squared_error: 0.1749\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17848 to 0.17486, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_15\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3407 - mean_squared_error: 0.3407 - val_loss: 0.1884 - val_mean_squared_error: 0.1884\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17486\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 0.3100 - mean_squared_error: 0.3100 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17486\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.3011 - mean_squared_error: 0.3011 - val_loss: 0.2032 - val_mean_squared_error: 0.2032\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17486\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.3119 - mean_squared_error: 0.3119 - val_loss: 0.3234 - val_mean_squared_error: 0.3234\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17486\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.2863 - mean_squared_error: 0.2863 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.17486 to 0.16041, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_20\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2835 - mean_squared_error: 0.2835 - val_loss: 0.1777 - val_mean_squared_error: 0.1777\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16041\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2748 - mean_squared_error: 0.2748 - val_loss: 0.1745 - val_mean_squared_error: 0.1745\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16041\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.2754 - mean_squared_error: 0.2754 - val_loss: 0.2016 - val_mean_squared_error: 0.2016\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16041\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2747 - mean_squared_error: 0.2747 - val_loss: 0.2862 - val_mean_squared_error: 0.2862\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16041\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2707 - mean_squared_error: 0.2707 - val_loss: 0.5555 - val_mean_squared_error: 0.5555\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16041\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2637 - mean_squared_error: 0.2637 - val_loss: 0.1765 - val_mean_squared_error: 0.1765\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16041\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2621 - mean_squared_error: 0.2621 - val_loss: 0.2066 - val_mean_squared_error: 0.2066\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16041\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.2613 - mean_squared_error: 0.2613 - val_loss: 0.3006 - val_mean_squared_error: 0.3006\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16041\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2620 - mean_squared_error: 0.2620 - val_loss: 0.2742 - val_mean_squared_error: 0.2742\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16041\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.2503 - mean_squared_error: 0.2503 - val_loss: 0.1595 - val_mean_squared_error: 0.1595\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16041 to 0.15950, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.2574 - mean_squared_error: 0.2574 - val_loss: 0.1330 - val_mean_squared_error: 0.1330\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15950 to 0.13296, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_31\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.2511 - mean_squared_error: 0.2511 - val_loss: 0.2073 - val_mean_squared_error: 0.2073\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.13296\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2404 - mean_squared_error: 0.2404 - val_loss: 0.1164 - val_mean_squared_error: 0.1164\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.13296 to 0.11641, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_33\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2518 - mean_squared_error: 0.2518 - val_loss: 0.1480 - val_mean_squared_error: 0.1480\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11641\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.2393 - mean_squared_error: 0.2393 - val_loss: 0.1238 - val_mean_squared_error: 0.1238\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11641\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 282s 47us/step - loss: 0.2593 - mean_squared_error: 0.2593 - val_loss: 0.4802 - val_mean_squared_error: 0.4802\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11641\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.2317 - mean_squared_error: 0.2317 - val_loss: 0.7974 - val_mean_squared_error: 0.7974\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11641\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2652 - mean_squared_error: 0.2652 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11641\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 276s 46us/step - loss: 0.2322 - mean_squared_error: 0.2322 - val_loss: 0.1910 - val_mean_squared_error: 0.1910\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11641\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2338 - mean_squared_error: 0.2338 - val_loss: 0.1436 - val_mean_squared_error: 0.1436\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11641\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.0874 - mean_squared_error: 0.0874 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.11641 to 0.08292, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.0824 - mean_squared_error: 0.0824 - val_loss: 0.0788 - val_mean_squared_error: 0.0788\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08292 to 0.07885, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.0804 - mean_squared_error: 0.0804 - val_loss: 0.0862 - val_mean_squared_error: 0.0862\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07885\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0785 - mean_squared_error: 0.0785 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07885\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.0779 - mean_squared_error: 0.0779 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07885 to 0.07658, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0764 - mean_squared_error: 0.0764 - val_loss: 0.0709 - val_mean_squared_error: 0.0709\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.07658 to 0.07090, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_0_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.0750 - mean_squared_error: 0.0750 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07090\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.0746 - mean_squared_error: 0.0746 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07090\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.0735 - mean_squared_error: 0.0735 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07090\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.0728 - mean_squared_error: 0.0728 - val_loss: 0.0774 - val_mean_squared_error: 0.0774\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07090\n",
      "1\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 2.0938 - mean_squared_error: 2.0938 - val_loss: 1.3407 - val_mean_squared_error: 1.3407\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34071, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.9763 - mean_squared_error: 0.9763 - val_loss: 0.4012 - val_mean_squared_error: 0.4012\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34071 to 0.40115, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.8088 - mean_squared_error: 0.8088 - val_loss: 0.4080 - val_mean_squared_error: 0.4080\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.40115\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.7126 - mean_squared_error: 0.7126 - val_loss: 0.7245 - val_mean_squared_error: 0.7245\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40115\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.6122 - mean_squared_error: 0.6122 - val_loss: 0.2908 - val_mean_squared_error: 0.2908\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40115 to 0.29078, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.5767 - mean_squared_error: 0.5767 - val_loss: 1.6661 - val_mean_squared_error: 1.6661\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29078\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.5200 - mean_squared_error: 0.5200 - val_loss: 0.6219 - val_mean_squared_error: 0.6219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29078\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.5072 - mean_squared_error: 0.5072 - val_loss: 1.7539 - val_mean_squared_error: 1.7539\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.29078\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.4731 - mean_squared_error: 0.4731 - val_loss: 0.3900 - val_mean_squared_error: 0.3900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.29078\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.4505 - mean_squared_error: 0.4505 - val_loss: 0.4308 - val_mean_squared_error: 0.4308\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.29078\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.4179 - mean_squared_error: 0.4179 - val_loss: 0.2764 - val_mean_squared_error: 0.2764\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29078 to 0.27635, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.4016 - mean_squared_error: 0.4016 - val_loss: 3.2036 - val_mean_squared_error: 3.2036\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27635\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 0.3826 - mean_squared_error: 0.3826 - val_loss: 1.1409 - val_mean_squared_error: 1.1409\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27635\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3679 - mean_squared_error: 0.3679 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27635 to 0.15711, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.3717 - mean_squared_error: 0.3717 - val_loss: 0.2193 - val_mean_squared_error: 0.2193\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15711\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 276s 46us/step - loss: 0.3565 - mean_squared_error: 0.3565 - val_loss: 0.5556 - val_mean_squared_error: 0.5556\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15711\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.3485 - mean_squared_error: 0.3485 - val_loss: 0.2215 - val_mean_squared_error: 0.2215\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15711\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3467 - mean_squared_error: 0.3467 - val_loss: 0.2707 - val_mean_squared_error: 0.2707\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15711\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.1683 - val_mean_squared_error: 0.1683\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15711\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3357 - mean_squared_error: 0.3357 - val_loss: 0.2563 - val_mean_squared_error: 0.2563\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15711\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3140 - mean_squared_error: 0.3140 - val_loss: 0.6959 - val_mean_squared_error: 0.6959\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15711\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2975 - mean_squared_error: 0.2975 - val_loss: 0.4411 - val_mean_squared_error: 0.4411\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15711\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.2984 - mean_squared_error: 0.2984 - val_loss: 1.8997 - val_mean_squared_error: 1.8997\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15711\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.2734 - mean_squared_error: 0.2734 - val_loss: 0.3531 - val_mean_squared_error: 0.3531\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15711\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2756 - mean_squared_error: 0.2756 - val_loss: 0.1813 - val_mean_squared_error: 0.1813\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15711\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2711 - mean_squared_error: 0.2711 - val_loss: 0.2071 - val_mean_squared_error: 0.2071\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15711\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2646 - mean_squared_error: 0.2646 - val_loss: 0.4427 - val_mean_squared_error: 0.4427\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15711\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.2566 - mean_squared_error: 0.2566 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15711\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2539 - mean_squared_error: 0.2539 - val_loss: 0.2394 - val_mean_squared_error: 0.2394\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15711\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2500 - mean_squared_error: 0.2500 - val_loss: 0.2993 - val_mean_squared_error: 0.2993\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15711\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2504 - mean_squared_error: 0.2504 - val_loss: 0.2531 - val_mean_squared_error: 0.2531\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15711\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2446 - mean_squared_error: 0.2446 - val_loss: 0.4047 - val_mean_squared_error: 0.4047\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15711\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2438 - mean_squared_error: 0.2438 - val_loss: 0.2589 - val_mean_squared_error: 0.2589\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15711\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2397 - mean_squared_error: 0.2397 - val_loss: 0.1812 - val_mean_squared_error: 0.1812\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15711\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 282s 47us/step - loss: 0.2475 - mean_squared_error: 0.2475 - val_loss: 0.1630 - val_mean_squared_error: 0.1630\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15711\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2390 - mean_squared_error: 0.2390 - val_loss: 0.6130 - val_mean_squared_error: 0.6130\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15711\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2345 - mean_squared_error: 0.2345 - val_loss: 0.1330 - val_mean_squared_error: 0.1330\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15711 to 0.13300, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2358 - mean_squared_error: 0.2358 - val_loss: 0.3473 - val_mean_squared_error: 0.3473\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.13300\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 231s 38us/step - loss: 0.2322 - mean_squared_error: 0.2322 - val_loss: 0.1404 - val_mean_squared_error: 0.1404\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.13300\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 201s 33us/step - loss: 0.2282 - mean_squared_error: 0.2282 - val_loss: 0.3897 - val_mean_squared_error: 0.3897\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13300\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 212s 35us/step - loss: 0.2293 - mean_squared_error: 0.2293 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13300 to 0.13072, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 203s 33us/step - loss: 0.2239 - mean_squared_error: 0.2239 - val_loss: 0.1470 - val_mean_squared_error: 0.1470\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13072\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.2198 - mean_squared_error: 0.2198 - val_loss: 0.1234 - val_mean_squared_error: 0.1234\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13072 to 0.12341, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_1_43\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.2209 - mean_squared_error: 0.2209 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12341\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.2206 - mean_squared_error: 0.2206 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12341\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 207s 34us/step - loss: 0.2172 - mean_squared_error: 0.2172 - val_loss: 0.2327 - val_mean_squared_error: 0.2327\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12341\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.2093 - mean_squared_error: 0.2093 - val_loss: 0.2097 - val_mean_squared_error: 0.2097\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.12341\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.2048 - mean_squared_error: 0.2048 - val_loss: 0.1705 - val_mean_squared_error: 0.1705\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.12341\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.2051 - mean_squared_error: 0.2051 - val_loss: 0.2895 - val_mean_squared_error: 0.2895\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12341\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 207s 34us/step - loss: 0.1990 - mean_squared_error: 0.1990 - val_loss: 0.1281 - val_mean_squared_error: 0.1281\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.12341\n",
      "2\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 203s 34us/step - loss: 2.4311 - mean_squared_error: 2.4311 - val_loss: 1.7261 - val_mean_squared_error: 1.7261\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.72614, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 212s 35us/step - loss: 1.0490 - mean_squared_error: 1.0490 - val_loss: 0.5729 - val_mean_squared_error: 0.5729\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.72614 to 0.57291, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.7788 - mean_squared_error: 0.7788 - val_loss: 0.2963 - val_mean_squared_error: 0.2963\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57291 to 0.29631, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 214s 35us/step - loss: 0.6491 - mean_squared_error: 0.6491 - val_loss: 0.2871 - val_mean_squared_error: 0.2871\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29631 to 0.28706, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 206s 34us/step - loss: 0.5848 - mean_squared_error: 0.5848 - val_loss: 0.9001 - val_mean_squared_error: 0.9001\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28706\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.5702 - mean_squared_error: 0.5702 - val_loss: 0.2997 - val_mean_squared_error: 0.2997\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28706\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.5117 - mean_squared_error: 0.5117 - val_loss: 0.3073 - val_mean_squared_error: 0.3073\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28706\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.4855 - mean_squared_error: 0.4855 - val_loss: 0.3814 - val_mean_squared_error: 0.3814\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28706\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.4654 - mean_squared_error: 0.4654 - val_loss: 1.2773 - val_mean_squared_error: 1.2773\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28706\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.4292 - mean_squared_error: 0.4292 - val_loss: 0.2065 - val_mean_squared_error: 0.2065\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.28706 to 0.20652, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_10\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.4059 - mean_squared_error: 0.4059 - val_loss: 0.3628 - val_mean_squared_error: 0.3628\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20652\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 213s 35us/step - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.2404 - val_mean_squared_error: 0.2404\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20652\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.7428 - val_mean_squared_error: 0.7428\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20652\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 216s 36us/step - loss: 0.3573 - mean_squared_error: 0.3573 - val_loss: 0.2559 - val_mean_squared_error: 0.2559\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20652\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.4270 - val_mean_squared_error: 0.4270\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20652\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.3603 - mean_squared_error: 0.3603 - val_loss: 0.3035 - val_mean_squared_error: 0.3035\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20652\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20652\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 216s 36us/step - loss: 0.3575 - mean_squared_error: 0.3575 - val_loss: 1.4548 - val_mean_squared_error: 1.4548\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20652\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.3236 - mean_squared_error: 0.3236 - val_loss: 0.8859 - val_mean_squared_error: 0.8859\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20652\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 213s 35us/step - loss: 0.3014 - mean_squared_error: 0.3014 - val_loss: 0.3052 - val_mean_squared_error: 0.3052\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20652\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 207s 34us/step - loss: 0.2996 - mean_squared_error: 0.2996 - val_loss: 0.1801 - val_mean_squared_error: 0.1801\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20652 to 0.18005, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_21\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.3009 - mean_squared_error: 0.3009 - val_loss: 0.2935 - val_mean_squared_error: 0.2935\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.18005\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 206s 34us/step - loss: 0.2719 - mean_squared_error: 0.2719 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.18005 to 0.12297, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 214s 35us/step - loss: 0.2658 - mean_squared_error: 0.2658 - val_loss: 0.1225 - val_mean_squared_error: 0.1225\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.12297 to 0.12255, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_24\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 207s 34us/step - loss: 0.2515 - mean_squared_error: 0.2515 - val_loss: 0.2149 - val_mean_squared_error: 0.2149\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12255\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.2442 - mean_squared_error: 0.2442 - val_loss: 0.1343 - val_mean_squared_error: 0.1343\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12255\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 209s 34us/step - loss: 0.2487 - mean_squared_error: 0.2487 - val_loss: 0.2740 - val_mean_squared_error: 0.2740\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12255\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.2418 - mean_squared_error: 0.2418 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12255\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.2332 - mean_squared_error: 0.2332 - val_loss: 0.1719 - val_mean_squared_error: 0.1719\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12255\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.2268 - mean_squared_error: 0.2268 - val_loss: 0.3599 - val_mean_squared_error: 0.3599\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12255\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.2167 - mean_squared_error: 0.2167 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12255 to 0.11109, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_31\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.2202 - mean_squared_error: 0.2202 - val_loss: 0.1881 - val_mean_squared_error: 0.1881\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11109\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 211s 35us/step - loss: 0.2229 - mean_squared_error: 0.2229 - val_loss: 1.1462 - val_mean_squared_error: 1.1462\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11109\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 206s 34us/step - loss: 0.2139 - mean_squared_error: 0.2139 - val_loss: 0.1131 - val_mean_squared_error: 0.1131\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11109\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 214s 35us/step - loss: 0.2120 - mean_squared_error: 0.2120 - val_loss: 0.1118 - val_mean_squared_error: 0.1118\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11109\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.2128 - mean_squared_error: 0.2128 - val_loss: 0.2953 - val_mean_squared_error: 0.2953\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11109\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.2076 - mean_squared_error: 0.2076 - val_loss: 0.2385 - val_mean_squared_error: 0.2385\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11109\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.2108 - mean_squared_error: 0.2108 - val_loss: 0.2329 - val_mean_squared_error: 0.2329\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11109\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 206s 34us/step - loss: 0.2039 - mean_squared_error: 0.2039 - val_loss: 0.1194 - val_mean_squared_error: 0.1194\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11109\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 214s 35us/step - loss: 0.1992 - mean_squared_error: 0.1992 - val_loss: 0.1526 - val_mean_squared_error: 0.1526\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11109\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.1990 - mean_squared_error: 0.1990 - val_loss: 0.1591 - val_mean_squared_error: 0.1591\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11109\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.1938 - mean_squared_error: 0.1938 - val_loss: 0.2104 - val_mean_squared_error: 0.2104\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11109\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.1920 - mean_squared_error: 0.1920 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11109\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.1896 - mean_squared_error: 0.1896 - val_loss: 0.1097 - val_mean_squared_error: 0.1097\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.11109 to 0.10965, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_44\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 213s 35us/step - loss: 0.1925 - mean_squared_error: 0.1925 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.10965 to 0.10548, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.1964 - mean_squared_error: 0.1964 - val_loss: 0.2486 - val_mean_squared_error: 0.2486\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10548\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.1805 - mean_squared_error: 0.1805 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.10548 to 0.09016, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_2_47\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.1774 - mean_squared_error: 0.1774 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.09016\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 205s 34us/step - loss: 0.1778 - mean_squared_error: 0.1778 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.09016\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.1821 - mean_squared_error: 0.1821 - val_loss: 0.2291 - val_mean_squared_error: 0.2291\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09016\n",
      "3\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 2.3105 - mean_squared_error: 2.3105 - val_loss: 1.0005 - val_mean_squared_error: 1.0005\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.00051, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 214s 35us/step - loss: 1.0055 - mean_squared_error: 1.0055 - val_loss: 1.0868 - val_mean_squared_error: 1.0868\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.00051\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 203s 34us/step - loss: 0.8115 - mean_squared_error: 0.8115 - val_loss: 0.3952 - val_mean_squared_error: 0.3952\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.00051 to 0.39520, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.7019 - mean_squared_error: 0.7019 - val_loss: 0.5777 - val_mean_squared_error: 0.5777\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39520\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 203s 33us/step - loss: 0.5943 - mean_squared_error: 0.5943 - val_loss: 0.2004 - val_mean_squared_error: 0.2004\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39520 to 0.20043, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.5492 - mean_squared_error: 0.5492 - val_loss: 0.3806 - val_mean_squared_error: 0.3806\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20043\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 203s 34us/step - loss: 0.4986 - mean_squared_error: 0.4986 - val_loss: 1.1496 - val_mean_squared_error: 1.1496\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20043\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.4602 - mean_squared_error: 0.4602 - val_loss: 0.7022 - val_mean_squared_error: 0.7022\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20043\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.4336 - mean_squared_error: 0.4336 - val_loss: 0.2548 - val_mean_squared_error: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20043\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 204s 34us/step - loss: 0.4003 - mean_squared_error: 0.4003 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20043\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.4021 - mean_squared_error: 0.4021 - val_loss: 0.7532 - val_mean_squared_error: 0.7532\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20043\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.3707 - mean_squared_error: 0.3707 - val_loss: 0.1489 - val_mean_squared_error: 0.1489\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20043 to 0.14892, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 210s 35us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.1947 - val_mean_squared_error: 0.1947\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.14892\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 208s 34us/step - loss: 0.3460 - mean_squared_error: 0.3460 - val_loss: 0.1970 - val_mean_squared_error: 0.1970\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14892\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 231s 38us/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.1937 - val_mean_squared_error: 0.1937\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14892\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.3316 - mean_squared_error: 0.3316 - val_loss: 0.4266 - val_mean_squared_error: 0.4266\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.14892\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 288s 48us/step - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.1534 - val_mean_squared_error: 0.1534\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.14892\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.3150 - mean_squared_error: 0.3150 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.14892\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.3078 - mean_squared_error: 0.3078 - val_loss: 0.2001 - val_mean_squared_error: 0.2001\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14892\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.2941 - mean_squared_error: 0.2941 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.14892\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14892\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2833 - mean_squared_error: 0.2833 - val_loss: 0.3887 - val_mean_squared_error: 0.3887\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14892\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.2843 - mean_squared_error: 0.2843 - val_loss: 0.1490 - val_mean_squared_error: 0.1490\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14892\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2768 - mean_squared_error: 0.2768 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14892 to 0.11669, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_24\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2705 - mean_squared_error: 0.2705 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11669\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2712 - mean_squared_error: 0.2712 - val_loss: 0.1522 - val_mean_squared_error: 0.1522\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11669\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.2702 - mean_squared_error: 0.2702 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11669\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2635 - mean_squared_error: 0.2635 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.11669 to 0.11362, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_28\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.2613 - mean_squared_error: 0.2613 - val_loss: 0.2069 - val_mean_squared_error: 0.2069\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11362\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.2529 - mean_squared_error: 0.2529 - val_loss: 0.1421 - val_mean_squared_error: 0.1421\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11362\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2603 - mean_squared_error: 0.2603 - val_loss: 0.4014 - val_mean_squared_error: 0.4014\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11362\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2521 - mean_squared_error: 0.2521 - val_loss: 0.1874 - val_mean_squared_error: 0.1874\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11362\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.2482 - mean_squared_error: 0.2482 - val_loss: 0.1810 - val_mean_squared_error: 0.1810\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11362\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.2424 - mean_squared_error: 0.2424 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11362\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.2465 - mean_squared_error: 0.2465 - val_loss: 0.1543 - val_mean_squared_error: 0.1543\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11362\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.1360 - val_mean_squared_error: 0.1360\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11362\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 289s 48us/step - loss: 0.2412 - mean_squared_error: 0.2412 - val_loss: 0.1881 - val_mean_squared_error: 0.1881\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11362\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 0.2340 - mean_squared_error: 0.2340 - val_loss: 0.1782 - val_mean_squared_error: 0.1782\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11362\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.2341 - mean_squared_error: 0.2341 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11362\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.2347 - mean_squared_error: 0.2347 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11362\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.2357 - mean_squared_error: 0.2357 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.11362 to 0.10185, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.0781 - mean_squared_error: 0.0781 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10185 to 0.07142, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.0738 - mean_squared_error: 0.0738 - val_loss: 0.0685 - val_mean_squared_error: 0.0685\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.07142 to 0.06853, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_43\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.0715 - mean_squared_error: 0.0715 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06853\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.0696 - mean_squared_error: 0.0696 - val_loss: 0.0679 - val_mean_squared_error: 0.0679\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.06853 to 0.06793, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 288s 47us/step - loss: 0.0681 - mean_squared_error: 0.0681 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06793\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 276s 46us/step - loss: 0.0666 - mean_squared_error: 0.0666 - val_loss: 0.0632 - val_mean_squared_error: 0.0632\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.06793 to 0.06324, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_47\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 282s 47us/step - loss: 0.0657 - mean_squared_error: 0.0657 - val_loss: 0.0655 - val_mean_squared_error: 0.0655\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06324\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 281s 46us/step - loss: 0.0643 - mean_squared_error: 0.0643 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06324 to 0.06133, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_3_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0630 - mean_squared_error: 0.0630 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06133\n",
      "4\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 289s 48us/step - loss: 2.2320 - mean_squared_error: 2.2320 - val_loss: 0.6662 - val_mean_squared_error: 0.6662\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66620, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.9821 - mean_squared_error: 0.9821 - val_loss: 0.3949 - val_mean_squared_error: 0.3949\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66620 to 0.39489, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.7779 - mean_squared_error: 0.7779 - val_loss: 0.4899 - val_mean_squared_error: 0.4899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.39489\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 292s 48us/step - loss: 0.6417 - mean_squared_error: 0.6417 - val_loss: 0.2950 - val_mean_squared_error: 0.2950\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.39489 to 0.29497, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 282s 47us/step - loss: 0.5761 - mean_squared_error: 0.5761 - val_loss: 0.2980 - val_mean_squared_error: 0.2980\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29497\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 288s 47us/step - loss: 0.4982 - mean_squared_error: 0.4982 - val_loss: 0.5742 - val_mean_squared_error: 0.5742\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29497\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.4654 - mean_squared_error: 0.4654 - val_loss: 0.2132 - val_mean_squared_error: 0.2132\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.29497 to 0.21322, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 290s 48us/step - loss: 0.4304 - mean_squared_error: 0.4304 - val_loss: 0.7007 - val_mean_squared_error: 0.7007\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21322\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 284s 47us/step - loss: 0.3987 - mean_squared_error: 0.3987 - val_loss: 0.2174 - val_mean_squared_error: 0.2174\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21322\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.4054 - mean_squared_error: 0.4054 - val_loss: 0.2288 - val_mean_squared_error: 0.2288\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21322\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.3773 - mean_squared_error: 0.3773 - val_loss: 0.6268 - val_mean_squared_error: 0.6268\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21322\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 286s 47us/step - loss: 0.3583 - mean_squared_error: 0.3583 - val_loss: 0.3363 - val_mean_squared_error: 0.3363\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.21322\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.2483 - val_mean_squared_error: 0.2483\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.21322\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3488 - mean_squared_error: 0.3488 - val_loss: 0.2239 - val_mean_squared_error: 0.2239\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21322\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3377 - mean_squared_error: 0.3377 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.21322\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 288s 47us/step - loss: 0.3424 - mean_squared_error: 0.3424 - val_loss: 0.5798 - val_mean_squared_error: 0.5798\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.21322\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 291s 48us/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.1445 - val_mean_squared_error: 0.1445\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.21322 to 0.14447, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 0.3155 - mean_squared_error: 0.3155 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.14447\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 291s 48us/step - loss: 0.3047 - mean_squared_error: 0.3047 - val_loss: 0.1736 - val_mean_squared_error: 0.1736\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14447\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.3031 - mean_squared_error: 0.3031 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.14447\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 287s 47us/step - loss: 0.3107 - mean_squared_error: 0.3107 - val_loss: 0.2494 - val_mean_squared_error: 0.2494\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14447\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 290s 48us/step - loss: 0.3012 - mean_squared_error: 0.3012 - val_loss: 0.1818 - val_mean_squared_error: 0.1818\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14447\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.2916 - mean_squared_error: 0.2916 - val_loss: 0.6450 - val_mean_squared_error: 0.6450\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14447\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 282s 46us/step - loss: 0.2985 - mean_squared_error: 0.2985 - val_loss: 0.3409 - val_mean_squared_error: 0.3409\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14447\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 288s 48us/step - loss: 0.2872 - mean_squared_error: 0.2872 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14447\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 290s 48us/step - loss: 0.2781 - mean_squared_error: 0.2781 - val_loss: 0.2113 - val_mean_squared_error: 0.2113\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14447\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.2813 - mean_squared_error: 0.2813 - val_loss: 0.5004 - val_mean_squared_error: 0.5004\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14447\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 289s 48us/step - loss: 0.2771 - mean_squared_error: 0.2771 - val_loss: 0.1750 - val_mean_squared_error: 0.1750\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.14447\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2921 - mean_squared_error: 0.2921 - val_loss: 0.2389 - val_mean_squared_error: 0.2389\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14447\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 289s 48us/step - loss: 0.2746 - mean_squared_error: 0.2746 - val_loss: 0.3197 - val_mean_squared_error: 0.3197\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14447\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 280s 46us/step - loss: 0.2653 - mean_squared_error: 0.2653 - val_loss: 0.1580 - val_mean_squared_error: 0.1580\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14447\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 292s 48us/step - loss: 0.2630 - mean_squared_error: 0.2630 - val_loss: 1.5999 - val_mean_squared_error: 1.5999\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14447\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 283s 47us/step - loss: 0.2543 - mean_squared_error: 0.2543 - val_loss: 0.6104 - val_mean_squared_error: 0.6104\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14447\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 289s 48us/step - loss: 0.2576 - mean_squared_error: 0.2576 - val_loss: 0.1765 - val_mean_squared_error: 0.1765\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14447\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 0.2603 - mean_squared_error: 0.2603 - val_loss: 0.3445 - val_mean_squared_error: 0.3445\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14447\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 291s 48us/step - loss: 0.2497 - mean_squared_error: 0.2497 - val_loss: 0.2561 - val_mean_squared_error: 0.2561\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14447\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.2550 - mean_squared_error: 0.2550 - val_loss: 0.2020 - val_mean_squared_error: 0.2020\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14447\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2429 - mean_squared_error: 0.2429 - val_loss: 0.1748 - val_mean_squared_error: 0.1748\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14447\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2435 - mean_squared_error: 0.2435 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14447\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2417 - mean_squared_error: 0.2417 - val_loss: 0.3129 - val_mean_squared_error: 0.3129\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14447\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2471 - mean_squared_error: 0.2471 - val_loss: 0.1772 - val_mean_squared_error: 0.1772\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.14447\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2433 - mean_squared_error: 0.2433 - val_loss: 0.1959 - val_mean_squared_error: 0.1959\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14447\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2355 - mean_squared_error: 0.2355 - val_loss: 0.2242 - val_mean_squared_error: 0.2242\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.14447\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2320 - mean_squared_error: 0.2320 - val_loss: 0.1542 - val_mean_squared_error: 0.1542\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14447\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2302 - mean_squared_error: 0.2302 - val_loss: 0.1822 - val_mean_squared_error: 0.1822\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.14447\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 252s 41us/step - loss: 0.2248 - mean_squared_error: 0.2248 - val_loss: 0.1192 - val_mean_squared_error: 0.1192\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14447 to 0.11924, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_4_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 252s 42us/step - loss: 0.2205 - mean_squared_error: 0.2205 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11924\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 252s 42us/step - loss: 0.2184 - mean_squared_error: 0.2184 - val_loss: 0.3688 - val_mean_squared_error: 0.3688\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11924\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2146 - mean_squared_error: 0.2146 - val_loss: 0.1433 - val_mean_squared_error: 0.1433\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11924\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 252s 42us/step - loss: 0.2167 - mean_squared_error: 0.2167 - val_loss: 0.1799 - val_mean_squared_error: 0.1799\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11924\n",
      "5\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 2.3951 - mean_squared_error: 2.3951 - val_loss: 0.8007 - val_mean_squared_error: 0.8007\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80075, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 1.0366 - mean_squared_error: 1.0366 - val_loss: 0.6705 - val_mean_squared_error: 0.6705\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80075 to 0.67052, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.7951 - mean_squared_error: 0.7951 - val_loss: 0.7096 - val_mean_squared_error: 0.7096\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67052\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.6545 - mean_squared_error: 0.6545 - val_loss: 0.2558 - val_mean_squared_error: 0.2558\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67052 to 0.25584, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.5574 - mean_squared_error: 0.5574 - val_loss: 0.3425 - val_mean_squared_error: 0.3425\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25584\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.4937 - mean_squared_error: 0.4937 - val_loss: 0.4981 - val_mean_squared_error: 0.4981\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25584\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.4610 - mean_squared_error: 0.4610 - val_loss: 0.2102 - val_mean_squared_error: 0.2102\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25584 to 0.21019, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.4398 - mean_squared_error: 0.4398 - val_loss: 0.2095 - val_mean_squared_error: 0.2095\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21019 to 0.20948, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.4116 - mean_squared_error: 0.4116 - val_loss: 0.2575 - val_mean_squared_error: 0.2575\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20948\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.4055 - mean_squared_error: 0.4055 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20948\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3786 - mean_squared_error: 0.3786 - val_loss: 0.4637 - val_mean_squared_error: 0.4637\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20948\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3663 - mean_squared_error: 0.3663 - val_loss: 0.4359 - val_mean_squared_error: 0.4359\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20948\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3521 - mean_squared_error: 0.3521 - val_loss: 0.2075 - val_mean_squared_error: 0.2075\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.20948 to 0.20749, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_13\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3315 - mean_squared_error: 0.3315 - val_loss: 0.1837 - val_mean_squared_error: 0.1837\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20749 to 0.18373, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.3161 - val_mean_squared_error: 0.3161\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18373\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3085 - mean_squared_error: 0.3085 - val_loss: 0.2570 - val_mean_squared_error: 0.2570\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18373\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3065 - mean_squared_error: 0.3065 - val_loss: 0.2749 - val_mean_squared_error: 0.2749\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18373\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2947 - mean_squared_error: 0.2947 - val_loss: 0.1955 - val_mean_squared_error: 0.1955\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18373\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2941 - mean_squared_error: 0.2941 - val_loss: 0.1890 - val_mean_squared_error: 0.1890\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18373\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2814 - mean_squared_error: 0.2814 - val_loss: 0.1923 - val_mean_squared_error: 0.1923\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18373\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2848 - mean_squared_error: 0.2848 - val_loss: 0.6032 - val_mean_squared_error: 0.6032\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.18373\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2746 - mean_squared_error: 0.2746 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.18373 to 0.16449, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_22\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2706 - mean_squared_error: 0.2706 - val_loss: 0.2182 - val_mean_squared_error: 0.2182\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16449\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2645 - mean_squared_error: 0.2645 - val_loss: 0.3484 - val_mean_squared_error: 0.3484\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16449\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2658 - mean_squared_error: 0.2658 - val_loss: 0.1789 - val_mean_squared_error: 0.1789\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16449\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2580 - mean_squared_error: 0.2580 - val_loss: 0.1622 - val_mean_squared_error: 0.1622\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16449 to 0.16221, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_26\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2518 - mean_squared_error: 0.2518 - val_loss: 0.1859 - val_mean_squared_error: 0.1859\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16221\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2451 - mean_squared_error: 0.2451 - val_loss: 0.3029 - val_mean_squared_error: 0.3029\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16221\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2377 - mean_squared_error: 0.2377 - val_loss: 0.1493 - val_mean_squared_error: 0.1493\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.16221 to 0.14926, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2433 - mean_squared_error: 0.2433 - val_loss: 0.1360 - val_mean_squared_error: 0.1360\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.14926 to 0.13602, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2325 - mean_squared_error: 0.2325 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13602 to 0.11478, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_31\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2227 - mean_squared_error: 0.2227 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11478\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2265 - mean_squared_error: 0.2265 - val_loss: 0.1352 - val_mean_squared_error: 0.1352\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11478\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2241 - mean_squared_error: 0.2241 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11478 to 0.11343, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_34\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2163 - mean_squared_error: 0.2163 - val_loss: 0.1723 - val_mean_squared_error: 0.1723\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11343\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2138 - mean_squared_error: 0.2138 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11343 to 0.11125, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_5_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2100 - mean_squared_error: 0.2100 - val_loss: 0.1558 - val_mean_squared_error: 0.1558\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11125\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2114 - mean_squared_error: 0.2114 - val_loss: 0.9870 - val_mean_squared_error: 0.9870\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11125\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2115 - mean_squared_error: 0.2115 - val_loss: 0.2448 - val_mean_squared_error: 0.2448\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11125\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2021 - mean_squared_error: 0.2021 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11125\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2040 - mean_squared_error: 0.2040 - val_loss: 0.3792 - val_mean_squared_error: 0.3792\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11125\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2049 - mean_squared_error: 0.2049 - val_loss: 0.1481 - val_mean_squared_error: 0.1481\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11125\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1990 - mean_squared_error: 0.1990 - val_loss: 0.4404 - val_mean_squared_error: 0.4404\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11125\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1989 - mean_squared_error: 0.1989 - val_loss: 0.3067 - val_mean_squared_error: 0.3067\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11125\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2028 - mean_squared_error: 0.2028 - val_loss: 0.2420 - val_mean_squared_error: 0.2420\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11125\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1950 - mean_squared_error: 0.1950 - val_loss: 0.1256 - val_mean_squared_error: 0.1256\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11125\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1905 - mean_squared_error: 0.1905 - val_loss: 0.1852 - val_mean_squared_error: 0.1852\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11125\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1914 - mean_squared_error: 0.1914 - val_loss: 2.6493 - val_mean_squared_error: 2.6493\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11125\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1970 - mean_squared_error: 0.1970 - val_loss: 0.3136 - val_mean_squared_error: 0.3136\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11125\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.1901 - mean_squared_error: 0.1901 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11125\n",
      "6\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 2.1204 - mean_squared_error: 2.1204 - val_loss: 0.7681 - val_mean_squared_error: 0.7681\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76810, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 1.0753 - mean_squared_error: 1.0753 - val_loss: 0.5552 - val_mean_squared_error: 0.5552\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76810 to 0.55522, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_02\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.8169 - mean_squared_error: 0.8169 - val_loss: 1.0867 - val_mean_squared_error: 1.0867\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55522\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.6413 - mean_squared_error: 0.6413 - val_loss: 0.4357 - val_mean_squared_error: 0.4357\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55522 to 0.43566, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.5643 - mean_squared_error: 0.5643 - val_loss: 0.5234 - val_mean_squared_error: 0.5234\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43566\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.5207 - mean_squared_error: 0.5207 - val_loss: 0.2808 - val_mean_squared_error: 0.2808\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43566 to 0.28078, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_06\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.4713 - mean_squared_error: 0.4713 - val_loss: 0.4205 - val_mean_squared_error: 0.4205\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28078\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.4516 - mean_squared_error: 0.4516 - val_loss: 0.2788 - val_mean_squared_error: 0.2788\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28078 to 0.27879, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.4203 - mean_squared_error: 0.4203 - val_loss: 0.4557 - val_mean_squared_error: 0.4557\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27879\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.4329 - mean_squared_error: 0.4329 - val_loss: 0.4133 - val_mean_squared_error: 0.4133\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27879\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3988 - mean_squared_error: 0.3988 - val_loss: 0.6274 - val_mean_squared_error: 0.6274\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27879\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.2955 - val_mean_squared_error: 0.2955\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27879\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.8772 - val_mean_squared_error: 0.8772\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27879\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3625 - mean_squared_error: 0.3625 - val_loss: 0.2237 - val_mean_squared_error: 0.2237\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27879 to 0.22369, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.4879 - val_mean_squared_error: 0.4879\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.22369\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.5011 - val_mean_squared_error: 0.5011\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.22369\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.3373 - mean_squared_error: 0.3373 - val_loss: 0.1974 - val_mean_squared_error: 0.1974\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22369 to 0.19736, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3480 - val_mean_squared_error: 0.3480\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19736\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3330 - mean_squared_error: 0.3330 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.19736 to 0.16848, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_19\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3186 - mean_squared_error: 0.3186 - val_loss: 0.3432 - val_mean_squared_error: 0.3432\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16848\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3137 - mean_squared_error: 0.3137 - val_loss: 0.2486 - val_mean_squared_error: 0.2486\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16848\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.2380 - val_mean_squared_error: 0.2380\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16848\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3116 - mean_squared_error: 0.3116 - val_loss: 0.3321 - val_mean_squared_error: 0.3321\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16848\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.3010 - mean_squared_error: 0.3010 - val_loss: 0.1618 - val_mean_squared_error: 0.1618\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16848 to 0.16177, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_24\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 253s 42us/step - loss: 0.2989 - mean_squared_error: 0.2989 - val_loss: 0.2995 - val_mean_squared_error: 0.2995\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16177\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2918 - mean_squared_error: 0.2918 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16177 to 0.15815, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_26\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2911 - mean_squared_error: 0.2911 - val_loss: 0.2096 - val_mean_squared_error: 0.2096\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15815\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2964 - mean_squared_error: 0.2964 - val_loss: 0.2037 - val_mean_squared_error: 0.2037\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15815\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2868 - mean_squared_error: 0.2868 - val_loss: 0.2837 - val_mean_squared_error: 0.2837\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15815\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3032 - mean_squared_error: 0.3032 - val_loss: 0.2828 - val_mean_squared_error: 0.2828\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15815\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2911 - mean_squared_error: 0.2911 - val_loss: 0.2170 - val_mean_squared_error: 0.2170\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15815\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2812 - mean_squared_error: 0.2812 - val_loss: 0.1677 - val_mean_squared_error: 0.1677\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15815\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2822 - mean_squared_error: 0.2822 - val_loss: 0.1875 - val_mean_squared_error: 0.1875\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15815\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2770 - mean_squared_error: 0.2770 - val_loss: 0.1711 - val_mean_squared_error: 0.1711\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15815\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2767 - mean_squared_error: 0.2767 - val_loss: 0.1822 - val_mean_squared_error: 0.1822\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15815\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2766 - mean_squared_error: 0.2766 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15815 to 0.15556, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2730 - mean_squared_error: 0.2730 - val_loss: 0.1373 - val_mean_squared_error: 0.1373\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15556 to 0.13726, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2719 - mean_squared_error: 0.2719 - val_loss: 0.2765 - val_mean_squared_error: 0.2765\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.13726\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2700 - mean_squared_error: 0.2700 - val_loss: 0.2788 - val_mean_squared_error: 0.2788\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.13726\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2706 - mean_squared_error: 0.2706 - val_loss: 0.3277 - val_mean_squared_error: 0.3277\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13726\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2584 - mean_squared_error: 0.2584 - val_loss: 0.1650 - val_mean_squared_error: 0.1650\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.13726\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2585 - mean_squared_error: 0.2585 - val_loss: 0.1859 - val_mean_squared_error: 0.1859\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13726\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2526 - mean_squared_error: 0.2526 - val_loss: 0.1878 - val_mean_squared_error: 0.1878\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.13726\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2541 - mean_squared_error: 0.2541 - val_loss: 0.2167 - val_mean_squared_error: 0.2167\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.13726\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2503 - mean_squared_error: 0.2503 - val_loss: 0.3362 - val_mean_squared_error: 0.3362\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.13726\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2518 - mean_squared_error: 0.2518 - val_loss: 0.1581 - val_mean_squared_error: 0.1581\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.13726\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2392 - mean_squared_error: 0.2392 - val_loss: 0.1741 - val_mean_squared_error: 0.1741\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.13726\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2409 - mean_squared_error: 0.2409 - val_loss: 0.1824 - val_mean_squared_error: 0.1824\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.13726\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2435 - mean_squared_error: 0.2435 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13726 to 0.12050, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 254s 42us/step - loss: 0.2350 - mean_squared_error: 0.2350 - val_loss: 0.1152 - val_mean_squared_error: 0.1152\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12050 to 0.11519, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_6_50\n",
      "7\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 2.2684 - mean_squared_error: 2.2684 - val_loss: 0.8230 - val_mean_squared_error: 0.8230\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82298, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 1.0535 - mean_squared_error: 1.0535 - val_loss: 0.4011 - val_mean_squared_error: 0.4011\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82298 to 0.40114, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.8161 - mean_squared_error: 0.8161 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.40114\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.6646 - mean_squared_error: 0.6646 - val_loss: 0.3547 - val_mean_squared_error: 0.3547\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40114 to 0.35467, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.5834 - mean_squared_error: 0.5834 - val_loss: 1.1816 - val_mean_squared_error: 1.1816\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35467\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.5463 - mean_squared_error: 0.5463 - val_loss: 0.3211 - val_mean_squared_error: 0.3211\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35467 to 0.32115, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_06\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.4906 - mean_squared_error: 0.4906 - val_loss: 0.8337 - val_mean_squared_error: 0.8337\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32115\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.4505 - mean_squared_error: 0.4505 - val_loss: 0.6141 - val_mean_squared_error: 0.6141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32115\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.4382 - mean_squared_error: 0.4382 - val_loss: 0.2486 - val_mean_squared_error: 0.2486\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32115 to 0.24864, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.4379 - mean_squared_error: 0.4379 - val_loss: 0.5558 - val_mean_squared_error: 0.5558\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.24864\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.4117 - mean_squared_error: 0.4117 - val_loss: 0.2161 - val_mean_squared_error: 0.2161\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.24864 to 0.21612, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_11\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.4006 - mean_squared_error: 0.4006 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.21612\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3748 - mean_squared_error: 0.3748 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.21612\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3578 - mean_squared_error: 0.3578 - val_loss: 0.1865 - val_mean_squared_error: 0.1865\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.21612 to 0.18651, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3497 - mean_squared_error: 0.3497 - val_loss: 0.2364 - val_mean_squared_error: 0.2364\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18651\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 258s 42us/step - loss: 0.3324 - mean_squared_error: 0.3324 - val_loss: 0.3889 - val_mean_squared_error: 0.3889\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18651\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3347 - mean_squared_error: 0.3347 - val_loss: 0.1994 - val_mean_squared_error: 0.1994\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18651\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3367 - mean_squared_error: 0.3367 - val_loss: 0.2149 - val_mean_squared_error: 0.2149\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18651\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 258s 43us/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.2046 - val_mean_squared_error: 0.2046\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18651\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.2431 - val_mean_squared_error: 0.2431\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18651\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3227 - mean_squared_error: 0.3227 - val_loss: 0.1793 - val_mean_squared_error: 0.1793\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18651 to 0.17932, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_21\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.3049 - mean_squared_error: 0.3049 - val_loss: 1.9530 - val_mean_squared_error: 1.9530\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17932\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.3085 - mean_squared_error: 0.3085 - val_loss: 0.3238 - val_mean_squared_error: 0.3238\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17932\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.3043 - mean_squared_error: 0.3043 - val_loss: 0.4276 - val_mean_squared_error: 0.4276\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17932\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2969 - mean_squared_error: 0.2969 - val_loss: 0.3328 - val_mean_squared_error: 0.3328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17932\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2912 - mean_squared_error: 0.2912 - val_loss: 0.3978 - val_mean_squared_error: 0.3978\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17932\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2867 - mean_squared_error: 0.2867 - val_loss: 0.2593 - val_mean_squared_error: 0.2593\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.17932\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2831 - mean_squared_error: 0.2831 - val_loss: 0.2388 - val_mean_squared_error: 0.2388\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17932\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.2834 - mean_squared_error: 0.2834 - val_loss: 0.1723 - val_mean_squared_error: 0.1723\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17932 to 0.17226, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2834 - mean_squared_error: 0.2834 - val_loss: 0.2876 - val_mean_squared_error: 0.2876\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17226\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2861 - mean_squared_error: 0.2861 - val_loss: 0.2967 - val_mean_squared_error: 0.2967\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17226\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.1108 - mean_squared_error: 0.1108 - val_loss: 0.0995 - val_mean_squared_error: 0.0995\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17226 to 0.09950, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_32\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0980 - mean_squared_error: 0.0980 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09950 to 0.09298, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_33\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0946 - mean_squared_error: 0.0946 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09298 to 0.08944, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_34\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0925 - mean_squared_error: 0.0925 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08944\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0904 - mean_squared_error: 0.0904 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08944 to 0.08471, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0889 - mean_squared_error: 0.0889 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08471\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0875 - mean_squared_error: 0.0875 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08471\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0873 - mean_squared_error: 0.0873 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08471\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0863 - mean_squared_error: 0.0863 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08471 to 0.08002, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_40\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0859 - mean_squared_error: 0.0859 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08002\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0845 - mean_squared_error: 0.0845 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08002 to 0.07797, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0844 - mean_squared_error: 0.0844 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07797\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0835 - mean_squared_error: 0.0835 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.07797 to 0.07577, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_44\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0828 - mean_squared_error: 0.0828 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07577\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07577\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0819 - mean_squared_error: 0.0819 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07577\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0812 - mean_squared_error: 0.0812 - val_loss: 0.0748 - val_mean_squared_error: 0.0748\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07577 to 0.07483, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_48\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0802 - mean_squared_error: 0.0802 - val_loss: 0.0872 - val_mean_squared_error: 0.0872\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07483\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 255s 42us/step - loss: 0.0802 - mean_squared_error: 0.0802 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.07483 to 0.07359, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_7_50\n",
      "8\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 2.2530 - mean_squared_error: 2.2530 - val_loss: 0.8246 - val_mean_squared_error: 0.8246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82458, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 1.0027 - mean_squared_error: 1.0027 - val_loss: 0.6718 - val_mean_squared_error: 0.6718\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82458 to 0.67184, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.7860 - mean_squared_error: 0.7860 - val_loss: 0.9851 - val_mean_squared_error: 0.9851\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67184\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.6110 - mean_squared_error: 0.6110 - val_loss: 0.4500 - val_mean_squared_error: 0.4500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67184 to 0.45005, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.5592 - mean_squared_error: 0.5592 - val_loss: 0.5256 - val_mean_squared_error: 0.5256\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45005\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.4928 - mean_squared_error: 0.4928 - val_loss: 0.5594 - val_mean_squared_error: 0.5594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45005\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.4461 - mean_squared_error: 0.4461 - val_loss: 0.3074 - val_mean_squared_error: 0.3074\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45005 to 0.30737, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.4327 - mean_squared_error: 0.4327 - val_loss: 0.1908 - val_mean_squared_error: 0.1908\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.30737 to 0.19078, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.1958 - val_mean_squared_error: 0.1958\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19078\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.1800 - val_mean_squared_error: 0.1800\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19078 to 0.17995, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_10\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.2217 - val_mean_squared_error: 0.2217\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17995\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3432 - mean_squared_error: 0.3432 - val_loss: 0.2436 - val_mean_squared_error: 0.2436\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17995\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3535 - mean_squared_error: 0.3535 - val_loss: 0.3560 - val_mean_squared_error: 0.3560\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17995\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3200 - mean_squared_error: 0.3200 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17995\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.3103 - mean_squared_error: 0.3103 - val_loss: 0.1938 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17995\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2951 - mean_squared_error: 0.2951 - val_loss: 0.1962 - val_mean_squared_error: 0.1962\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17995\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2895 - mean_squared_error: 0.2895 - val_loss: 0.1588 - val_mean_squared_error: 0.1588\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17995 to 0.15877, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 256s 42us/step - loss: 0.2848 - mean_squared_error: 0.2848 - val_loss: 0.4693 - val_mean_squared_error: 0.4693\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15877\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 257s 42us/step - loss: 0.2694 - mean_squared_error: 0.2694 - val_loss: 0.1939 - val_mean_squared_error: 0.1939\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15877\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2596 - mean_squared_error: 0.2596 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15877 to 0.14505, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_20\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2617 - mean_squared_error: 0.2617 - val_loss: 0.7811 - val_mean_squared_error: 0.7811\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14505\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2620 - mean_squared_error: 0.2620 - val_loss: 0.2835 - val_mean_squared_error: 0.2835\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14505\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2456 - mean_squared_error: 0.2456 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14505\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.2560 - mean_squared_error: 0.2560 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14505\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2458 - mean_squared_error: 0.2458 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14505 to 0.12028, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_25\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2422 - mean_squared_error: 0.2422 - val_loss: 0.1757 - val_mean_squared_error: 0.1757\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12028\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2353 - mean_squared_error: 0.2353 - val_loss: 0.2042 - val_mean_squared_error: 0.2042\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12028\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2154 - mean_squared_error: 0.2154 - val_loss: 0.1614 - val_mean_squared_error: 0.1614\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12028\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2094 - mean_squared_error: 0.2094 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.12028 to 0.10932, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2070 - mean_squared_error: 0.2070 - val_loss: 0.1513 - val_mean_squared_error: 0.1513\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10932\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.2260 - mean_squared_error: 0.2260 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10932\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1961 - mean_squared_error: 0.1961 - val_loss: 0.1101 - val_mean_squared_error: 0.1101\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10932\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1934 - mean_squared_error: 0.1934 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10932 to 0.10108, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_33\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1836 - mean_squared_error: 0.1836 - val_loss: 0.2582 - val_mean_squared_error: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10108\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1789 - mean_squared_error: 0.1789 - val_loss: 0.1224 - val_mean_squared_error: 0.1224\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10108\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.1819 - mean_squared_error: 0.1819 - val_loss: 0.1658 - val_mean_squared_error: 0.1658\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10108\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1750 - mean_squared_error: 0.1750 - val_loss: 0.1549 - val_mean_squared_error: 0.1549\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10108\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10108\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.1681 - mean_squared_error: 0.1681 - val_loss: 0.2952 - val_mean_squared_error: 0.2952\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10108\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1679 - mean_squared_error: 0.1679 - val_loss: 0.1261 - val_mean_squared_error: 0.1261\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10108\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1637 - mean_squared_error: 0.1637 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10108\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1613 - mean_squared_error: 0.1613 - val_loss: 0.1615 - val_mean_squared_error: 0.1615\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10108\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1562 - mean_squared_error: 0.1562 - val_loss: 0.3609 - val_mean_squared_error: 0.3609\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10108\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1610 - mean_squared_error: 0.1610 - val_loss: 0.1414 - val_mean_squared_error: 0.1414\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10108\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1549 - mean_squared_error: 0.1549 - val_loss: 1.2235 - val_mean_squared_error: 1.2235\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10108\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.2419 - val_mean_squared_error: 0.2419\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10108\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1529 - mean_squared_error: 0.1529 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10108\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1527 - mean_squared_error: 0.1527 - val_loss: 0.3379 - val_mean_squared_error: 0.3379\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10108\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1454 - mean_squared_error: 0.1454 - val_loss: 0.0917 - val_mean_squared_error: 0.0917\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.10108 to 0.09172, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_8_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1483 - mean_squared_error: 0.1483 - val_loss: 0.2391 - val_mean_squared_error: 0.2391\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09172\n",
      "9\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 2.2364 - mean_squared_error: 2.2364 - val_loss: 1.4040 - val_mean_squared_error: 1.4040\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.40396, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 1.0796 - mean_squared_error: 1.0796 - val_loss: 1.4283 - val_mean_squared_error: 1.4283\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.40396\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.8518 - mean_squared_error: 0.8518 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.40396 to 0.68999, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.7271 - mean_squared_error: 0.7271 - val_loss: 0.6057 - val_mean_squared_error: 0.6057\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68999 to 0.60574, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.6479 - mean_squared_error: 0.6479 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60574 to 0.32207, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.5838 - mean_squared_error: 0.5838 - val_loss: 0.2805 - val_mean_squared_error: 0.2805\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32207 to 0.28049, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_06\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.5385 - mean_squared_error: 0.5385 - val_loss: 0.5445 - val_mean_squared_error: 0.5445\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28049\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.5030 - mean_squared_error: 0.5030 - val_loss: 0.2959 - val_mean_squared_error: 0.2959\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28049\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.4869 - mean_squared_error: 0.4869 - val_loss: 0.4184 - val_mean_squared_error: 0.4184\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28049\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.4766 - mean_squared_error: 0.4766 - val_loss: 0.5717 - val_mean_squared_error: 0.5717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28049\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4614 - mean_squared_error: 0.4614 - val_loss: 0.2636 - val_mean_squared_error: 0.2636\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28049 to 0.26358, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4328 - mean_squared_error: 0.4328 - val_loss: 0.2700 - val_mean_squared_error: 0.2700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26358\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4245 - mean_squared_error: 0.4245 - val_loss: 0.2982 - val_mean_squared_error: 0.2982\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26358\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4049 - mean_squared_error: 0.4049 - val_loss: 0.2364 - val_mean_squared_error: 0.2364\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26358 to 0.23636, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3915 - mean_squared_error: 0.3915 - val_loss: 0.3184 - val_mean_squared_error: 0.3184\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.23636\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3841 - mean_squared_error: 0.3841 - val_loss: 0.9038 - val_mean_squared_error: 0.9038\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.23636\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.3697 - mean_squared_error: 0.3697 - val_loss: 0.2654 - val_mean_squared_error: 0.2654\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23636\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.3588 - mean_squared_error: 0.3588 - val_loss: 0.1646 - val_mean_squared_error: 0.1646\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23636 to 0.16458, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_18\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3568 - mean_squared_error: 0.3568 - val_loss: 0.2003 - val_mean_squared_error: 0.2003\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16458\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3467 - mean_squared_error: 0.3467 - val_loss: 0.2774 - val_mean_squared_error: 0.2774\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16458\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.2801 - val_mean_squared_error: 0.2801\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16458\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.2752 - val_mean_squared_error: 0.2752\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16458\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 0.4306 - val_mean_squared_error: 0.4306\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16458\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 1.0461 - val_mean_squared_error: 1.0461\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16458\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.3194 - mean_squared_error: 0.3194 - val_loss: 0.1830 - val_mean_squared_error: 0.1830\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16458\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.2592 - val_mean_squared_error: 0.2592\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16458\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1330 - mean_squared_error: 0.1330 - val_loss: 0.1222 - val_mean_squared_error: 0.1222\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.16458 to 0.12221, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_27\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1250 - mean_squared_error: 0.1250 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12221 to 0.11780, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_28\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1213 - mean_squared_error: 0.1213 - val_loss: 0.1247 - val_mean_squared_error: 0.1247\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11780\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1188 - mean_squared_error: 0.1188 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11780 to 0.11115, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1166 - mean_squared_error: 0.1166 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11115\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1134 - mean_squared_error: 0.1134 - val_loss: 0.1056 - val_mean_squared_error: 0.1056\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11115 to 0.10561, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_32\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1104 - mean_squared_error: 0.1104 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10561 to 0.10225, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_33\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1083 - mean_squared_error: 0.1083 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10225\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1058 - mean_squared_error: 0.1058 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10225\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.1035 - mean_squared_error: 0.1035 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10225 to 0.09609, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1015 - mean_squared_error: 0.1015 - val_loss: 0.0966 - val_mean_squared_error: 0.0966\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09609\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.1001 - mean_squared_error: 0.1001 - val_loss: 0.0934 - val_mean_squared_error: 0.0934\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.09609 to 0.09339, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_38\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0986 - mean_squared_error: 0.0986 - val_loss: 0.0994 - val_mean_squared_error: 0.0994\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09339\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0972 - mean_squared_error: 0.0972 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09339\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0963 - mean_squared_error: 0.0963 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.09339 to 0.09160, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0957 - mean_squared_error: 0.0957 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.09160\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 260s 43us/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09160 to 0.08841, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_43\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0933 - mean_squared_error: 0.0933 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08841\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08841\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0905 - mean_squared_error: 0.0905 - val_loss: 0.0906 - val_mean_squared_error: 0.0906\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08841\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0889 - mean_squared_error: 0.0889 - val_loss: 0.0856 - val_mean_squared_error: 0.0856\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08841 to 0.08563, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_47\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0880 - mean_squared_error: 0.0880 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.08563 to 0.08380, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_9_48\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0869 - mean_squared_error: 0.0869 - val_loss: 0.0844 - val_mean_squared_error: 0.0844\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08380\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 259s 43us/step - loss: 0.0862 - mean_squared_error: 0.0862 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08380\n",
      "10\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 2.2435 - mean_squared_error: 2.2435 - val_loss: 3.4340 - val_mean_squared_error: 3.4340\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.43404, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 1.0398 - mean_squared_error: 1.0398 - val_loss: 2.0531 - val_mean_squared_error: 2.0531\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.43404 to 2.05307, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.7607 - mean_squared_error: 0.7607 - val_loss: 0.6309 - val_mean_squared_error: 0.6309\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.05307 to 0.63088, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.6347 - mean_squared_error: 0.6347 - val_loss: 0.4058 - val_mean_squared_error: 0.4058\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63088 to 0.40582, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_04\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.5394 - mean_squared_error: 0.5394 - val_loss: 0.2396 - val_mean_squared_error: 0.2396\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40582 to 0.23963, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.5003 - mean_squared_error: 0.5003 - val_loss: 0.2984 - val_mean_squared_error: 0.2984\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23963\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4690 - mean_squared_error: 0.4690 - val_loss: 0.3009 - val_mean_squared_error: 0.3009\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23963\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4351 - mean_squared_error: 0.4351 - val_loss: 1.3500 - val_mean_squared_error: 1.3500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23963\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.4060 - mean_squared_error: 0.4060 - val_loss: 1.2788 - val_mean_squared_error: 1.2788\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23963\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3995 - mean_squared_error: 0.3995 - val_loss: 0.6105 - val_mean_squared_error: 0.6105\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23963\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3795 - mean_squared_error: 0.3795 - val_loss: 0.2503 - val_mean_squared_error: 0.2503\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.23963\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.3647 - mean_squared_error: 0.3647 - val_loss: 0.2017 - val_mean_squared_error: 0.2017\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.23963 to 0.20167, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.3444 - mean_squared_error: 0.3444 - val_loss: 0.2214 - val_mean_squared_error: 0.2214\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20167\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.1966 - val_mean_squared_error: 0.1966\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20167 to 0.19665, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3175 - mean_squared_error: 0.3175 - val_loss: 0.2416 - val_mean_squared_error: 0.2416\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19665\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.8005 - val_mean_squared_error: 0.8005\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19665\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3183 - mean_squared_error: 0.3183 - val_loss: 0.1951 - val_mean_squared_error: 0.1951\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19665 to 0.19511, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3024 - mean_squared_error: 0.3024 - val_loss: 0.1681 - val_mean_squared_error: 0.1681\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.19511 to 0.16810, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_18\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3049 - mean_squared_error: 0.3049 - val_loss: 0.2277 - val_mean_squared_error: 0.2277\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16810\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2945 - mean_squared_error: 0.2945 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16810\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.2784 - mean_squared_error: 0.2784 - val_loss: 0.2695 - val_mean_squared_error: 0.2695\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16810\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.3015 - mean_squared_error: 0.3015 - val_loss: 0.3608 - val_mean_squared_error: 0.3608\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16810\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2733 - mean_squared_error: 0.2733 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16810 to 0.13882, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.2827 - mean_squared_error: 0.2827 - val_loss: 0.2154 - val_mean_squared_error: 0.2154\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.13882\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2767 - mean_squared_error: 0.2767 - val_loss: 0.1441 - val_mean_squared_error: 0.1441\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13882\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2668 - mean_squared_error: 0.2668 - val_loss: 0.1263 - val_mean_squared_error: 0.1263\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13882 to 0.12631, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_26\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2670 - mean_squared_error: 0.2670 - val_loss: 0.1936 - val_mean_squared_error: 0.1936\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12631\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2628 - mean_squared_error: 0.2628 - val_loss: 0.1577 - val_mean_squared_error: 0.1577\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12631\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2561 - mean_squared_error: 0.2561 - val_loss: 0.4562 - val_mean_squared_error: 0.4562\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12631\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2602 - mean_squared_error: 0.2602 - val_loss: 0.1247 - val_mean_squared_error: 0.1247\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12631 to 0.12468, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2486 - mean_squared_error: 0.2486 - val_loss: 0.1180 - val_mean_squared_error: 0.1180\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12468 to 0.11803, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_31\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2498 - mean_squared_error: 0.2498 - val_loss: 0.2156 - val_mean_squared_error: 0.2156\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11803\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2473 - mean_squared_error: 0.2473 - val_loss: 0.1473 - val_mean_squared_error: 0.1473\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11803\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2374 - mean_squared_error: 0.2374 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11803\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2337 - mean_squared_error: 0.2337 - val_loss: 0.3220 - val_mean_squared_error: 0.3220\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11803\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2370 - mean_squared_error: 0.2370 - val_loss: 0.3343 - val_mean_squared_error: 0.3343\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11803\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.2292 - mean_squared_error: 0.2292 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11803\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2254 - mean_squared_error: 0.2254 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11803\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2268 - mean_squared_error: 0.2268 - val_loss: 0.1953 - val_mean_squared_error: 0.1953\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11803\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2187 - mean_squared_error: 0.2187 - val_loss: 0.1851 - val_mean_squared_error: 0.1851\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11803\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2211 - mean_squared_error: 0.2211 - val_loss: 0.1486 - val_mean_squared_error: 0.1486\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11803\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2208 - mean_squared_error: 0.2208 - val_loss: 0.4211 - val_mean_squared_error: 0.4211\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11803\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2127 - mean_squared_error: 0.2127 - val_loss: 0.1518 - val_mean_squared_error: 0.1518\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11803\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2096 - mean_squared_error: 0.2096 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11803\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2098 - mean_squared_error: 0.2098 - val_loss: 0.4554 - val_mean_squared_error: 0.4554\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11803\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2106 - mean_squared_error: 0.2106 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11803 to 0.11772, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.2108 - mean_squared_error: 0.2108 - val_loss: 0.1655 - val_mean_squared_error: 0.1655\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11772\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 261s 43us/step - loss: 0.0807 - mean_squared_error: 0.0807 - val_loss: 0.0769 - val_mean_squared_error: 0.0769\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11772 to 0.07694, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_48\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 262s 43us/step - loss: 0.0754 - mean_squared_error: 0.0754 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.07694 to 0.07556, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 263s 43us/step - loss: 0.0724 - mean_squared_error: 0.0724 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.07556 to 0.07203, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_10_50\n",
      "11\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 2.1213 - mean_squared_error: 2.1213 - val_loss: 1.0714 - val_mean_squared_error: 1.0714\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.07140, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 1.0033 - mean_squared_error: 1.0033 - val_loss: 1.1589 - val_mean_squared_error: 1.1589\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.07140\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.7420 - mean_squared_error: 0.7420 - val_loss: 1.0646 - val_mean_squared_error: 1.0646\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.07140 to 1.06461, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.6355 - mean_squared_error: 0.6355 - val_loss: 0.8279 - val_mean_squared_error: 0.8279\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.06461 to 0.82786, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.5600 - mean_squared_error: 0.5600 - val_loss: 0.3954 - val_mean_squared_error: 0.3954\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82786 to 0.39537, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.5422 - mean_squared_error: 0.5422 - val_loss: 0.5939 - val_mean_squared_error: 0.5939\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39537\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.5073 - mean_squared_error: 0.5073 - val_loss: 0.9130 - val_mean_squared_error: 0.9130\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39537\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4774 - mean_squared_error: 0.4774 - val_loss: 0.4279 - val_mean_squared_error: 0.4279\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39537\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4564 - mean_squared_error: 0.4564 - val_loss: 0.2127 - val_mean_squared_error: 0.2127\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39537 to 0.21265, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4100 - mean_squared_error: 0.4100 - val_loss: 0.2316 - val_mean_squared_error: 0.2316\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21265\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4070 - mean_squared_error: 0.4070 - val_loss: 0.3442 - val_mean_squared_error: 0.3442\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21265\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3903 - mean_squared_error: 0.3903 - val_loss: 0.2389 - val_mean_squared_error: 0.2389\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.21265\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3892 - mean_squared_error: 0.3892 - val_loss: 0.3551 - val_mean_squared_error: 0.3551\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.21265\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3776 - mean_squared_error: 0.3776 - val_loss: 0.2084 - val_mean_squared_error: 0.2084\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.21265 to 0.20839, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3592 - mean_squared_error: 0.3592 - val_loss: 0.2437 - val_mean_squared_error: 0.2437\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20839\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3532 - mean_squared_error: 0.3532 - val_loss: 0.5021 - val_mean_squared_error: 0.5021\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20839\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3445 - mean_squared_error: 0.3445 - val_loss: 0.2739 - val_mean_squared_error: 0.2739\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20839\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3439 - mean_squared_error: 0.3439 - val_loss: 0.4810 - val_mean_squared_error: 0.4810\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20839\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.2202 - val_mean_squared_error: 0.2202\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20839\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3386 - mean_squared_error: 0.3386 - val_loss: 0.3036 - val_mean_squared_error: 0.3036\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20839\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.4703 - val_mean_squared_error: 0.4703\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20839\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3101 - val_mean_squared_error: 0.3101\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20839\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.1205 - mean_squared_error: 0.1205 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20839 to 0.13061, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1116 - mean_squared_error: 0.1116 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.13061 to 0.10876, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_24\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.1080 - mean_squared_error: 0.1080 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.10876 to 0.10615, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_25\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1054 - mean_squared_error: 0.1054 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10615\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1032 - mean_squared_error: 0.1032 - val_loss: 0.1129 - val_mean_squared_error: 0.1129\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10615\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.1014 - mean_squared_error: 0.1014 - val_loss: 0.0962 - val_mean_squared_error: 0.0962\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.10615 to 0.09618, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_28\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0993 - mean_squared_error: 0.0993 - val_loss: 0.0995 - val_mean_squared_error: 0.0995\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09618\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0976 - mean_squared_error: 0.0976 - val_loss: 0.0895 - val_mean_squared_error: 0.0895\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.09618 to 0.08947, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0954 - mean_squared_error: 0.0954 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08947\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0942 - mean_squared_error: 0.0942 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08947\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0895 - val_mean_squared_error: 0.0895\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08947\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0913 - mean_squared_error: 0.0913 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08947\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0904 - mean_squared_error: 0.0904 - val_loss: 0.0875 - val_mean_squared_error: 0.0875\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.08947 to 0.08747, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_35\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0889 - mean_squared_error: 0.0889 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08747 to 0.08599, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0886 - mean_squared_error: 0.0886 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08599\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0876 - mean_squared_error: 0.0876 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08599\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0876 - mean_squared_error: 0.0876 - val_loss: 0.0864 - val_mean_squared_error: 0.0864\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08599\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.0863 - mean_squared_error: 0.0863 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08599\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.0856 - mean_squared_error: 0.0856 - val_loss: 0.0956 - val_mean_squared_error: 0.0956\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08599\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0847 - mean_squared_error: 0.0847 - val_loss: 0.0819 - val_mean_squared_error: 0.0819\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08599 to 0.08194, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0839 - mean_squared_error: 0.0839 - val_loss: 0.0917 - val_mean_squared_error: 0.0917\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08194\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0833 - mean_squared_error: 0.0833 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08194\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.0826 - mean_squared_error: 0.0826 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08194 to 0.08155, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0817 - mean_squared_error: 0.0817 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08155 to 0.07909, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0807 - mean_squared_error: 0.0807 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07909\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0798 - mean_squared_error: 0.0798 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07909\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.0778 - mean_squared_error: 0.0778 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.07909 to 0.07659, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.0766 - mean_squared_error: 0.0766 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.07659 to 0.07588, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_11_50\n",
      "12\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 2.5498 - mean_squared_error: 2.5498 - val_loss: 1.6121 - val_mean_squared_error: 1.6121\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61213, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 1.2744 - mean_squared_error: 1.2744 - val_loss: 2.0129 - val_mean_squared_error: 2.0129\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61213\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.9034 - mean_squared_error: 0.9034 - val_loss: 0.7687 - val_mean_squared_error: 0.7687\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61213 to 0.76874, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.7465 - mean_squared_error: 0.7465 - val_loss: 0.9917 - val_mean_squared_error: 0.9917\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.76874\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.6497 - mean_squared_error: 0.6497 - val_loss: 0.4019 - val_mean_squared_error: 0.4019\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76874 to 0.40190, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.6078 - mean_squared_error: 0.6078 - val_loss: 0.4223 - val_mean_squared_error: 0.4223\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40190\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.5557 - mean_squared_error: 0.5557 - val_loss: 0.3841 - val_mean_squared_error: 0.3841\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40190 to 0.38408, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.5451 - mean_squared_error: 0.5451 - val_loss: 0.4806 - val_mean_squared_error: 0.4806\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38408\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.5076 - mean_squared_error: 0.5076 - val_loss: 0.3658 - val_mean_squared_error: 0.3658\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38408 to 0.36577, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4817 - mean_squared_error: 0.4817 - val_loss: 0.7337 - val_mean_squared_error: 0.7337\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36577\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.4796 - mean_squared_error: 0.4796 - val_loss: 0.2906 - val_mean_squared_error: 0.2906\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36577 to 0.29065, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.4525 - mean_squared_error: 0.4525 - val_loss: 0.4326 - val_mean_squared_error: 0.4326\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29065\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4324 - mean_squared_error: 0.4324 - val_loss: 0.4031 - val_mean_squared_error: 0.4031\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.29065\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.4193 - mean_squared_error: 0.4193 - val_loss: 0.4894 - val_mean_squared_error: 0.4894\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.29065\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.4127 - mean_squared_error: 0.4127 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29065\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3994 - mean_squared_error: 0.3994 - val_loss: 0.2202 - val_mean_squared_error: 0.2202\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.29065 to 0.22022, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_16\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3869 - mean_squared_error: 0.3869 - val_loss: 0.2575 - val_mean_squared_error: 0.2575\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.22022\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3639 - mean_squared_error: 0.3639 - val_loss: 0.2789 - val_mean_squared_error: 0.2789\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22022\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3623 - mean_squared_error: 0.3623 - val_loss: 0.3094 - val_mean_squared_error: 0.3094\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.22022\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3428 - mean_squared_error: 0.3428 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.22022\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3567 - mean_squared_error: 0.3567 - val_loss: 0.3078 - val_mean_squared_error: 0.3078\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.22022\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3438 - mean_squared_error: 0.3438 - val_loss: 0.3892 - val_mean_squared_error: 0.3892\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22022\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.3376 - mean_squared_error: 0.3376 - val_loss: 0.3385 - val_mean_squared_error: 0.3385\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.22022\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.3231 - val_mean_squared_error: 0.3231\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.22022\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 264s 43us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.2005 - val_mean_squared_error: 0.2005\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.22022 to 0.20049, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_25\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.2231 - val_mean_squared_error: 0.2231\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20049\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.3142 - mean_squared_error: 0.3142 - val_loss: 0.6398 - val_mean_squared_error: 0.6398\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20049\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3209 - mean_squared_error: 0.3209 - val_loss: 0.2796 - val_mean_squared_error: 0.2796\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20049\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3140 - mean_squared_error: 0.3140 - val_loss: 0.2225 - val_mean_squared_error: 0.2225\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20049\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.3072 - mean_squared_error: 0.3072 - val_loss: 0.1870 - val_mean_squared_error: 0.1870\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20049 to 0.18698, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2982 - mean_squared_error: 0.2982 - val_loss: 0.2013 - val_mean_squared_error: 0.2013\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.18698\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2993 - mean_squared_error: 0.2993 - val_loss: 0.2500 - val_mean_squared_error: 0.2500\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.18698\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2919 - mean_squared_error: 0.2919 - val_loss: 0.2036 - val_mean_squared_error: 0.2036\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.18698\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2948 - mean_squared_error: 0.2948 - val_loss: 0.2149 - val_mean_squared_error: 0.2149\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.18698\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2926 - mean_squared_error: 0.2926 - val_loss: 0.3227 - val_mean_squared_error: 0.3227\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18698\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2883 - mean_squared_error: 0.2883 - val_loss: 0.2011 - val_mean_squared_error: 0.2011\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.18698\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2694 - mean_squared_error: 0.2694 - val_loss: 0.1588 - val_mean_squared_error: 0.1588\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18698 to 0.15881, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2770 - mean_squared_error: 0.2770 - val_loss: 0.5957 - val_mean_squared_error: 0.5957\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15881\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2777 - mean_squared_error: 0.2777 - val_loss: 0.2708 - val_mean_squared_error: 0.2708\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15881\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2766 - mean_squared_error: 0.2766 - val_loss: 0.2392 - val_mean_squared_error: 0.2392\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15881\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.1177 - mean_squared_error: 0.1177 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15881 to 0.11257, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.1126 - mean_squared_error: 0.1126 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11257 to 0.11015, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1101 - mean_squared_error: 0.1101 - val_loss: 0.1065 - val_mean_squared_error: 0.1065\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.11015 to 0.10649, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_43\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.1078 - mean_squared_error: 0.1078 - val_loss: 0.1079 - val_mean_squared_error: 0.1079\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10649\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.1061 - mean_squared_error: 0.1061 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.10649 to 0.10485, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1048 - mean_squared_error: 0.1048 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.10485 to 0.10273, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1031 - mean_squared_error: 0.1031 - val_loss: 0.1019 - val_mean_squared_error: 0.1019\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.10273 to 0.10186, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_47\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 264s 44us/step - loss: 0.1016 - mean_squared_error: 0.1016 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10186\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.1006 - mean_squared_error: 0.1006 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10186\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.0993 - mean_squared_error: 0.0993 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10186 to 0.10179, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_12_50\n",
      "13\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 2.3711 - mean_squared_error: 2.3711 - val_loss: 0.6873 - val_mean_squared_error: 0.6873\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68726, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 1.0074 - mean_squared_error: 1.0074 - val_loss: 0.5246 - val_mean_squared_error: 0.5246\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68726 to 0.52455, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.7289 - mean_squared_error: 0.7289 - val_loss: 0.5096 - val_mean_squared_error: 0.5096\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52455 to 0.50958, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.6119 - mean_squared_error: 0.6119 - val_loss: 0.3585 - val_mean_squared_error: 0.3585\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50958 to 0.35854, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.5446 - mean_squared_error: 0.5446 - val_loss: 0.5291 - val_mean_squared_error: 0.5291\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35854\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.5199 - mean_squared_error: 0.5199 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35854\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.4612 - mean_squared_error: 0.4612 - val_loss: 0.2957 - val_mean_squared_error: 0.2957\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35854 to 0.29571, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.4368 - mean_squared_error: 0.4368 - val_loss: 0.3265 - val_mean_squared_error: 0.3265\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.29571\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.4204 - mean_squared_error: 0.4204 - val_loss: 2.6865 - val_mean_squared_error: 2.6865\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.29571\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3941 - mean_squared_error: 0.3941 - val_loss: 0.4094 - val_mean_squared_error: 0.4094\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.29571\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3717 - mean_squared_error: 0.3717 - val_loss: 0.6581 - val_mean_squared_error: 0.6581\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29571\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.2900 - val_mean_squared_error: 0.2900\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29571 to 0.29004, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3617 - mean_squared_error: 0.3617 - val_loss: 0.2475 - val_mean_squared_error: 0.2475\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29004 to 0.24750, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_13\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3394 - mean_squared_error: 0.3394 - val_loss: 0.2341 - val_mean_squared_error: 0.2341\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24750 to 0.23412, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.2707 - val_mean_squared_error: 0.2707\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.23412\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.23412\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.3738 - val_mean_squared_error: 0.3738\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23412\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3079 - mean_squared_error: 0.3079 - val_loss: 0.2137 - val_mean_squared_error: 0.2137\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23412 to 0.21373, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_18\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.3037 - mean_squared_error: 0.3037 - val_loss: 0.4105 - val_mean_squared_error: 0.4105\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.21373\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.2988 - mean_squared_error: 0.2988 - val_loss: 0.1809 - val_mean_squared_error: 0.1809\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21373 to 0.18091, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_20\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2995 - mean_squared_error: 0.2995 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.18091\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2910 - mean_squared_error: 0.2910 - val_loss: 0.1966 - val_mean_squared_error: 0.1966\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.18091\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2822 - mean_squared_error: 0.2822 - val_loss: 0.1688 - val_mean_squared_error: 0.1688\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.18091 to 0.16876, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_23\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2883 - mean_squared_error: 0.2883 - val_loss: 0.2096 - val_mean_squared_error: 0.2096\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16876\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2722 - mean_squared_error: 0.2722 - val_loss: 0.2305 - val_mean_squared_error: 0.2305\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16876\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2715 - mean_squared_error: 0.2715 - val_loss: 0.1572 - val_mean_squared_error: 0.1572\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16876 to 0.15721, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_26\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2593 - mean_squared_error: 0.2593 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15721\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2618 - mean_squared_error: 0.2618 - val_loss: 0.4908 - val_mean_squared_error: 0.4908\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15721\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2610 - mean_squared_error: 0.2610 - val_loss: 0.1567 - val_mean_squared_error: 0.1567\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15721 to 0.15670, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2577 - mean_squared_error: 0.2577 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15670\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2585 - mean_squared_error: 0.2585 - val_loss: 0.1783 - val_mean_squared_error: 0.1783\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15670\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2558 - mean_squared_error: 0.2558 - val_loss: 0.1815 - val_mean_squared_error: 0.1815\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15670\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2463 - mean_squared_error: 0.2463 - val_loss: 0.1875 - val_mean_squared_error: 0.1875\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15670\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 267s 44us/step - loss: 0.2393 - mean_squared_error: 0.2393 - val_loss: 0.2057 - val_mean_squared_error: 0.2057\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15670\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.2110 - val_mean_squared_error: 0.2110\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15670\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2356 - mean_squared_error: 0.2356 - val_loss: 0.2476 - val_mean_squared_error: 0.2476\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15670\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2377 - mean_squared_error: 0.2377 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15670 to 0.13118, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2365 - mean_squared_error: 0.2365 - val_loss: 0.1549 - val_mean_squared_error: 0.1549\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.13118\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2305 - mean_squared_error: 0.2305 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.13118\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2323 - mean_squared_error: 0.2323 - val_loss: 0.1684 - val_mean_squared_error: 0.1684\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13118\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2292 - mean_squared_error: 0.2292 - val_loss: 0.5882 - val_mean_squared_error: 0.5882\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.13118\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2222 - mean_squared_error: 0.2222 - val_loss: 0.2359 - val_mean_squared_error: 0.2359\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13118\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2221 - mean_squared_error: 0.2221 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.13118\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2164 - mean_squared_error: 0.2164 - val_loss: 0.1302 - val_mean_squared_error: 0.1302\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13118 to 0.13025, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_44\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 268s 44us/step - loss: 0.2124 - mean_squared_error: 0.2124 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.13025\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2128 - mean_squared_error: 0.2128 - val_loss: 0.8840 - val_mean_squared_error: 0.8840\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.13025\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2077 - mean_squared_error: 0.2077 - val_loss: 0.1682 - val_mean_squared_error: 0.1682\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.13025\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2105 - mean_squared_error: 0.2105 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13025 to 0.12287, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_48\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 266s 44us/step - loss: 0.2034 - mean_squared_error: 0.2034 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12287 to 0.11110, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_13_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 265s 44us/step - loss: 0.2050 - mean_squared_error: 0.2050 - val_loss: 0.2575 - val_mean_squared_error: 0.2575\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11110\n",
      "14\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 2.1854 - mean_squared_error: 2.1854 - val_loss: 1.0509 - val_mean_squared_error: 1.0509\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05094, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.9681 - mean_squared_error: 0.9681 - val_loss: 0.3774 - val_mean_squared_error: 0.3774\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05094 to 0.37742, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_02\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.7473 - mean_squared_error: 0.7473 - val_loss: 0.4344 - val_mean_squared_error: 0.4344\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37742\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.6526 - mean_squared_error: 0.6526 - val_loss: 0.2790 - val_mean_squared_error: 0.2790\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37742 to 0.27904, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.5792 - mean_squared_error: 0.5792 - val_loss: 0.3399 - val_mean_squared_error: 0.3399\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27904\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.5227 - mean_squared_error: 0.5227 - val_loss: 0.7969 - val_mean_squared_error: 0.7969\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27904\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.4798 - mean_squared_error: 0.4798 - val_loss: 0.4628 - val_mean_squared_error: 0.4628\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27904\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.4662 - mean_squared_error: 0.4662 - val_loss: 0.2702 - val_mean_squared_error: 0.2702\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27904 to 0.27017, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.4448 - mean_squared_error: 0.4448 - val_loss: 0.8150 - val_mean_squared_error: 0.8150\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27017\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.4131 - mean_squared_error: 0.4131 - val_loss: 0.3859 - val_mean_squared_error: 0.3859\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27017\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.4152 - mean_squared_error: 0.4152 - val_loss: 0.2293 - val_mean_squared_error: 0.2293\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27017 to 0.22932, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.3915 - mean_squared_error: 0.3915 - val_loss: 0.2593 - val_mean_squared_error: 0.2593\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.22932\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.3683 - mean_squared_error: 0.3683 - val_loss: 0.2270 - val_mean_squared_error: 0.2270\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.22932 to 0.22701, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_13\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.3629 - mean_squared_error: 0.3629 - val_loss: 0.2500 - val_mean_squared_error: 0.2500\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.22701\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.1821 - val_mean_squared_error: 0.1821\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.22701 to 0.18205, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_15\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.3703 - mean_squared_error: 0.3703 - val_loss: 0.2188 - val_mean_squared_error: 0.2188\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18205\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.3397 - mean_squared_error: 0.3397 - val_loss: 0.1749 - val_mean_squared_error: 0.1749\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.18205 to 0.17491, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.3526 - mean_squared_error: 0.3526 - val_loss: 0.1967 - val_mean_squared_error: 0.1967\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17491\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 269s 44us/step - loss: 0.3609 - mean_squared_error: 0.3609 - val_loss: 0.2574 - val_mean_squared_error: 0.2574\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17491\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.3574 - mean_squared_error: 0.3574 - val_loss: 0.7609 - val_mean_squared_error: 0.7609\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17491\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17491 to 0.12323, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_21\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.1175 - mean_squared_error: 0.1175 - val_loss: 0.1142 - val_mean_squared_error: 0.1142\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.12323 to 0.11424, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_22\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.1116 - mean_squared_error: 0.1116 - val_loss: 0.1096 - val_mean_squared_error: 0.1096\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11424 to 0.10956, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.1074 - mean_squared_error: 0.1074 - val_loss: 0.1044 - val_mean_squared_error: 0.1044\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.10956 to 0.10436, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_24\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.1039 - mean_squared_error: 0.1039 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10436\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.1013 - mean_squared_error: 0.1013 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.10436 to 0.09632, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_26\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0987 - mean_squared_error: 0.0987 - val_loss: 0.1259 - val_mean_squared_error: 0.1259\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09632\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0970 - mean_squared_error: 0.0970 - val_loss: 0.0984 - val_mean_squared_error: 0.0984\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09632\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0954 - mean_squared_error: 0.0954 - val_loss: 0.0951 - val_mean_squared_error: 0.0951\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.09632 to 0.09512, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_29\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0936 - mean_squared_error: 0.0936 - val_loss: 0.0889 - val_mean_squared_error: 0.0889\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.09512 to 0.08894, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0924 - mean_squared_error: 0.0924 - val_loss: 0.0946 - val_mean_squared_error: 0.0946\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08894\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08894\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0896 - mean_squared_error: 0.0896 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08894\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0886 - mean_squared_error: 0.0886 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08894\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0875 - mean_squared_error: 0.0875 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08894\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.0862 - mean_squared_error: 0.0862 - val_loss: 0.0862 - val_mean_squared_error: 0.0862\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08894 to 0.08621, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.0847 - mean_squared_error: 0.0847 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08621 to 0.08581, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0836 - mean_squared_error: 0.0836 - val_loss: 0.0879 - val_mean_squared_error: 0.0879\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08581\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0825 - mean_squared_error: 0.0825 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08581 to 0.07776, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_39\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 270s 44us/step - loss: 0.0812 - mean_squared_error: 0.0812 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07776\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.0804 - mean_squared_error: 0.0804 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07776 to 0.07237, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_41\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0796 - mean_squared_error: 0.0796 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07237\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0793 - mean_squared_error: 0.0793 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07237\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0788 - mean_squared_error: 0.0788 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07237\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0780 - mean_squared_error: 0.0780 - val_loss: 0.0763 - val_mean_squared_error: 0.0763\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07237\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0777 - mean_squared_error: 0.0777 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07237\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0765 - mean_squared_error: 0.0765 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07237\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0761 - mean_squared_error: 0.0761 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07237 to 0.07198, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_14_48\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0756 - mean_squared_error: 0.0756 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07198\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0753 - mean_squared_error: 0.0753 - val_loss: 0.0727 - val_mean_squared_error: 0.0727\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07198\n",
      "15\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 2.0745 - mean_squared_error: 2.0745 - val_loss: 0.6845 - val_mean_squared_error: 0.6845\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68451, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 1.0016 - mean_squared_error: 1.0016 - val_loss: 1.0929 - val_mean_squared_error: 1.0929\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.68451\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.7546 - mean_squared_error: 0.7546 - val_loss: 0.5124 - val_mean_squared_error: 0.5124\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68451 to 0.51244, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.6127 - mean_squared_error: 0.6127 - val_loss: 0.2884 - val_mean_squared_error: 0.2884\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51244 to 0.28844, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.5590 - mean_squared_error: 0.5590 - val_loss: 0.4076 - val_mean_squared_error: 0.4076\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28844\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.4911 - mean_squared_error: 0.4911 - val_loss: 0.4568 - val_mean_squared_error: 0.4568\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28844\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.4507 - mean_squared_error: 0.4507 - val_loss: 2.0079 - val_mean_squared_error: 2.0079\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28844\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.4315 - mean_squared_error: 0.4315 - val_loss: 0.2675 - val_mean_squared_error: 0.2675\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28844 to 0.26747, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_08\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.3993 - mean_squared_error: 0.3993 - val_loss: 0.2468 - val_mean_squared_error: 0.2468\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.26747 to 0.24682, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.2207 - val_mean_squared_error: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24682 to 0.22070, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_10\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.3682 - val_mean_squared_error: 0.3682\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22070\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.3397 - mean_squared_error: 0.3397 - val_loss: 0.1863 - val_mean_squared_error: 0.1863\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.22070 to 0.18630, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.3380 - mean_squared_error: 0.3380 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18630\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.3413 - mean_squared_error: 0.3413 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18630 to 0.14868, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_14\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.3344 - mean_squared_error: 0.3344 - val_loss: 0.1371 - val_mean_squared_error: 0.1371\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.14868 to 0.13708, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_15\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.2998 - mean_squared_error: 0.2998 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13708\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2979 - mean_squared_error: 0.2979 - val_loss: 0.6631 - val_mean_squared_error: 0.6631\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13708\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2923 - mean_squared_error: 0.2923 - val_loss: 0.1452 - val_mean_squared_error: 0.1452\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.13708\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2708 - mean_squared_error: 0.2708 - val_loss: 0.2715 - val_mean_squared_error: 0.2715\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13708\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2687 - mean_squared_error: 0.2687 - val_loss: 0.1848 - val_mean_squared_error: 0.1848\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13708\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2744 - mean_squared_error: 0.2744 - val_loss: 0.4272 - val_mean_squared_error: 0.4272\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.13708\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.2636 - mean_squared_error: 0.2636 - val_loss: 0.1347 - val_mean_squared_error: 0.1347\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.13708 to 0.13472, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_22\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2701 - mean_squared_error: 0.2701 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.13472 to 0.12904, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.2652 - mean_squared_error: 0.2652 - val_loss: 0.4213 - val_mean_squared_error: 0.4213\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12904\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2575 - mean_squared_error: 0.2575 - val_loss: 0.1730 - val_mean_squared_error: 0.1730\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12904\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2553 - mean_squared_error: 0.2553 - val_loss: 0.2356 - val_mean_squared_error: 0.2356\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12904\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2442 - mean_squared_error: 0.2442 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12904\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2544 - mean_squared_error: 0.2544 - val_loss: 0.1902 - val_mean_squared_error: 0.1902\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12904\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.2542 - mean_squared_error: 0.2542 - val_loss: 0.2650 - val_mean_squared_error: 0.2650\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12904\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 270s 45us/step - loss: 0.2600 - mean_squared_error: 0.2600 - val_loss: 0.2303 - val_mean_squared_error: 0.2303\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12904\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0806 - mean_squared_error: 0.0806 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12904 to 0.07193, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_31\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0727 - mean_squared_error: 0.0727 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.07193 to 0.07013, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_32\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0697 - mean_squared_error: 0.0697 - val_loss: 0.0757 - val_mean_squared_error: 0.0757\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07013\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0678 - mean_squared_error: 0.0678 - val_loss: 0.0659 - val_mean_squared_error: 0.0659\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.07013 to 0.06585, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_34\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.06585 to 0.06024, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_35\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0641 - mean_squared_error: 0.0641 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06024\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0627 - mean_squared_error: 0.0627 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.06024 to 0.05871, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0611 - mean_squared_error: 0.0611 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05871\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05871 to 0.05614, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_39\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 271s 45us/step - loss: 0.0589 - mean_squared_error: 0.0589 - val_loss: 0.0574 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05614\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0582 - mean_squared_error: 0.0582 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05614\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0570 - mean_squared_error: 0.0570 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.05614 to 0.05431, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0562 - mean_squared_error: 0.0562 - val_loss: 0.0713 - val_mean_squared_error: 0.0713\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05431\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0556 - mean_squared_error: 0.0556 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05431\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0550 - mean_squared_error: 0.0550 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05431 to 0.05286, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_45\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0545 - mean_squared_error: 0.0545 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05286 to 0.05119, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_15_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0542 - mean_squared_error: 0.0542 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05119\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0539 - mean_squared_error: 0.0539 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05119\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0534 - mean_squared_error: 0.0534 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05119\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0533 - mean_squared_error: 0.0533 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05119\n",
      "Epoch 00050: early stopping\n",
      "16\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 2.2682 - mean_squared_error: 2.2682 - val_loss: 1.3646 - val_mean_squared_error: 1.3646\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.36457, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 0.5028 - val_mean_squared_error: 0.5028\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36457 to 0.50280, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.8084 - mean_squared_error: 0.8084 - val_loss: 1.7677 - val_mean_squared_error: 1.7677\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50280\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.6974 - mean_squared_error: 0.6974 - val_loss: 0.2741 - val_mean_squared_error: 0.2741\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50280 to 0.27406, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_04\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.5569 - mean_squared_error: 0.5569 - val_loss: 0.2964 - val_mean_squared_error: 0.2964\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27406\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.5106 - mean_squared_error: 0.5106 - val_loss: 1.0508 - val_mean_squared_error: 1.0508\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27406\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4601 - mean_squared_error: 0.4601 - val_loss: 0.4154 - val_mean_squared_error: 0.4154\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27406\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4211 - mean_squared_error: 0.4211 - val_loss: 0.7178 - val_mean_squared_error: 0.7178\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27406\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4029 - mean_squared_error: 0.4029 - val_loss: 0.1932 - val_mean_squared_error: 0.1932\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27406 to 0.19316, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3752 - mean_squared_error: 0.3752 - val_loss: 1.5599 - val_mean_squared_error: 1.5599\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19316\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3663 - mean_squared_error: 0.3663 - val_loss: 0.1649 - val_mean_squared_error: 0.1649\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.19316 to 0.16492, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3567 - mean_squared_error: 0.3567 - val_loss: 0.1902 - val_mean_squared_error: 0.1902\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16492\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3650 - mean_squared_error: 0.3650 - val_loss: 1.2108 - val_mean_squared_error: 1.2108\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16492\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3602 - mean_squared_error: 0.3602 - val_loss: 0.5209 - val_mean_squared_error: 0.5209\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16492\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.2170 - val_mean_squared_error: 0.2170\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16492\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.1023 - mean_squared_error: 0.1023 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16492 to 0.10601, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_16\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0925 - mean_squared_error: 0.0925 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.10601 to 0.08845, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_17\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0891 - mean_squared_error: 0.0891 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08845 to 0.08839, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_18\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.0860 - mean_squared_error: 0.0860 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08839 to 0.07815, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_19\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07815\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0812 - mean_squared_error: 0.0812 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07815 to 0.07684, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_21\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0787 - mean_squared_error: 0.0787 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07684\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0767 - mean_squared_error: 0.0767 - val_loss: 0.0757 - val_mean_squared_error: 0.0757\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07684 to 0.07575, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_23\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0748 - mean_squared_error: 0.0748 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07575\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0737 - mean_squared_error: 0.0737 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07575 to 0.06653, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_25\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0729 - mean_squared_error: 0.0729 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06653\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0713 - mean_squared_error: 0.0713 - val_loss: 0.0672 - val_mean_squared_error: 0.0672\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06653\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0694 - mean_squared_error: 0.0694 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06653 to 0.06600, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_28\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0679 - mean_squared_error: 0.0679 - val_loss: 0.0604 - val_mean_squared_error: 0.0604\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06600 to 0.06041, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0667 - mean_squared_error: 0.0667 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06041 to 0.05874, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_30\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05874\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0645 - mean_squared_error: 0.0645 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05874 to 0.05835, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_32\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0637 - mean_squared_error: 0.0637 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05835\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0630 - mean_squared_error: 0.0630 - val_loss: 0.0725 - val_mean_squared_error: 0.0725\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05835\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05835 to 0.05782, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_35\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0616 - mean_squared_error: 0.0616 - val_loss: 0.0566 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.05782 to 0.05663, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0608 - mean_squared_error: 0.0608 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05663 to 0.05487, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0601 - mean_squared_error: 0.0601 - val_loss: 0.0608 - val_mean_squared_error: 0.0608\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05487\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0597 - mean_squared_error: 0.0597 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05487 to 0.05422, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_39\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05422\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0585 - mean_squared_error: 0.0585 - val_loss: 0.0559 - val_mean_squared_error: 0.0559\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05422\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0578 - mean_squared_error: 0.0578 - val_loss: 0.0559 - val_mean_squared_error: 0.0559\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05422\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0571 - mean_squared_error: 0.0571 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05422\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0570 - mean_squared_error: 0.0570 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.05422 to 0.05073, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_44\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0577 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05073\n",
      "Epoch 46/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05073\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0558 - mean_squared_error: 0.0558 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05073\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0555 - mean_squared_error: 0.0555 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05073\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0549 - mean_squared_error: 0.0549 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05073\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05073 to 0.04943, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_16_50\n",
      "17\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 2.3083 - mean_squared_error: 2.3083 - val_loss: 2.0306 - val_mean_squared_error: 2.0306\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.03065, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.9964 - mean_squared_error: 0.9964 - val_loss: 0.3676 - val_mean_squared_error: 0.3676\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.03065 to 0.36758, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.7635 - mean_squared_error: 0.7635 - val_loss: 1.1647 - val_mean_squared_error: 1.1647\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36758\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.6420 - mean_squared_error: 0.6420 - val_loss: 0.5599 - val_mean_squared_error: 0.5599\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36758\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.5851 - mean_squared_error: 0.5851 - val_loss: 0.3164 - val_mean_squared_error: 0.3164\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36758 to 0.31637, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.5250 - mean_squared_error: 0.5250 - val_loss: 0.4962 - val_mean_squared_error: 0.4962\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31637\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4894 - mean_squared_error: 0.4894 - val_loss: 0.2408 - val_mean_squared_error: 0.2408\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31637 to 0.24079, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_07\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4418 - mean_squared_error: 0.4418 - val_loss: 0.2889 - val_mean_squared_error: 0.2889\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24079\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.4086 - mean_squared_error: 0.4086 - val_loss: 0.2029 - val_mean_squared_error: 0.2029\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24079 to 0.20292, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_09\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3840 - mean_squared_error: 0.3840 - val_loss: 0.4319 - val_mean_squared_error: 0.4319\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20292\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3757 - mean_squared_error: 0.3757 - val_loss: 0.1971 - val_mean_squared_error: 0.1971\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20292 to 0.19715, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3590 - mean_squared_error: 0.3590 - val_loss: 0.4297 - val_mean_squared_error: 0.4297\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19715\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 272s 45us/step - loss: 0.3354 - mean_squared_error: 0.3354 - val_loss: 0.1624 - val_mean_squared_error: 0.1624\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.19715 to 0.16245, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_13\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 273s 45us/step - loss: 0.3182 - mean_squared_error: 0.3182 - val_loss: 0.2751 - val_mean_squared_error: 0.2751\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16245\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.3063 - mean_squared_error: 0.3063 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16245 to 0.12317, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_15\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2970 - mean_squared_error: 0.2970 - val_loss: 0.6857 - val_mean_squared_error: 0.6857\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12317\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2974 - mean_squared_error: 0.2974 - val_loss: 0.6058 - val_mean_squared_error: 0.6058\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12317\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2897 - mean_squared_error: 0.2897 - val_loss: 0.2497 - val_mean_squared_error: 0.2497\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12317\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2837 - mean_squared_error: 0.2837 - val_loss: 0.1606 - val_mean_squared_error: 0.1606\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.12317\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.2744 - mean_squared_error: 0.2744 - val_loss: 0.4134 - val_mean_squared_error: 0.4134\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12317\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.2678 - mean_squared_error: 0.2678 - val_loss: 0.2658 - val_mean_squared_error: 0.2658\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.12317\n",
      "Epoch 22/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2812 - mean_squared_error: 0.2812 - val_loss: 0.6375 - val_mean_squared_error: 0.6375\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.12317\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2637 - mean_squared_error: 0.2637 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.12317\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2621 - mean_squared_error: 0.2621 - val_loss: 0.1796 - val_mean_squared_error: 0.1796\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12317\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2505 - mean_squared_error: 0.2505 - val_loss: 0.6075 - val_mean_squared_error: 0.6075\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12317\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2570 - mean_squared_error: 0.2570 - val_loss: 0.2822 - val_mean_squared_error: 0.2822\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12317\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2553 - mean_squared_error: 0.2553 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12317\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2501 - mean_squared_error: 0.2501 - val_loss: 0.1615 - val_mean_squared_error: 0.1615\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12317\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2371 - mean_squared_error: 0.2371 - val_loss: 0.0975 - val_mean_squared_error: 0.0975\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.12317 to 0.09747, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_29\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.2487 - mean_squared_error: 0.2487 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09747\n",
      "Epoch 31/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.2477 - mean_squared_error: 0.2477 - val_loss: 0.1401 - val_mean_squared_error: 0.1401\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.09747\n",
      "Epoch 32/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.1424 - val_mean_squared_error: 0.1424\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09747\n",
      "Epoch 33/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0777 - mean_squared_error: 0.0777 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09747 to 0.07458, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_33\n",
      "Epoch 34/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.0728 - mean_squared_error: 0.0728 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07458\n",
      "Epoch 35/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0704 - mean_squared_error: 0.0704 - val_loss: 0.0709 - val_mean_squared_error: 0.0709\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.07458 to 0.07088, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_35\n",
      "Epoch 36/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.0685 - mean_squared_error: 0.0685 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07088 to 0.06420, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_36\n",
      "Epoch 37/50\n",
      "6069260/6069260 [==============================] - 276s 45us/step - loss: 0.0659 - mean_squared_error: 0.0659 - val_loss: 0.0611 - val_mean_squared_error: 0.0611\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.06420 to 0.06106, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_37\n",
      "Epoch 38/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0643 - mean_squared_error: 0.0643 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06106\n",
      "Epoch 39/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0627 - mean_squared_error: 0.0627 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.06106 to 0.05882, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_39\n",
      "Epoch 40/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05882 to 0.05835, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_40\n",
      "Epoch 41/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0592 - mean_squared_error: 0.0592 - val_loss: 0.0623 - val_mean_squared_error: 0.0623\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05835\n",
      "Epoch 42/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.05835 to 0.05429, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_42\n",
      "Epoch 43/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0570 - mean_squared_error: 0.0570 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05429\n",
      "Epoch 44/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.05429 to 0.05389, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_44\n",
      "Epoch 45/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0556 - mean_squared_error: 0.0556 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05389 to 0.05290, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_45\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0550 - mean_squared_error: 0.0550 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05290 to 0.05150, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_46\n",
      "Epoch 47/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0542 - mean_squared_error: 0.0542 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05150\n",
      "Epoch 48/50\n",
      "6069260/6069260 [==============================] - 274s 45us/step - loss: 0.0537 - mean_squared_error: 0.0537 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05150\n",
      "Epoch 49/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0533 - mean_squared_error: 0.0533 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.05150 to 0.05033, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_49\n",
      "Epoch 50/50\n",
      "6069260/6069260 [==============================] - 275s 45us/step - loss: 0.0527 - mean_squared_error: 0.0527 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05033 to 0.04909, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_17_50\n",
      "18\n",
      "batch_size:  1000\n",
      "layers:  [10, 50, 50, 50]\n",
      "hidden_activations: ['relu', 'relu', 'relu', 'relu']\n",
      "l1_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "l2_kernel:  [0.0, 0.0, 0.0, 0.0]\n",
      "Train on 6069260 samples, validate on 1518747 samples\n",
      "Epoch 1/50\n",
      "6069260/6069260 [==============================] - 279s 46us/step - loss: 2.0486 - mean_squared_error: 2.0486 - val_loss: 1.5292 - val_mean_squared_error: 1.5292\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52916, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_01\n",
      "Epoch 2/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 1.0044 - mean_squared_error: 1.0044 - val_loss: 1.0282 - val_mean_squared_error: 1.0282\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52916 to 1.02821, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_02\n",
      "Epoch 3/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.7370 - mean_squared_error: 0.7370 - val_loss: 0.3583 - val_mean_squared_error: 0.3583\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02821 to 0.35828, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_03\n",
      "Epoch 4/50\n",
      "6069260/6069260 [==============================] - 278s 46us/step - loss: 0.5954 - mean_squared_error: 0.5954 - val_loss: 0.9774 - val_mean_squared_error: 0.9774\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35828\n",
      "Epoch 5/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.5258 - mean_squared_error: 0.5258 - val_loss: 0.2955 - val_mean_squared_error: 0.2955\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35828 to 0.29545, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_05\n",
      "Epoch 6/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.4848 - mean_squared_error: 0.4848 - val_loss: 0.5822 - val_mean_squared_error: 0.5822\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29545\n",
      "Epoch 7/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.4565 - mean_squared_error: 0.4565 - val_loss: 0.5884 - val_mean_squared_error: 0.5884\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29545\n",
      "Epoch 8/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.4264 - mean_squared_error: 0.4264 - val_loss: 0.2559 - val_mean_squared_error: 0.2559\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29545 to 0.25593, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_08\n",
      "Epoch 9/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.4131 - mean_squared_error: 0.4131 - val_loss: 0.2802 - val_mean_squared_error: 0.2802\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25593\n",
      "Epoch 10/50\n",
      "6069260/6069260 [==============================] - 276s 46us/step - loss: 0.3862 - mean_squared_error: 0.3862 - val_loss: 0.6134 - val_mean_squared_error: 0.6134\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25593\n",
      "Epoch 11/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.2475 - val_mean_squared_error: 0.2475\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.25593 to 0.24754, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_11\n",
      "Epoch 12/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3747 - mean_squared_error: 0.3747 - val_loss: 0.2154 - val_mean_squared_error: 0.2154\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24754 to 0.21536, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_12\n",
      "Epoch 13/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3468 - mean_squared_error: 0.3468 - val_loss: 0.1718 - val_mean_squared_error: 0.1718\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21536 to 0.17184, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_13\n",
      "Epoch 14/50\n",
      "6069260/6069260 [==============================] - 276s 46us/step - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.2405 - val_mean_squared_error: 0.2405\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17184\n",
      "Epoch 15/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3365 - mean_squared_error: 0.3365 - val_loss: 0.3010 - val_mean_squared_error: 0.3010\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17184\n",
      "Epoch 16/50\n",
      "6069260/6069260 [==============================] - 277s 46us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.1528 - val_mean_squared_error: 0.1528\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17184 to 0.15283, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_16\n",
      "Epoch 17/50\n",
      "6069260/6069260 [==============================] - 285s 47us/step - loss: 0.3151 - mean_squared_error: 0.3151 - val_loss: 0.1746 - val_mean_squared_error: 0.1746\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15283\n",
      "Epoch 18/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.3153 - mean_squared_error: 0.3153 - val_loss: 0.8904 - val_mean_squared_error: 0.8904\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15283\n",
      "Epoch 19/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.3043 - mean_squared_error: 0.3043 - val_loss: 0.1825 - val_mean_squared_error: 0.1825\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15283\n",
      "Epoch 20/50\n",
      "6069260/6069260 [==============================] - 222s 37us/step - loss: 0.2911 - mean_squared_error: 0.2911 - val_loss: 0.2224 - val_mean_squared_error: 0.2224\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15283\n",
      "Epoch 21/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.2884 - mean_squared_error: 0.2884 - val_loss: 0.3444 - val_mean_squared_error: 0.3444\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15283\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.2808 - mean_squared_error: 0.2808 - val_loss: 0.1591 - val_mean_squared_error: 0.1591\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15283\n",
      "Epoch 23/50\n",
      "6069260/6069260 [==============================] - 222s 37us/step - loss: 0.2769 - mean_squared_error: 0.2769 - val_loss: 0.1797 - val_mean_squared_error: 0.1797\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15283\n",
      "Epoch 24/50\n",
      "6069260/6069260 [==============================] - 224s 37us/step - loss: 0.2756 - mean_squared_error: 0.2756 - val_loss: 0.1542 - val_mean_squared_error: 0.1542\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15283\n",
      "Epoch 25/50\n",
      "6069260/6069260 [==============================] - 224s 37us/step - loss: 0.2726 - mean_squared_error: 0.2726 - val_loss: 0.3023 - val_mean_squared_error: 0.3023\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15283\n",
      "Epoch 26/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.2641 - mean_squared_error: 0.2641 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15283\n",
      "Epoch 27/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.2573 - mean_squared_error: 0.2573 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15283\n",
      "Epoch 28/50\n",
      "6069260/6069260 [==============================] - 223s 37us/step - loss: 0.2588 - mean_squared_error: 0.2588 - val_loss: 0.3490 - val_mean_squared_error: 0.3490\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15283\n",
      "Epoch 29/50\n",
      "6069260/6069260 [==============================] - 222s 37us/step - loss: 0.2504 - mean_squared_error: 0.2504 - val_loss: 0.1584 - val_mean_squared_error: 0.1584\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15283\n",
      "Epoch 30/50\n",
      "6069260/6069260 [==============================] - 215s 35us/step - loss: 0.2511 - mean_squared_error: 0.2511 - val_loss: 0.1466 - val_mean_squared_error: 0.1466\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15283 to 0.14665, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_post_stability_experiment_choice_rt_09_19_18_23_17_40/ckpt_18_30\n",
      "Epoch 31/50\n",
      "2120192/6069260 [=========>....................] - ETA: 2:54 - loss: 0.2544 - mean_squared_error: 0.2544"
     ]
    }
   ],
   "source": [
    "# Hyperparameter training loop:\n",
    "\n",
    "# Runs: \n",
    "num_runs = 20\n",
    "cnt = 0\n",
    "max_layers = 5\n",
    "layer_sizes = [10, 50, 60]\n",
    "batch_sizes = [1000, 1000]\n",
    "regularization_sizes = [0.0, 0.0]\n",
    "\n",
    "# Update model directory to make sure we collect all our models from this hyperparameter optimization run in the same place\n",
    "cpm.data_params['model_directory'] =  '/home/afengler/git_repos/nn_likelihoods/keras_models/'\n",
    "cpm.data_params['model_name'] = 'dnnregressor_wftp_hyp_opt_post_stability_experiment'\n",
    "cpm.train_params['model_cnt'] = 0\n",
    "\n",
    "histories = []\n",
    "\n",
    "while cnt < num_runs:\n",
    "    cnt += 1\n",
    "    \n",
    "    # Sample # layers \n",
    "    #num_layers = np.random.choice(np.arange(4, max_layers + 1, 1))\n",
    "    num_layers = 4\n",
    "    # Layer sizes\n",
    "    layers = [10, 50, 50, 50]\n",
    "    activations = ['relu', 'relu', 'relu', 'relu']\n",
    "    regularizers_l1 = [0.0, 0.0, 0.0, 0.0]\n",
    "    regularizers_l2 = [0.0, 0.0, 0.0, 0.0]\n",
    "    regularizer = np.random.choice(['l1', 'l2', 'none'])\n",
    "    regularizer_size = np.random.choice(regularization_sizes)\n",
    "    \n",
    "#     for i in range(0, num_layers, 1):\n",
    "#         layers.append(np.random.choice(layer_sizes))\n",
    "#         activations.append('relu')\n",
    "#         if regularizer == 'l1':\n",
    "#             regularizers_l1.append(regularizer_size)\n",
    "#             regularizers_l2.append(0.0)\n",
    "#         if regularizer == 'l2':\n",
    "#             regularizers_l1.append(0.0)\n",
    "#             regularizers_l2.append(regularizer_size)\n",
    "#         else:\n",
    "#             regularizers_l1.append(0.0)\n",
    "#             regularizers_l2.append(0.0)\n",
    "        \n",
    "    # Batch size\n",
    "    batch_size = np.random.choice(batch_sizes)\n",
    "    \n",
    "    # Update relevant model parameters\n",
    "    cpm.train_params['batch_size'] = batch_size\n",
    "    print('batch_size: ', batch_size)\n",
    "    cpm.model_params['hidden_layers'] = layers\n",
    "    print('layers: ', layers)\n",
    "    cpm.model_params['hidden_activations'] = activations\n",
    "    print('hidden_activations:', activations)\n",
    "#     cpm.model_params['l1_activation'] = regularizers_l1\n",
    "#     print('l1_activatons: ', regularizers_l1)\n",
    "#     cpm.model_params['l2_activation'] = regularizers\n",
    "#     print('l2_activations:', regularizers_l2)\n",
    "    cpm.model_params['l1_kernel'] = regularizers_l1\n",
    "    print('l1_kernel: ', regularizers_l1)\n",
    "    cpm.model_params['l2_kernel'] = regularizers_l2\n",
    "    print('l2_kernel: ', regularizers_l2)\n",
    "    \n",
    "    # Make new timestamp\n",
    "    #cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "    \n",
    "    # Make model\n",
    "    cpm.keras_model_generate(save_model = True)\n",
    "    \n",
    "    # Train model\n",
    "    cpm.run_training(save_history = True, \n",
    "                     warm_start = False) # Note that this increments model count automatically !\n",
    "    \n",
    "#     histories[-1]['model_cnt'] = cpm.train_params['model_cnt']\n",
    "#     histories[-1]['num_layers'] = num_layers\n",
    "#     histories[-1]['size_layers'] = str(layers)\n",
    "#     histories[-1]['activations'] = str(activations) \n",
    "#     histories[-1]['batch_size'] = batch_size\n",
    "    \n",
    "    print(cnt)\n",
    "    \n",
    "# histories = pd.concat(histories)\n",
    "# histories['optimizer'] = cpm.model_params['optimizer']\n",
    "# histories['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "# histories.to_csv(cpm.data_params['model_directory'] + cpm.data_params['model_name'] + '_choice_rt_' +\\\n",
    "#                  cpm.data_params['timestamp'] + '/hyp_opt_histories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
