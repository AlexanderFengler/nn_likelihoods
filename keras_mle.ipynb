{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "import make_data_wfpt as mdw\n",
    "from kde_training_utilities import kde_load_data\n",
    "import ddm_data_simulation as ddm_sim\n",
    "import boundary_functions as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7747126415252714600\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14333018260300978518\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 12048773940\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10136970403330521425\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16824059044018370692\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Handle some cuda business\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f83a46e7128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_path = '/media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/model_0' \n",
    "ckpt_path = '/media/data_cifs/afengler/data/kde/linear_collapse/keras_models/dnnregressor_ddm_linear_collapse_06_22_19_23_27_28/ckpt_0_130'\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "model.load_weights(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 20)                160       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 60)                2460      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 80)                4880      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               8100      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 120)               12120     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 28,681\n",
      "Trainable params: 28,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations -----\n",
    "n_runs = 300\n",
    "n_samples = 2500\n",
    "\n",
    "\n",
    "# NOTE PARAMETERS: WEIBULL: [v, a, w, node, shape, scale]\n",
    "param_bounds = [(-2.5, 2.5), (0.5, 4), (0.15, 0.85), (0, 5), (1.01, 49), (0.01, 9.9)]\n",
    "\n",
    "\n",
    "my_optim_columns = ['v_sim', 'a_sim', 'w_sim', 'node_sim', 'shape_sim', 'scale_sim',\n",
    "                    'v_mle', 'a_mle', 'w_mle', 'node_mle', 'shape_mle', 'scale_mle', 'n_samples']\n",
    "\n",
    "# Get parameter names in correct ordering:\n",
    "dat = pickle.load(open('/home/afengler/git_repos/nn_likelihoods/data_storage/kde/weibull/train_test_data/test_features.pickle' , \n",
    "                       'rb'))\n",
    "\n",
    "parameter_names = list(dat.keys())[:-2] # :-1 to get rid of 'rt' and 'choice' here\n",
    "\n",
    "# Make columns for optimizer result table\n",
    "p_sim = []\n",
    "p_mle = []\n",
    "\n",
    "for parameter_name in parameter_names:\n",
    "    p_sim.append(parameter_name + '_sim')\n",
    "    p_mle.append(parameter_name + '_mle')\n",
    "    \n",
    "my_optim_columns = p_sim + p_mle + ['n_samples']\n",
    "\n",
    "# Initialize the data frame in which to store optimizer results\n",
    "optim_results = pd.DataFrame(np.zeros((n_runs, len(my_optim_columns))), columns = my_optim_columns)\n",
    "optim_results.iloc[:, 2 * len(parameter_names)] = n_samples\n",
    "\n",
    "# define boundary\n",
    "boundary = bf.weibull_bnd\n",
    "boundary_multiplicative = False\n",
    "\n",
    "# Define the likelihood function\n",
    "def log_p(params = [0, 1, 0.9], model = [], data = [], parameter_names = []):\n",
    "    # Make feature array\n",
    "    feature_array = np.zeros((data[0].shape[0], len(parameter_names) + 2))\n",
    "    \n",
    "    # Store parameters\n",
    "    cnt = 0\n",
    "    for i in range(0, len(parameter_names), 1):\n",
    "        feature_array[:, i] = params[i]\n",
    "        cnt += 1\n",
    "    \n",
    "    # Store rts and choices\n",
    "    feature_array[:, cnt] = data[0].ravel() # rts\n",
    "    feature_array[:, cnt + 1] = data[1].ravel() # choices\n",
    "    \n",
    "    # Get model predictions\n",
    "    prediction = model.predict(feature_array)\n",
    "    \n",
    "    # Some post-processing of predictions\n",
    "    prediction[prediction < 1e-29] = 1e-29\n",
    "    \n",
    "    return(- np.sum(np.log(prediction)))  \n",
    "\n",
    "def make_params(param_bounds = []):\n",
    "    params = np.zeros(len(param_bounds))\n",
    "    \n",
    "    for i in range(len(params)):\n",
    "        params[i] = np.random.uniform(low = param_bounds[i][0], high = param_bounds[i][1])\n",
    "        \n",
    "    return\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop ----------- TD: Parallelize\n",
    "for i in range(0, n_runs, 1): \n",
    "    \n",
    "    # Get start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "#     # Sample parameters\n",
    "#     v_sim = np.random.uniform(high = v_range[1], low = v_range[0])\n",
    "#     a_sim = np.random.uniform(high = a_range[1], low = a_range[0])\n",
    "#     w_sim = np.random.uniform(high = w_range[1], low = w_range[0])\n",
    "\n",
    "#     #c1_sim = np.random.uniform(high = c1_range[1], low = c1_range[0])\n",
    "#     #c2_sim = np.random.uniform(high = c2_range[1], low = c2_range[0])\n",
    "#     node_sim = np.random.uniform(high = node_range[1], low = node_range[0])\n",
    "#     shape_sim = np.random.uniform(high = shape_range[1], low = shape_range[0])\n",
    "#     scale_sim = np.random.uniform(high = scale_range[1], low = scale_range[0])\n",
    "\n",
    "    tmp_params = make_params(param_bounds = param_bounds)\n",
    "    \n",
    "    # Store in output file\n",
    "    optim_results.iloc[i, :len(parameter_names)] = tmp_params\n",
    "    \n",
    "    # Print some info on run\n",
    "    print('Parameters for run ' + str(i) + ': ')\n",
    "    print([v_sim, a_sim, w_sim, node_sim, shape_sim, scale_sim])\n",
    "    \n",
    "    # Run model simulations\n",
    "    ddm_dat_tmp = ddm_sim.ddm_flexbound_simulate(v = tmp_params[0],\n",
    "                                                 a = tmp_params[1],\n",
    "                                                 w = tmp_params[2],\n",
    "                                                 s = 1,\n",
    "                                                 delta_t = 0.001,\n",
    "                                                 max_t = 20,\n",
    "                                                 n_samples = n_samples,\n",
    "                                                 boundary_fun = boundary, # function of t (and potentially other parameters) that takes in (t, *args)\n",
    "                                                 boundary_multiplicative = boundary_multiplicative, # CAREFUL: CHECK IF BOUND\n",
    "                                                 boundary_params = {'node': tmp_params[3], \n",
    "                                                                    'shape': tmp_params[4],\n",
    "                                                                    'scale': tmp_params[5]})\n",
    "        \n",
    "    # Print some info on run\n",
    "    print('Mean rt for current run: ')\n",
    "    print(np.mean(ddm_dat_tmp[0]))\n",
    "    \n",
    "    # Run optimizer\n",
    "    out = differential_evolution(log_p, \n",
    "                                 bounds = [(v_range[0],v_range[1]), \n",
    "                                           (a_range[0], a_range[1]), \n",
    "                                           (w_range[0], w_range[1]),\n",
    "                                           (node_range[0], node_range[1]),\n",
    "                                           (shape_range[0], shape_range[1]),\n",
    "                                           (scale_range[0], scale_range[1])], \n",
    "                                 args = (model, ddm_dat_tmp, parameter_names), \n",
    "                                 popsize = 30,\n",
    "                                 disp = True)\n",
    "    \n",
    "    # Print some info\n",
    "    print('Solution vector of current run: ')\n",
    "    print(out.x)\n",
    "    \n",
    "    print('The run took: ')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    # Store result in output file\n",
    "    optim_results.iloc[i, len(parameter_names):(2*len(parameter_names))] = out.x\n",
    "# -----------------------\n",
    "\n",
    "# Save optimization results to file\n",
    "optim_results.to_csv(os.getcwd() + '/experiments/kde_ddm_weibull_mle/optim_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in results\n",
    "optim_results = pd.read_csv(os.getcwd() + '/experiments/ddm_flexbound_kde_mle_fix_v_0_c1_0_w_unbiased_arange_2_3/optim_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['v_sim'], optim_results['v_mle'], c = optim_results['c2_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for v\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['v_mle'], 1), np.expand_dims(optim_results['v_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['v_mle'], 1), np.expand_dims(optim_results['v_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['a_sim'], optim_results['a_mle'], c = optim_results['c2_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for a\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['a_mle'], 1), np.expand_dims(optim_results['a_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['a_mle'], 1), np.expand_dims(optim_results['a_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['w_sim'], optim_results['w_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for w\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['w_mle'], 1), np.expand_dims(optim_results['w_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['w_mle'], 1), np.expand_dims(optim_results['w_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['c1_sim'], optim_results['c1_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for c1\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['c1_mle'], 1), np.expand_dims(optim_results['c1_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['c1_mle'], 1), np.expand_dims(optim_results['c1_sim'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(optim_results['c2_sim'], optim_results['c2_mle'], c = optim_results['a_mle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for w\n",
    "reg = LinearRegression().fit(np.expand_dims(optim_results['c2_mle'], 1), np.expand_dims(optim_results['c2_sim'], 1))\n",
    "reg.score(np.expand_dims(optim_results['c2_mle'], 1), np.expand_dims(optim_results['c2_sim'], 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
