{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "from datetime import datetime\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(os.getcwd() + '/data_storage/data_11000000_from_simulation_mix_09_12_18_18_20_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some cleaning of the data\n",
    "data = data[['v', 'a', 'w', 'rt', 'choice', 'nf_likelihood']]\n",
    "data = data.loc[data['w'] > 0.1]\n",
    "data = data.loc[data['w'] < 0.9]\n",
    "data = data.loc[data['a'] > 0.5]\n",
    "\n",
    "mini_data = data.loc[1:10000]\n",
    "\n",
    "\n",
    "train_f, train_l, test_f, test_l = mdw.train_test_split_rt_choice(data = data,\n",
    "                                                                  write_to_file = False,\n",
    "                                                                  from_file = False,\n",
    "                                                                  p_train = 0.8,\n",
    "                                                                  backend = 'keras')\n",
    "# Choice probabilities\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_choice_probabilities(n_samples = 2500000,\n",
    "#                                                             f_signature = '_choice_probabilities_analytic_',\n",
    "#                                                                                 backend = 'keras')\n",
    "\n",
    "# rt_choice\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_rt_choice(n_samples = 11000000,\n",
    "#                                                                       f_signature = '_from_simulation_mix_',\n",
    "#                                                                       backend = 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "cpm.data['train_features'] = train_f\n",
    "cpm.data['train_labels'] = train_l\n",
    "cpm.data['test_features'] = test_f\n",
    "cpm.data['test_labels'] = test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 3,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'sigmoid',\n",
       " 'hidden_layers': [20, 20, 20, 20],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 2000,\n",
       " 'batch_size': 10000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'choice_probabilities',\n",
       " 'model_directory': '/home/afengler/git_repos/nn_likelihoods/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_choice_probabilities_analytic_',\n",
       " 'timestamp': '09_13_18_23_31_32',\n",
       " 'training_data_size': 2500000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFYING META PARAMETERS THAT STAY CONSTANT DURING HYPERPARAMETER OPTIMIZATION\n",
    "\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['input_shape'] = 5\n",
    "\n",
    "# Training params\n",
    "# Meta\n",
    "cpm.train_params['early_stopping_patience'] = 5\n",
    "cpm.train_params['plateau_patience'] = 3\n",
    "cpm.train_params['min_delta'] = 0.5\n",
    "cpm.train_params['ckpt_period'] = 1\n",
    "cpm.train_params['model_cnt'] = 0\n",
    "cpm.train_params['max_train_epochs'] = 100\n",
    "\n",
    "# Hyper\n",
    "#cpm.train_params['l1_kernel']\n",
    "cpm.model_params['hidden_layers'] = [5, 5, 5, 5]\n",
    "#cpm.train_params['hidden_activations']\n",
    "#cpm.train_params['l2_kernel'] = [0.5, 0.5, 0.5, 0.5]\n",
    "#cpm.train_params['l2_activation'] = [0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'wfpt'\n",
    "cpm.data_params['data_type_signature'] = '_choice_rt_'\n",
    "cpm.data_params['training_data_size'] = 1000\n",
    "\n",
    "# Update timestamp\n",
    "cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "cpm.run_training(save_history = True, \n",
    "                 warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 212s 35us/step - loss: 2.0044 - mean_squared_error: 2.0044 - val_loss: 1.7722 - val_mean_squared_error: 1.7722\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77221, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-0-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 210s 35us/step - loss: 0.8980 - mean_squared_error: 0.8980 - val_loss: 0.9448 - val_mean_squared_error: 0.9448\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.77221 to 0.94485, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-0-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 208s 34us/step - loss: 0.6857 - mean_squared_error: 0.6857 - val_loss: 1.0925 - val_mean_squared_error: 1.0925\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.94485\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 208s 34us/step - loss: 0.5742 - mean_squared_error: 0.5742 - val_loss: 0.3374 - val_mean_squared_error: 0.3374\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.94485 to 0.33742, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-0-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 210s 35us/step - loss: 0.5013 - mean_squared_error: 0.5013 - val_loss: 0.2915 - val_mean_squared_error: 0.2915\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33742 to 0.29146, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-0-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 210s 35us/step - loss: 0.4594 - mean_squared_error: 0.4594 - val_loss: 0.6323 - val_mean_squared_error: 0.6323\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29146\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 212s 35us/step - loss: 0.4203 - mean_squared_error: 0.4203 - val_loss: 0.3115 - val_mean_squared_error: 0.3115\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29146\n",
      "Epoch 00007: early stopping\n",
      "1\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 186s 31us/step - loss: 2.4920 - mean_squared_error: 2.4920 - val_loss: 1.1971 - val_mean_squared_error: 1.1971\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.19711, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-1-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 185s 30us/step - loss: 1.1382 - mean_squared_error: 1.1382 - val_loss: 0.8335 - val_mean_squared_error: 0.8335\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.19711 to 0.83345, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-1-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 185s 30us/step - loss: 0.9671 - mean_squared_error: 0.9671 - val_loss: 0.7491 - val_mean_squared_error: 0.7491\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83345 to 0.74911, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-1-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 187s 31us/step - loss: 0.8645 - mean_squared_error: 0.8645 - val_loss: 0.6190 - val_mean_squared_error: 0.6190\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74911 to 0.61900, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-1-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 186s 31us/step - loss: 0.7807 - mean_squared_error: 0.7807 - val_loss: 0.7627 - val_mean_squared_error: 0.7627\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.61900\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 186s 31us/step - loss: 0.7204 - mean_squared_error: 0.7204 - val_loss: 0.8225 - val_mean_squared_error: 0.8225\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61900\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 187s 31us/step - loss: 0.6626 - mean_squared_error: 0.6626 - val_loss: 0.8677 - val_mean_squared_error: 0.8677\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61900\n",
      "Epoch 00007: early stopping\n",
      "2\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 187s 31us/step - loss: 2.3004 - mean_squared_error: 2.3004 - val_loss: 2.3317 - val_mean_squared_error: 2.3317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.33169, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 187s 31us/step - loss: 1.2889 - mean_squared_error: 1.2889 - val_loss: 0.6967 - val_mean_squared_error: 0.6967\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.33169 to 0.69670, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 188s 31us/step - loss: 0.9183 - mean_squared_error: 0.9183 - val_loss: 0.5023 - val_mean_squared_error: 0.5023\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69670 to 0.50227, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 0.6881 - mean_squared_error: 0.6881 - val_loss: 0.4870 - val_mean_squared_error: 0.4870\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50227 to 0.48705, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 0.5952 - mean_squared_error: 0.5952 - val_loss: 0.5141 - val_mean_squared_error: 0.5141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48705\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 0.5466 - mean_squared_error: 0.5466 - val_loss: 0.4379 - val_mean_squared_error: 0.4379\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48705 to 0.43795, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 188s 31us/step - loss: 0.5061 - mean_squared_error: 0.5061 - val_loss: 0.7511 - val_mean_squared_error: 0.7511\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.43795\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 187s 31us/step - loss: 0.4763 - mean_squared_error: 0.4763 - val_loss: 0.8458 - val_mean_squared_error: 0.8458\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43795\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 188s 31us/step - loss: 0.4490 - mean_squared_error: 0.4490 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43795 to 0.35764, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-2-09\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 188s 31us/step - loss: 2.4623 - mean_squared_error: 2.4623 - val_loss: 1.6336 - val_mean_squared_error: 1.6336\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63361, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 1.1518 - mean_squared_error: 1.1518 - val_loss: 1.1429 - val_mean_squared_error: 1.1429\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63361 to 1.14292, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-02\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 191s 32us/step - loss: 0.8954 - mean_squared_error: 0.8954 - val_loss: 0.5073 - val_mean_squared_error: 0.5073\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.14292 to 0.50727, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 0.7376 - mean_squared_error: 0.7376 - val_loss: 0.4809 - val_mean_squared_error: 0.4809\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50727 to 0.48091, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 0.6399 - mean_squared_error: 0.6399 - val_loss: 0.5370 - val_mean_squared_error: 0.5370\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48091\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 0.5652 - mean_squared_error: 0.5652 - val_loss: 0.6521 - val_mean_squared_error: 0.6521\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48091\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 191s 31us/step - loss: 0.5433 - mean_squared_error: 0.5433 - val_loss: 0.3419 - val_mean_squared_error: 0.3419\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48091 to 0.34192, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 0.5051 - mean_squared_error: 0.5051 - val_loss: 0.4602 - val_mean_squared_error: 0.4602\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34192\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 0.4661 - mean_squared_error: 0.4661 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34192 to 0.32207, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-3-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 0.4534 - mean_squared_error: 0.4534 - val_loss: 0.3635 - val_mean_squared_error: 0.3635\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32207\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 7.9797 - mean_squared_error: 7.9797 - val_loss: 6.0695 - val_mean_squared_error: 6.0695\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.06951, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 173s 28us/step - loss: 5.3984 - mean_squared_error: 5.3984 - val_loss: 4.9780 - val_mean_squared_error: 4.9780\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.06951 to 4.97798, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 174s 29us/step - loss: 4.6671 - mean_squared_error: 4.6671 - val_loss: 4.4690 - val_mean_squared_error: 4.4690\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.97798 to 4.46897, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 4.2569 - mean_squared_error: 4.2569 - val_loss: 4.2584 - val_mean_squared_error: 4.2584\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.46897 to 4.25836, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 173s 29us/step - loss: 3.9885 - mean_squared_error: 3.9885 - val_loss: 3.7764 - val_mean_squared_error: 3.7764\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.25836 to 3.77643, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 170s 28us/step - loss: 3.7895 - mean_squared_error: 3.7895 - val_loss: 3.6300 - val_mean_squared_error: 3.6300\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.77643 to 3.62998, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 3.6259 - mean_squared_error: 3.6259 - val_loss: 3.7327 - val_mean_squared_error: 3.7327\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.62998\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 171s 28us/step - loss: 3.4841 - mean_squared_error: 3.4841 - val_loss: 3.2903 - val_mean_squared_error: 3.2903\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.62998 to 3.29032, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 3.3783 - mean_squared_error: 3.3783 - val_loss: 3.1451 - val_mean_squared_error: 3.1451\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.29032 to 3.14510, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 3.2853 - mean_squared_error: 3.2853 - val_loss: 3.2275 - val_mean_squared_error: 3.2275\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.14510\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 169s 28us/step - loss: 3.2192 - mean_squared_error: 3.2192 - val_loss: 3.0936 - val_mean_squared_error: 3.0936\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.14510 to 3.09364, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-11\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 171s 28us/step - loss: 3.1397 - mean_squared_error: 3.1397 - val_loss: 3.0140 - val_mean_squared_error: 3.0140\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.09364 to 3.01404, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-12\n",
      "Epoch 13/100\n",
      "6069924/6069924 [==============================] - 172s 28us/step - loss: 3.0831 - mean_squared_error: 3.0831 - val_loss: 2.8625 - val_mean_squared_error: 2.8625\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.01404 to 2.86251, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-4-13\n",
      "Epoch 00013: early stopping\n",
      "5\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 2.1989 - mean_squared_error: 2.1989 - val_loss: 0.8938 - val_mean_squared_error: 0.8938\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89384, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 1.0606 - mean_squared_error: 1.0606 - val_loss: 0.4923 - val_mean_squared_error: 0.4923\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.89384 to 0.49234, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 0.8505 - mean_squared_error: 0.8505 - val_loss: 3.2101 - val_mean_squared_error: 3.2101\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49234\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 0.7268 - mean_squared_error: 0.7268 - val_loss: 0.4386 - val_mean_squared_error: 0.4386\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49234 to 0.43864, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-04\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 0.6279 - mean_squared_error: 0.6279 - val_loss: 0.4346 - val_mean_squared_error: 0.4346\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43864 to 0.43456, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 0.5673 - mean_squared_error: 0.5673 - val_loss: 0.5105 - val_mean_squared_error: 0.5105\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.43456\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 0.5364 - mean_squared_error: 0.5364 - val_loss: 1.0254 - val_mean_squared_error: 1.0254\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.43456\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 0.4815 - mean_squared_error: 0.4815 - val_loss: 0.6707 - val_mean_squared_error: 0.6707\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43456\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 213s 35us/step - loss: 0.4418 - mean_squared_error: 0.4418 - val_loss: 0.2888 - val_mean_squared_error: 0.2888\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43456 to 0.28878, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 0.4259 - mean_squared_error: 0.4259 - val_loss: 0.2839 - val_mean_squared_error: 0.2839\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.28878 to 0.28387, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-10\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.2120 - val_mean_squared_error: 0.2120\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28387 to 0.21199, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-11\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 220s 36us/step - loss: 0.3694 - mean_squared_error: 0.3694 - val_loss: 0.2032 - val_mean_squared_error: 0.2032\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21199 to 0.20316, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-5-12\n",
      "Epoch 00012: early stopping\n",
      "6\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 2.3796 - mean_squared_error: 2.3796 - val_loss: 0.9992 - val_mean_squared_error: 0.9992\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99923, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.9793 - mean_squared_error: 0.9793 - val_loss: 0.6473 - val_mean_squared_error: 0.6473\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99923 to 0.64734, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 197s 32us/step - loss: 0.7056 - mean_squared_error: 0.7056 - val_loss: 0.4311 - val_mean_squared_error: 0.4311\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64734 to 0.43108, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.5743 - mean_squared_error: 0.5743 - val_loss: 0.4653 - val_mean_squared_error: 0.4653\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43108\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 194s 32us/step - loss: 0.5105 - mean_squared_error: 0.5105 - val_loss: 1.0707 - val_mean_squared_error: 1.0707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43108\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.4604 - mean_squared_error: 0.4604 - val_loss: 0.2277 - val_mean_squared_error: 0.2277\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43108 to 0.22767, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 0.4276 - mean_squared_error: 0.4276 - val_loss: 0.1896 - val_mean_squared_error: 0.1896\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.22767 to 0.18956, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 0.3983 - mean_squared_error: 0.3983 - val_loss: 0.2331 - val_mean_squared_error: 0.2331\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18956\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.1695 - val_mean_squared_error: 0.1695\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18956 to 0.16945, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-6-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 0.3508 - mean_squared_error: 0.3508 - val_loss: 0.5119 - val_mean_squared_error: 0.5119\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16945\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 194s 32us/step - loss: 0.3393 - mean_squared_error: 0.3393 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16945\n",
      "Epoch 00011: early stopping\n",
      "7\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 2.2490 - mean_squared_error: 2.2490 - val_loss: 0.6721 - val_mean_squared_error: 0.6721\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67206, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-7-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 0.8850 - mean_squared_error: 0.8850 - val_loss: 1.3184 - val_mean_squared_error: 1.3184\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67206\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 194s 32us/step - loss: 0.6686 - mean_squared_error: 0.6686 - val_loss: 0.3394 - val_mean_squared_error: 0.3394\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67206 to 0.33935, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-7-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 0.5753 - mean_squared_error: 0.5753 - val_loss: 0.3970 - val_mean_squared_error: 0.3970\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33935\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.5097 - mean_squared_error: 0.5097 - val_loss: 0.4618 - val_mean_squared_error: 0.4618\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33935\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 196s 32us/step - loss: 0.4699 - mean_squared_error: 0.4699 - val_loss: 0.2688 - val_mean_squared_error: 0.2688\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33935 to 0.26876, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-7-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 197s 32us/step - loss: 0.4346 - mean_squared_error: 0.4346 - val_loss: 0.2514 - val_mean_squared_error: 0.2514\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26876 to 0.25145, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-7-07\n",
      "Epoch 00007: early stopping\n",
      "8\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 177s 29us/step - loss: 13.2674 - mean_squared_error: 13.2674 - val_loss: 11.7539 - val_mean_squared_error: 11.7539\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11.75393, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 175s 29us/step - loss: 11.2858 - mean_squared_error: 11.2858 - val_loss: 10.9039 - val_mean_squared_error: 10.9039\n",
      "\n",
      "Epoch 00002: val_loss improved from 11.75393 to 10.90393, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 178s 29us/step - loss: 10.6642 - mean_squared_error: 10.6642 - val_loss: 10.5056 - val_mean_squared_error: 10.5056\n",
      "\n",
      "Epoch 00003: val_loss improved from 10.90393 to 10.50559, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 175s 29us/step - loss: 10.2803 - mean_squared_error: 10.2803 - val_loss: 10.2119 - val_mean_squared_error: 10.2119\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.50559 to 10.21189, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 178s 29us/step - loss: 10.0003 - mean_squared_error: 10.0003 - val_loss: 10.0319 - val_mean_squared_error: 10.0319\n",
      "\n",
      "Epoch 00005: val_loss improved from 10.21189 to 10.03189, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 179s 29us/step - loss: 9.7762 - mean_squared_error: 9.7762 - val_loss: 9.7701 - val_mean_squared_error: 9.7701\n",
      "\n",
      "Epoch 00006: val_loss improved from 10.03189 to 9.77013, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 178s 29us/step - loss: 9.5936 - mean_squared_error: 9.5936 - val_loss: 9.5683 - val_mean_squared_error: 9.5683\n",
      "\n",
      "Epoch 00007: val_loss improved from 9.77013 to 9.56827, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 177s 29us/step - loss: 9.4396 - mean_squared_error: 9.4396 - val_loss: 9.3293 - val_mean_squared_error: 9.3293\n",
      "\n",
      "Epoch 00008: val_loss improved from 9.56827 to 9.32928, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 174s 29us/step - loss: 9.3023 - mean_squared_error: 9.3023 - val_loss: 9.2283 - val_mean_squared_error: 9.2283\n",
      "\n",
      "Epoch 00009: val_loss improved from 9.32928 to 9.22826, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 175s 29us/step - loss: 9.1896 - mean_squared_error: 9.1896 - val_loss: 9.2913 - val_mean_squared_error: 9.2913\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 9.22826\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 175s 29us/step - loss: 9.0828 - mean_squared_error: 9.0828 - val_loss: 9.0199 - val_mean_squared_error: 9.0199\n",
      "\n",
      "Epoch 00011: val_loss improved from 9.22826 to 9.01993, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-11\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 177s 29us/step - loss: 8.9920 - mean_squared_error: 8.9920 - val_loss: 9.1175 - val_mean_squared_error: 9.1175\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 9.01993\n",
      "Epoch 13/100\n",
      "6069924/6069924 [==============================] - 175s 29us/step - loss: 8.9133 - mean_squared_error: 8.9133 - val_loss: 8.7774 - val_mean_squared_error: 8.7774\n",
      "\n",
      "Epoch 00013: val_loss improved from 9.01993 to 8.77736, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-13\n",
      "Epoch 14/100\n",
      "6069924/6069924 [==============================] - 179s 29us/step - loss: 8.8337 - mean_squared_error: 8.8337 - val_loss: 8.7640 - val_mean_squared_error: 8.7640\n",
      "\n",
      "Epoch 00014: val_loss improved from 8.77736 to 8.76403, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-14\n",
      "Epoch 15/100\n",
      "6069924/6069924 [==============================] - 177s 29us/step - loss: 8.7689 - mean_squared_error: 8.7689 - val_loss: 8.6632 - val_mean_squared_error: 8.6632\n",
      "\n",
      "Epoch 00015: val_loss improved from 8.76403 to 8.66321, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-15\n",
      "Epoch 16/100\n",
      "6069924/6069924 [==============================] - 173s 29us/step - loss: 8.7039 - mean_squared_error: 8.7039 - val_loss: 8.6060 - val_mean_squared_error: 8.6060\n",
      "\n",
      "Epoch 00016: val_loss improved from 8.66321 to 8.60602, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-16\n",
      "Epoch 17/100\n",
      "6069924/6069924 [==============================] - 173s 29us/step - loss: 8.6394 - mean_squared_error: 8.6394 - val_loss: 8.8705 - val_mean_squared_error: 8.8705\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 8.60602\n",
      "Epoch 18/100\n",
      "6069924/6069924 [==============================] - 177s 29us/step - loss: 8.5860 - mean_squared_error: 8.5860 - val_loss: 8.5824 - val_mean_squared_error: 8.5824\n",
      "\n",
      "Epoch 00018: val_loss improved from 8.60602 to 8.58242, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-8-18\n",
      "Epoch 00018: early stopping\n",
      "9\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 2.1558 - mean_squared_error: 2.1558 - val_loss: 0.7276 - val_mean_squared_error: 0.7276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72763, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 0.7050 - val_mean_squared_error: 0.7050\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.72763 to 0.70500, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 0.7759 - mean_squared_error: 0.7759 - val_loss: 0.3609 - val_mean_squared_error: 0.3609\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70500 to 0.36085, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 0.6266 - mean_squared_error: 0.6266 - val_loss: 1.8939 - val_mean_squared_error: 1.8939\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36085\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 0.5527 - mean_squared_error: 0.5527 - val_loss: 0.3229 - val_mean_squared_error: 0.3229\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36085 to 0.32287, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-05\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 0.4968 - mean_squared_error: 0.4968 - val_loss: 0.6599 - val_mean_squared_error: 0.6599\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32287\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 0.4468 - mean_squared_error: 0.4468 - val_loss: 0.4022 - val_mean_squared_error: 0.4022\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32287\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 0.4512 - mean_squared_error: 0.4512 - val_loss: 0.3174 - val_mean_squared_error: 0.3174\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32287 to 0.31742, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 0.4219 - mean_squared_error: 0.4219 - val_loss: 0.5762 - val_mean_squared_error: 0.5762\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31742\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 0.3987 - mean_squared_error: 0.3987 - val_loss: 0.2034 - val_mean_squared_error: 0.2034\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31742 to 0.20341, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-9-10\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 220s 36us/step - loss: 0.3922 - mean_squared_error: 0.3922 - val_loss: 0.2946 - val_mean_squared_error: 0.2946\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20341\n",
      "Epoch 00011: early stopping\n",
      "10\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 226s 37us/step - loss: 1.9735 - mean_squared_error: 1.9735 - val_loss: 0.9213 - val_mean_squared_error: 0.9213\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92130, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-10-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 0.8882 - mean_squared_error: 0.8882 - val_loss: 0.9531 - val_mean_squared_error: 0.9531\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.92130\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 0.6631 - mean_squared_error: 0.6631 - val_loss: 0.4984 - val_mean_squared_error: 0.4984\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.92130 to 0.49842, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-10-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 0.5717 - mean_squared_error: 0.5717 - val_loss: 0.5172 - val_mean_squared_error: 0.5172\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49842\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 224s 37us/step - loss: 0.4856 - mean_squared_error: 0.4856 - val_loss: 0.4714 - val_mean_squared_error: 0.4714\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49842 to 0.47138, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-10-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 225s 37us/step - loss: 0.4263 - mean_squared_error: 0.4263 - val_loss: 0.3048 - val_mean_squared_error: 0.3048\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47138 to 0.30477, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-10-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 224s 37us/step - loss: 0.4002 - mean_squared_error: 0.4002 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30477 to 0.22224, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-10-07\n",
      "Epoch 00007: early stopping\n",
      "11\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 243s 40us/step - loss: 2.3392 - mean_squared_error: 2.3392 - val_loss: 0.7309 - val_mean_squared_error: 0.7309\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73087, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-11-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 247s 41us/step - loss: 1.2048 - mean_squared_error: 1.2048 - val_loss: 1.0882 - val_mean_squared_error: 1.0882\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.73087\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 246s 41us/step - loss: 0.9254 - mean_squared_error: 0.9254 - val_loss: 0.4730 - val_mean_squared_error: 0.4730\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73087 to 0.47302, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-11-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 249s 41us/step - loss: 0.7937 - mean_squared_error: 0.7937 - val_loss: 0.7476 - val_mean_squared_error: 0.7476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47302\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 247s 41us/step - loss: 0.6687 - mean_squared_error: 0.6687 - val_loss: 0.7570 - val_mean_squared_error: 0.7570\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47302\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 247s 41us/step - loss: 0.5935 - mean_squared_error: 0.5935 - val_loss: 0.9248 - val_mean_squared_error: 0.9248\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47302\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 245s 40us/step - loss: 0.5584 - mean_squared_error: 0.5584 - val_loss: 0.3999 - val_mean_squared_error: 0.3999\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47302 to 0.39992, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-11-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 245s 40us/step - loss: 0.5171 - mean_squared_error: 0.5171 - val_loss: 0.5807 - val_mean_squared_error: 0.5807\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39992\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 244s 40us/step - loss: 0.4781 - mean_squared_error: 0.4781 - val_loss: 0.5607 - val_mean_squared_error: 0.5607\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39992\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 246s 41us/step - loss: 0.4413 - mean_squared_error: 0.4413 - val_loss: 0.5386 - val_mean_squared_error: 0.5386\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39992\n",
      "Epoch 00010: early stopping\n",
      "12\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 252s 42us/step - loss: 2.1872 - mean_squared_error: 2.1872 - val_loss: 1.8744 - val_mean_squared_error: 1.8744\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.87444, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-12-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 252s 41us/step - loss: 0.9865 - mean_squared_error: 0.9865 - val_loss: 5.2620 - val_mean_squared_error: 5.2620\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.87444\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 251s 41us/step - loss: 0.7544 - mean_squared_error: 0.7544 - val_loss: 1.6606 - val_mean_squared_error: 1.6606\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.87444 to 1.66055, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-12-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 254s 42us/step - loss: 0.6191 - mean_squared_error: 0.6191 - val_loss: 0.7924 - val_mean_squared_error: 0.7924\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.66055 to 0.79243, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-12-04\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 251s 41us/step - loss: 0.5146 - mean_squared_error: 0.5146 - val_loss: 0.2863 - val_mean_squared_error: 0.2863\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79243 to 0.28629, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-12-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 252s 41us/step - loss: 0.4790 - mean_squared_error: 0.4790 - val_loss: 1.8966 - val_mean_squared_error: 1.8966\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28629\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.4347 - mean_squared_error: 0.4347 - val_loss: 0.2966 - val_mean_squared_error: 0.2966s - loss: 0.4364 - mean_squared_error - ETA: 2s - los\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28629\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 253s 42us/step - loss: 0.4112 - mean_squared_error: 0.4112 - val_loss: 0.3953 - val_mean_squared_error: 0.3953\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28629\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 253s 42us/step - loss: 0.3963 - mean_squared_error: 0.3963 - val_loss: 0.2700 - val_mean_squared_error: 0.2700\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28629 to 0.27004, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-12-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 252s 42us/step - loss: 0.3730 - mean_squared_error: 0.3730 - val_loss: 0.2876 - val_mean_squared_error: 0.2876\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27004\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 252s 41us/step - loss: 0.3574 - mean_squared_error: 0.3574 - val_loss: 1.6809 - val_mean_squared_error: 1.6809\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27004\n",
      "Epoch 00011: early stopping\n",
      "13\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 207s 34us/step - loss: 2.1926 - mean_squared_error: 2.1926 - val_loss: 0.9483 - val_mean_squared_error: 0.9483\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94833, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-13-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 208s 34us/step - loss: 1.1710 - mean_squared_error: 1.1710 - val_loss: 0.6989 - val_mean_squared_error: 0.6989\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94833 to 0.69890, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-13-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 204s 34us/step - loss: 0.9683 - mean_squared_error: 0.9683 - val_loss: 0.6160 - val_mean_squared_error: 0.6160\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69890 to 0.61598, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-13-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 207s 34us/step - loss: 0.8396 - mean_squared_error: 0.8396 - val_loss: 0.7329 - val_mean_squared_error: 0.7329\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.61598\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 205s 34us/step - loss: 0.7634 - mean_squared_error: 0.7634 - val_loss: 0.6512 - val_mean_squared_error: 0.6512\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.61598\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 206s 34us/step - loss: 0.6934 - mean_squared_error: 0.6934 - val_loss: 0.5252 - val_mean_squared_error: 0.5252\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.61598 to 0.52521, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-13-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 208s 34us/step - loss: 0.6344 - mean_squared_error: 0.6344 - val_loss: 0.6593 - val_mean_squared_error: 0.6593\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52521\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 206s 34us/step - loss: 0.6052 - mean_squared_error: 0.6052 - val_loss: 0.6195 - val_mean_squared_error: 0.6195\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52521\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 207s 34us/step - loss: 0.5721 - mean_squared_error: 0.5721 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52521 to 0.39744, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-13-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 207s 34us/step - loss: 0.5439 - mean_squared_error: 0.5439 - val_loss: 0.5078 - val_mean_squared_error: 0.5078\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39744\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 202s 33us/step - loss: 0.5281 - mean_squared_error: 0.5281 - val_loss: 0.4358 - val_mean_squared_error: 0.4358\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.39744\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 206s 34us/step - loss: 0.5080 - mean_squared_error: 0.5080 - val_loss: 0.4058 - val_mean_squared_error: 0.4058\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39744\n",
      "Epoch 00012: early stopping\n",
      "14\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 254s 42us/step - loss: 2.0434 - mean_squared_error: 2.0434 - val_loss: 0.6818 - val_mean_squared_error: 0.6818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68181, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-14-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 256s 42us/step - loss: 0.9361 - mean_squared_error: 0.9361 - val_loss: 0.3439 - val_mean_squared_error: 0.3439\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68181 to 0.34392, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-14-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.7342 - mean_squared_error: 0.7342 - val_loss: 0.3686 - val_mean_squared_error: 0.3686\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34392\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 253s 42us/step - loss: 0.6482 - mean_squared_error: 0.6482 - val_loss: 0.9050 - val_mean_squared_error: 0.9050\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34392\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 256s 42us/step - loss: 0.5477 - mean_squared_error: 0.5477 - val_loss: 0.2873 - val_mean_squared_error: 0.2873\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34392 to 0.28732, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-14-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 256s 42us/step - loss: 0.5026 - mean_squared_error: 0.5026 - val_loss: 1.1788 - val_mean_squared_error: 1.1788\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28732\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 258s 42us/step - loss: 0.4721 - mean_squared_error: 0.4721 - val_loss: 0.3392 - val_mean_squared_error: 0.3392\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28732\n",
      "Epoch 00007: early stopping\n",
      "15\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 2.3270 - mean_squared_error: 2.3270 - val_loss: 1.3752 - val_mean_squared_error: 1.3752\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37521, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 256s 42us/step - loss: 1.1294 - mean_squared_error: 1.1294 - val_loss: 1.2928 - val_mean_squared_error: 1.2928\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37521 to 1.29284, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-02\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 256s 42us/step - loss: 0.8463 - mean_squared_error: 0.8463 - val_loss: 0.5994 - val_mean_squared_error: 0.5994\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29284 to 0.59938, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.7041 - mean_squared_error: 0.7041 - val_loss: 0.6059 - val_mean_squared_error: 0.6059\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59938\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.6283 - mean_squared_error: 0.6283 - val_loss: 0.4625 - val_mean_squared_error: 0.4625\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59938 to 0.46252, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.5470 - mean_squared_error: 0.5470 - val_loss: 0.4416 - val_mean_squared_error: 0.4416\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46252 to 0.44159, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 254s 42us/step - loss: 0.4836 - mean_squared_error: 0.4836 - val_loss: 0.3262 - val_mean_squared_error: 0.3262\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44159 to 0.32619, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.4693 - mean_squared_error: 0.4693 - val_loss: 0.2628 - val_mean_squared_error: 0.2628\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32619 to 0.26284, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-15-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 255s 42us/step - loss: 0.4273 - mean_squared_error: 0.4273 - val_loss: 0.2920 - val_mean_squared_error: 0.2920\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26284\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 253s 42us/step - loss: 0.4031 - mean_squared_error: 0.4031 - val_loss: 0.3113 - val_mean_squared_error: 0.3113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26284\n",
      "Epoch 00010: early stopping\n",
      "16\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 231s 38us/step - loss: 2.3909 - mean_squared_error: 2.3909 - val_loss: 1.0750 - val_mean_squared_error: 1.0750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.07502, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-16-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 229s 38us/step - loss: 1.2768 - mean_squared_error: 1.2768 - val_loss: 0.6363 - val_mean_squared_error: 0.6363\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.07502 to 0.63630, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-16-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 228s 38us/step - loss: 1.0052 - mean_squared_error: 1.0052 - val_loss: 0.8908 - val_mean_squared_error: 0.8908\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63630\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 230s 38us/step - loss: 0.8748 - mean_squared_error: 0.8748 - val_loss: 0.5213 - val_mean_squared_error: 0.5213\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63630 to 0.52129, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-16-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 231s 38us/step - loss: 0.7758 - mean_squared_error: 0.7758 - val_loss: 0.7525 - val_mean_squared_error: 0.7525\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52129\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 231s 38us/step - loss: 0.7105 - mean_squared_error: 0.7105 - val_loss: 0.5745 - val_mean_squared_error: 0.5745\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52129\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 232s 38us/step - loss: 0.6467 - mean_squared_error: 0.6467 - val_loss: 0.3886 - val_mean_squared_error: 0.3886\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52129 to 0.38857, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-16-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 232s 38us/step - loss: 0.6054 - mean_squared_error: 0.6054 - val_loss: 0.8356 - val_mean_squared_error: 0.8356\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38857\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 232s 38us/step - loss: 0.5742 - mean_squared_error: 0.5742 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38857 to 0.36179, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-16-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 230s 38us/step - loss: 0.5552 - mean_squared_error: 0.5552 - val_loss: 0.3888 - val_mean_squared_error: 0.3888\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36179\n",
      "Epoch 00010: early stopping\n",
      "17\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 7.8488 - mean_squared_error: 7.8488 - val_loss: 6.0749 - val_mean_squared_error: 6.0749\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.07490, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 5.1935 - mean_squared_error: 5.1935 - val_loss: 4.8635 - val_mean_squared_error: 4.8635\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.07490 to 4.86353, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 4.4560 - mean_squared_error: 4.4560 - val_loss: 4.0153 - val_mean_squared_error: 4.0153\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.86353 to 4.01527, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 191s 31us/step - loss: 4.0368 - mean_squared_error: 4.0368 - val_loss: 3.8159 - val_mean_squared_error: 3.8159\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.01527 to 3.81589, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 3.7598 - mean_squared_error: 3.7598 - val_loss: 3.6441 - val_mean_squared_error: 3.6441\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.81589 to 3.64407, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 3.5545 - mean_squared_error: 3.5545 - val_loss: 3.5942 - val_mean_squared_error: 3.5942\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.64407 to 3.59418, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 3.3956 - mean_squared_error: 3.3956 - val_loss: 3.1475 - val_mean_squared_error: 3.1475\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.59418 to 3.14747, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-07\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 191s 31us/step - loss: 3.2692 - mean_squared_error: 3.2692 - val_loss: 2.9441 - val_mean_squared_error: 2.9441\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.14747 to 2.94414, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 3.1663 - mean_squared_error: 3.1663 - val_loss: 3.0627 - val_mean_squared_error: 3.0627\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.94414\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 3.0741 - mean_squared_error: 3.0741 - val_loss: 3.1583 - val_mean_squared_error: 3.1583\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.94414\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 190s 31us/step - loss: 2.9990 - mean_squared_error: 2.9990 - val_loss: 2.7836 - val_mean_squared_error: 2.7836\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.94414 to 2.78363, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-11\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 2.9303 - mean_squared_error: 2.9303 - val_loss: 2.7280 - val_mean_squared_error: 2.7280\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.78363 to 2.72796, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-17-12\n",
      "Epoch 13/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 2.8627 - mean_squared_error: 2.8627 - val_loss: 2.7610 - val_mean_squared_error: 2.7610\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.72796\n",
      "Epoch 14/100\n",
      "6069924/6069924 [==============================] - 189s 31us/step - loss: 2.8007 - mean_squared_error: 2.8007 - val_loss: 2.8476 - val_mean_squared_error: 2.8476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.72796\n",
      "Epoch 00014: early stopping\n",
      "18\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 232s 38us/step - loss: 2.0683 - mean_squared_error: 2.0683 - val_loss: 1.0549 - val_mean_squared_error: 1.0549\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05486, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 233s 38us/step - loss: 0.9189 - mean_squared_error: 0.9189 - val_loss: 0.8584 - val_mean_squared_error: 0.8584\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05486 to 0.85840, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 232s 38us/step - loss: 0.7503 - mean_squared_error: 0.7503 - val_loss: 0.5721 - val_mean_squared_error: 0.5721\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.85840 to 0.57209, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 234s 39us/step - loss: 0.6224 - mean_squared_error: 0.6224 - val_loss: 0.3949 - val_mean_squared_error: 0.3949\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57209 to 0.39489, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 237s 39us/step - loss: 0.5379 - mean_squared_error: 0.5379 - val_loss: 0.3328 - val_mean_squared_error: 0.3328\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39489 to 0.33283, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 233s 38us/step - loss: 0.5153 - mean_squared_error: 0.5153 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33283 to 0.32207, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 233s 38us/step - loss: 0.4581 - mean_squared_error: 0.4581 - val_loss: 0.2182 - val_mean_squared_error: 0.2182\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32207 to 0.21820, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-18-07\n",
      "Epoch 00007: early stopping\n",
      "19\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 194s 32us/step - loss: 9.4018 - mean_squared_error: 9.4018 - val_loss: 7.1847 - val_mean_squared_error: 7.1847\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.18472, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 6.6787 - mean_squared_error: 6.6787 - val_loss: 6.5810 - val_mean_squared_error: 6.5810\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.18472 to 6.58095, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 5.9211 - mean_squared_error: 5.9211 - val_loss: 5.7187 - val_mean_squared_error: 5.7187\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.58095 to 5.71871, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 5.3516 - mean_squared_error: 5.3516 - val_loss: 5.8629 - val_mean_squared_error: 5.8629\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.71871\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 5.0421 - mean_squared_error: 5.0421 - val_loss: 4.7730 - val_mean_squared_error: 4.7730\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.71871 to 4.77303, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 4.8453 - mean_squared_error: 4.8453 - val_loss: 4.5951 - val_mean_squared_error: 4.5951\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.77303 to 4.59508, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 4.6936 - mean_squared_error: 4.6936 - val_loss: 4.5529 - val_mean_squared_error: 4.5529\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.59508 to 4.55290, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 4.5760 - mean_squared_error: 4.5760 - val_loss: 4.3920 - val_mean_squared_error: 4.3920\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.55290 to 4.39203, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 4.4779 - mean_squared_error: 4.4779 - val_loss: 4.8477 - val_mean_squared_error: 4.8477\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.39203\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 4.3940 - mean_squared_error: 4.3940 - val_loss: 4.2412 - val_mean_squared_error: 4.2412\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.39203 to 4.24121, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-10\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 4.3189 - mean_squared_error: 4.3189 - val_loss: 4.2524 - val_mean_squared_error: 4.2524\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.24121\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 193s 32us/step - loss: 4.2524 - mean_squared_error: 4.2524 - val_loss: 4.4748 - val_mean_squared_error: 4.4748\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.24121\n",
      "Epoch 13/100\n",
      "6069924/6069924 [==============================] - 195s 32us/step - loss: 4.1980 - mean_squared_error: 4.1980 - val_loss: 4.0602 - val_mean_squared_error: 4.0602\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.24121 to 4.06020, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-13\n",
      "Epoch 14/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 4.1503 - mean_squared_error: 4.1503 - val_loss: 3.9844 - val_mean_squared_error: 3.9844\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.06020 to 3.98439, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-19-14\n",
      "Epoch 15/100\n",
      "6069924/6069924 [==============================] - 192s 32us/step - loss: 4.1062 - mean_squared_error: 4.1062 - val_loss: 4.1625 - val_mean_squared_error: 4.1625\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.98439\n",
      "Epoch 16/100\n",
      "6069924/6069924 [==============================] - 191s 31us/step - loss: 4.0632 - mean_squared_error: 4.0632 - val_loss: 4.2784 - val_mean_squared_error: 4.2784\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.98439\n",
      "Epoch 00016: early stopping\n",
      "20\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 2.0988 - mean_squared_error: 2.0988 - val_loss: 0.7341 - val_mean_squared_error: 0.7341\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73410, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-20-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 1.0518 - mean_squared_error: 1.0518 - val_loss: 1.1908 - val_mean_squared_error: 1.1908\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.73410\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 0.8286 - mean_squared_error: 0.8286 - val_loss: 0.5902 - val_mean_squared_error: 0.5902\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73410 to 0.59017, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-20-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 0.7233 - mean_squared_error: 0.7233 - val_loss: 0.6334 - val_mean_squared_error: 0.6334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59017\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 0.6360 - mean_squared_error: 0.6360 - val_loss: 0.5781 - val_mean_squared_error: 0.5781\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59017 to 0.57813, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-20-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 0.5783 - mean_squared_error: 0.5783 - val_loss: 0.7877 - val_mean_squared_error: 0.7877\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.57813\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 0.5316 - mean_squared_error: 0.5316 - val_loss: 0.3442 - val_mean_squared_error: 0.3442\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.57813 to 0.34418, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-20-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 0.5056 - mean_squared_error: 0.5056 - val_loss: 0.4968 - val_mean_squared_error: 0.4968\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34418\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 0.4756 - mean_squared_error: 0.4756 - val_loss: 7.1288 - val_mean_squared_error: 7.1288\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34418\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 0.4522 - mean_squared_error: 0.4522 - val_loss: 0.2744 - val_mean_squared_error: 0.2744\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34418 to 0.27444, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-20-10\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 0.4255 - mean_squared_error: 0.4255 - val_loss: 0.5926 - val_mean_squared_error: 0.5926\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27444\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 0.4090 - mean_squared_error: 0.4090 - val_loss: 0.3283 - val_mean_squared_error: 0.3283\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27444\n",
      "Epoch 00012: early stopping\n",
      "21\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 3.9381 - mean_squared_error: 3.9381 - val_loss: 2.0746 - val_mean_squared_error: 2.0746\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.07456, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-21-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 2.1669 - mean_squared_error: 2.1669 - val_loss: 80.9194 - val_mean_squared_error: 80.9194\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.07456\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 1.8100 - mean_squared_error: 1.8100 - val_loss: 1.5382 - val_mean_squared_error: 1.5382\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.07456 to 1.53825, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-21-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 1.5119 - mean_squared_error: 1.5119 - val_loss: 1.7141 - val_mean_squared_error: 1.7141\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.53825\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 1.3721 - mean_squared_error: 1.3721 - val_loss: 2.0481 - val_mean_squared_error: 2.0481\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.53825\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 1.2782 - mean_squared_error: 1.2782 - val_loss: 0.8890 - val_mean_squared_error: 0.8890\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.53825 to 0.88903, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-21-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.1834 - mean_squared_error: 1.1834 - val_loss: 0.8170 - val_mean_squared_error: 0.8170\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.88903 to 0.81700, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-21-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 1.1207 - mean_squared_error: 1.1207 - val_loss: 0.7490 - val_mean_squared_error: 0.7490\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81700 to 0.74895, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-21-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 1.0793 - mean_squared_error: 1.0793 - val_loss: 0.7670 - val_mean_squared_error: 0.7670\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.74895\n",
      "Epoch 00009: early stopping\n",
      "22\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 215s 35us/step - loss: 2.7741 - mean_squared_error: 2.7741 - val_loss: 1.2689 - val_mean_squared_error: 1.2689\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.26889, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-22-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 1.5080 - mean_squared_error: 1.5080 - val_loss: 1.2629 - val_mean_squared_error: 1.2629\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.26889 to 1.26290, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-22-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 1.3260 - mean_squared_error: 1.3260 - val_loss: 1.3352 - val_mean_squared_error: 1.3352\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.26290\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.2353 - mean_squared_error: 1.2353 - val_loss: 2.1659 - val_mean_squared_error: 2.1659\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.26290\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 1.1908 - mean_squared_error: 1.1908 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.26290 to 1.01869, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-22-05\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 1.1472 - mean_squared_error: 1.1472 - val_loss: 0.7962 - val_mean_squared_error: 0.7962\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01869 to 0.79617, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-22-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.0946 - mean_squared_error: 1.0946 - val_loss: 0.8207 - val_mean_squared_error: 0.8207\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.79617\n",
      "Epoch 00007: early stopping\n",
      "23\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 3.1358 - mean_squared_error: 3.1358 - val_loss: 2.5658 - val_mean_squared_error: 2.5658\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.56575, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 1.6901 - mean_squared_error: 1.6901 - val_loss: 1.6905 - val_mean_squared_error: 1.6905\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.56575 to 1.69054, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.4852 - mean_squared_error: 1.4852 - val_loss: 1.6305 - val_mean_squared_error: 1.6305\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.69054 to 1.63054, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-03\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.3630 - mean_squared_error: 1.3630 - val_loss: 1.1589 - val_mean_squared_error: 1.1589\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.63054 to 1.15893, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 220s 36us/step - loss: 1.3456 - mean_squared_error: 1.3456 - val_loss: 1.5927 - val_mean_squared_error: 1.5927\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.15893\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 1.2453 - mean_squared_error: 1.2453 - val_loss: 1.0506 - val_mean_squared_error: 1.0506\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15893 to 1.05057, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-06\n",
      "Epoch 7/100\n",
      "6069924/6069924 [==============================] - 225s 37us/step - loss: 1.1641 - mean_squared_error: 1.1641 - val_loss: 1.0428 - val_mean_squared_error: 1.0428\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05057 to 1.04280, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 216s 36us/step - loss: 1.0984 - mean_squared_error: 1.0984 - val_loss: 0.8971 - val_mean_squared_error: 0.8971\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.04280 to 0.89714, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-08\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.0723 - mean_squared_error: 1.0723 - val_loss: 0.9230 - val_mean_squared_error: 0.9230\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.89714\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 0.8119 - val_mean_squared_error: 0.8119\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.89714 to 0.81192, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-10\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 1.0069 - mean_squared_error: 1.0069 - val_loss: 0.8291 - val_mean_squared_error: 0.8291\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.81192\n",
      "Epoch 12/100\n",
      "6069924/6069924 [==============================] - 220s 36us/step - loss: 0.9564 - mean_squared_error: 0.9564 - val_loss: 0.7233 - val_mean_squared_error: 0.7233\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.81192 to 0.72333, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-23-12\n",
      "Epoch 00012: early stopping\n",
      "24\n",
      "Train on 6069924 samples, validate on 1518083 samples\n",
      "Epoch 1/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 3.6481 - mean_squared_error: 3.6481 - val_loss: 2.1639 - val_mean_squared_error: 2.1639\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.16386, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-24-01\n",
      "Epoch 2/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 2.1537 - mean_squared_error: 2.1537 - val_loss: 1.5823 - val_mean_squared_error: 1.5823\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.16386 to 1.58225, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-24-02\n",
      "Epoch 3/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.8741 - mean_squared_error: 1.8741 - val_loss: 1.9341 - val_mean_squared_error: 1.9341\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58225\n",
      "Epoch 4/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.7787 - mean_squared_error: 1.7787 - val_loss: 1.3404 - val_mean_squared_error: 1.3404\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.58225 to 1.34042, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-24-04\n",
      "Epoch 5/100\n",
      "6069924/6069924 [==============================] - 219s 36us/step - loss: 1.7185 - mean_squared_error: 1.7185 - val_loss: 1.5806 - val_mean_squared_error: 1.5806\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.34042\n",
      "Epoch 6/100\n",
      "6069924/6069924 [==============================] - 222s 37us/step - loss: 1.6495 - mean_squared_error: 1.6495 - val_loss: 1.6171 - val_mean_squared_error: 1.6171\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.34042\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.5934 - mean_squared_error: 1.5934 - val_loss: 1.1870 - val_mean_squared_error: 1.1870\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.34042 to 1.18700, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-24-07\n",
      "Epoch 8/100\n",
      "6069924/6069924 [==============================] - 218s 36us/step - loss: 1.5424 - mean_squared_error: 1.5424 - val_loss: 1.3343 - val_mean_squared_error: 1.3343\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.18700\n",
      "Epoch 9/100\n",
      "6069924/6069924 [==============================] - 221s 36us/step - loss: 1.4451 - mean_squared_error: 1.4451 - val_loss: 1.0402 - val_mean_squared_error: 1.0402\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.18700 to 1.04025, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_13_18_23_31_32/ckpt-24-09\n",
      "Epoch 10/100\n",
      "6069924/6069924 [==============================] - 214s 35us/step - loss: 1.4260 - mean_squared_error: 1.4260 - val_loss: 1.1787 - val_mean_squared_error: 1.1787\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.04025\n",
      "Epoch 11/100\n",
      "6069924/6069924 [==============================] - 217s 36us/step - loss: 1.4071 - mean_squared_error: 1.4071 - val_loss: 1.1018 - val_mean_squared_error: 1.1018\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.04025\n",
      "Epoch 00011: early stopping\n",
      "25\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4fe8229483af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_directory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_choice_rt_'\u001b[0m \u001b[0;34m+\u001b[0m                 \u001b[0mcpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/hyp_opt_histories.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Hyperparameter training loop:\n",
    "\n",
    "# Runs: \n",
    "num_runs = 25\n",
    "cnt = 0\n",
    "max_layers = 5\n",
    "layer_sizes = [10, 20, 50]\n",
    "batch_sizes = [1000, 10000, 100000]\n",
    "\n",
    "# Update model directory to make sure we collect all our models from this hyperparameter optimization run in the same place\n",
    "cpm.data_params['model_directory'] =  '/home/afengler/git_repos/nn_likelihoods/keras_models/'\n",
    "cpm.data_params['model_name'] = 'dnnregressor_wftp_hyp_opt'\n",
    "cpm.data_params['model_cnt'] = 0\n",
    "\n",
    "histories = []\n",
    "\n",
    "while cnt < num_runs:\n",
    "    cnt += 1\n",
    "    \n",
    "    # Sample # layers \n",
    "    num_layers = np.random.choice(np.arange(1, max_layers, 1))\n",
    "    \n",
    "    # Layer sizes\n",
    "    layers = []\n",
    "    activations = []\n",
    "    regularizers = []\n",
    "    \n",
    "    for i in range(0, num_layers, 1):\n",
    "        layers.append(np.random.choice(layer_sizes))\n",
    "        activations.append('relu')\n",
    "        regularizers.append(0.0)\n",
    "        \n",
    "    # Batch size\n",
    "    batch_size = np.random.choice(batch_sizes)\n",
    "    \n",
    "    # Update relevant model parameters\n",
    "    cpm.train_params['batch_size'] = batch_size\n",
    "    cpm.model_params['hidden_layers'] = layers\n",
    "    cpm.model_params['hidden_activations'] = activations\n",
    "    cpm.model_params['l1_activation'] = regularizers\n",
    "    cpm.model_params['l2_activation'] = regularizers\n",
    "    cpm.model_params['l1_kernel'] = regularizers\n",
    "    cpm.model_params['l2_kernel'] = regularizers\n",
    "    \n",
    "    # Increment model count\n",
    "    cpm.data_params['model_cnt'] += 1\n",
    "    \n",
    "    # Make new timestamp\n",
    "    #cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "    \n",
    "    # Make model\n",
    "    cpm.keras_model_generate(save_model = True)\n",
    "    \n",
    "    # Train model\n",
    "    histories.append(cpm.run_training(save_history = True, \n",
    "                                    warm_start = False))\n",
    "    \n",
    "    histories[-1]['model_cnt'] = cpm.train_params['model_cnt']\n",
    "    histories[-1]['num_layers'] = num_layers\n",
    "    histories[-1]['size_layers'] = str(layers)\n",
    "    histories[-1]['activations'] = str(activations) \n",
    "    histories[-1]['batch_size'] = batch_size\n",
    "    \n",
    "    print(cnt)\n",
    "histories = pd.concat(histories)\n",
    "histories.to_csv(cpm.data_params['model_directory'] + cpm.data_params['model_name'] + '_choice_rt_' +\\\n",
    "                 cpm.data_params['timestamp'] + '/hyp_opt_histories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = pd.concat(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories.to_csv(cpm.data_params['model_directory'] + cpm.data_params['model_name'] + '_choice_rt_' +\\\n",
    "                 cpm.data_params['timestamp'] + '/hyp_opt_histories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
