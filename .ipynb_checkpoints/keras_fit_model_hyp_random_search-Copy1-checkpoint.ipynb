{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "from datetime import datetime\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "import make_data_wfpt as mdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(os.getcwd() + '/data_storage/data_11000000_from_simulation_mix_09_12_18_18_20_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some cleaning of the data\n",
    "data = data[['v', 'a', 'w', 'rt', 'choice', 'nf_likelihood']]\n",
    "data = data.loc[data['w'] > 0.1]\n",
    "data = data.loc[data['w'] < 0.9]\n",
    "data = data.loc[data['a'] > 0.5]\n",
    "\n",
    "mini_data = data.loc[1:10000]\n",
    "\n",
    "\n",
    "train_f, train_l, test_f, test_l = mdw.train_test_split_rt_choice(data = data,\n",
    "                                                                  write_to_file = False,\n",
    "                                                                  from_file = False,\n",
    "                                                                  p_train = 0.8,\n",
    "                                                                  backend = 'keras')\n",
    "# Choice probabilities\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_choice_probabilities(n_samples = 2500000,\n",
    "#                                                             f_signature = '_choice_probabilities_analytic_',\n",
    "#                                                                                 backend = 'keras')\n",
    "\n",
    "# rt_choice\n",
    "# train_f, train_l, test_f, test_l = mdw.train_test_from_file_rt_choice(n_samples = 11000000,\n",
    "#                                                                       f_signature = '_from_simulation_mix_',\n",
    "#                                                                       backend = 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dnnk class (cpm for choice probability model)\n",
    "cpm = dnnk.dnn_trainer()\n",
    "cpm.data['train_features'] = train_f\n",
    "cpm.data['train_labels'] = train_l\n",
    "cpm.data['test_features'] = test_f\n",
    "cpm.data['test_labels'] = test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': 3,\n",
       " 'output_shape': 1,\n",
       " 'output_activation': 'sigmoid',\n",
       " 'hidden_layers': [20, 20, 20, 20],\n",
       " 'hidden_activations': ['relu', 'relu', 'relu', 'relu'],\n",
       " 'l1_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_activation': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l1_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'l2_kernel': [0.0, 0.0, 0.0, 0.0],\n",
       " 'optimizer': 'Nadam',\n",
       " 'loss': 'mse',\n",
       " 'metrics': ['mse']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all parameters we can specify explicit\n",
    "# Model parameters\n",
    "cpm.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callback_funs': ['ReduceLROnPlateau', 'EarlyStopping', 'ModelCheckpoint'],\n",
       " 'plateau_patience': 10,\n",
       " 'min_delta': 0.0001,\n",
       " 'early_stopping_patience': 15,\n",
       " 'callback_monitor': 'loss',\n",
       " 'min_learning_rate': 1e-07,\n",
       " 'red_coef_learning_rate': 0.1,\n",
       " 'ckpt_period': 10,\n",
       " 'ckpt_save_best_only': True,\n",
       " 'ckpt_save_weights_only': True,\n",
       " 'max_train_epochs': 2000,\n",
       " 'batch_size': 10000,\n",
       " 'warm_start': False,\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_cnt': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters governing training\n",
    "cpm.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_type': 'choice_probabilities',\n",
       " 'model_directory': '/home/afengler/git_repos/nn_likelihoods/keras_models',\n",
       " 'checkpoint': 'ckpt',\n",
       " 'model_name': 'dnnregressor',\n",
       " 'data_type_signature': '_choice_probabilities_analytic_',\n",
       " 'timestamp': '09_15_18_23_59_14',\n",
       " 'training_data_size': 2500000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters concerning data storage\n",
    "cpm.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFYING META PARAMETERS THAT STAY CONSTANT DURING HYPERPARAMETER OPTIMIZATION\n",
    "\n",
    "# Model params\n",
    "cpm.model_params['output_activation'] = 'linear'\n",
    "cpm.model_params['input_shape'] = 5\n",
    "\n",
    "# Training params\n",
    "# Meta\n",
    "cpm.train_params['early_stopping_patience'] = 5\n",
    "cpm.train_params['plateau_patience'] = 3\n",
    "cpm.train_params['min_delta'] = 0.001\n",
    "cpm.train_params['ckpt_period'] = 1\n",
    "cpm.train_params['model_cnt'] = 0\n",
    "cpm.train_params['max_train_epochs'] = 25\n",
    "\n",
    "# Hyper\n",
    "#cpm.train_params['l1_kernel']\n",
    "cpm.model_params['hidden_layers'] = [5, 5, 5, 5]\n",
    "#cpm.train_params['hidden_activations']\n",
    "#cpm.train_params['l2_kernel'] = [0.5, 0.5, 0.5, 0.5]\n",
    "#cpm.train_params['l2_activation'] = [0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "# Data params\n",
    "cpm.data_params['data_type'] = 'wfpt'\n",
    "cpm.data_params['data_type_signature'] = '_choice_rt_'\n",
    "cpm.data_params['training_data_size'] = 11000000\n",
    "\n",
    "# Update timestamp\n",
    "cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "cpm.keras_model_generate(save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "cpm.run_training(save_history = True, \n",
    "                 warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 2.1434 - mean_squared_error: 2.1434 - val_loss: 1.0423 - val_mean_squared_error: 1.0423\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04228, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 1.1171 - mean_squared_error: 1.1171 - val_loss: 2.1657 - val_mean_squared_error: 2.1657\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.04228\n",
      "Epoch 3/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.8194 - mean_squared_error: 0.8194 - val_loss: 0.4458 - val_mean_squared_error: 0.4458\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.04228 to 0.44582, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-03\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.6625 - mean_squared_error: 0.6625 - val_loss: 0.8116 - val_mean_squared_error: 0.8116\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44582\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.5720 - mean_squared_error: 0.5720 - val_loss: 0.3995 - val_mean_squared_error: 0.3995\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44582 to 0.39947, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-05\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.5018 - mean_squared_error: 0.5018 - val_loss: 0.8194 - val_mean_squared_error: 0.8194\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39947\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.4573 - mean_squared_error: 0.4573 - val_loss: 0.3543 - val_mean_squared_error: 0.3543\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39947 to 0.35427, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-07\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.5071 - mean_squared_error: 0.5071 - val_loss: 0.2315 - val_mean_squared_error: 0.2315\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35427 to 0.23147, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-08\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4202 - mean_squared_error: 0.4202 - val_loss: 0.3629 - val_mean_squared_error: 0.3629\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23147\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4094 - mean_squared_error: 0.4094 - val_loss: 0.1986 - val_mean_squared_error: 0.1986\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.23147 to 0.19857, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-10\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4068 - mean_squared_error: 0.4068 - val_loss: 0.2265 - val_mean_squared_error: 0.2265\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19857\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.2107 - val_mean_squared_error: 0.2107\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19857\n",
      "Epoch 13/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3640 - mean_squared_error: 0.3640 - val_loss: 0.2284 - val_mean_squared_error: 0.2284\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19857\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.19857 to 0.16630, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-14\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.3494 - mean_squared_error: 0.3494 - val_loss: 0.2383 - val_mean_squared_error: 0.2383\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16630\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16630 to 0.13181, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-16\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.3192 - mean_squared_error: 0.3192 - val_loss: 0.8651 - val_mean_squared_error: 0.8651\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13181\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3043 - mean_squared_error: 0.3043 - val_loss: 0.1884 - val_mean_squared_error: 0.1884\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.13181\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.3098 - mean_squared_error: 0.3098 - val_loss: 0.2890 - val_mean_squared_error: 0.2890\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13181\n",
      "Epoch 20/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.3102 - mean_squared_error: 0.3102 - val_loss: 0.3147 - val_mean_squared_error: 0.3147\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13181\n",
      "Epoch 21/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3044 - mean_squared_error: 0.3044 - val_loss: 0.3499 - val_mean_squared_error: 0.3499\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.13181\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1074 - mean_squared_error: 0.1074 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.13181 to 0.11203, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-22\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0977 - mean_squared_error: 0.0977 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11203 to 0.09590, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-23\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0942 - mean_squared_error: 0.0942 - val_loss: 0.0932 - val_mean_squared_error: 0.0932\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.09590 to 0.09324, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-24\n",
      "Epoch 25/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0917 - mean_squared_error: 0.0917 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.09324 to 0.09066, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-25\n",
      "Epoch 26/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0901 - mean_squared_error: 0.0901 - val_loss: 0.0945 - val_mean_squared_error: 0.0945\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.09066\n",
      "Epoch 27/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0882 - mean_squared_error: 0.0882 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.09066 to 0.08674, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-27\n",
      "Epoch 28/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0866 - mean_squared_error: 0.0866 - val_loss: 0.0874 - val_mean_squared_error: 0.0874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08674\n",
      "Epoch 29/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0850 - mean_squared_error: 0.0850 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08674 to 0.08320, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-29\n",
      "Epoch 30/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0842 - mean_squared_error: 0.0842 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08320\n",
      "Epoch 31/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0834 - mean_squared_error: 0.0834 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08320\n",
      "Epoch 32/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08320 to 0.08235, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-32\n",
      "Epoch 33/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0809 - mean_squared_error: 0.0809 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08235 to 0.08147, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-33\n",
      "Epoch 34/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0795 - mean_squared_error: 0.0795 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08147 to 0.07844, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-34\n",
      "Epoch 35/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0775 - mean_squared_error: 0.0775 - val_loss: 0.0729 - val_mean_squared_error: 0.0729\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.07844 to 0.07293, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-35\n",
      "Epoch 36/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0761 - mean_squared_error: 0.0761 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07293\n",
      "Epoch 37/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0752 - mean_squared_error: 0.0752 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07293\n",
      "Epoch 38/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0741 - mean_squared_error: 0.0741 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.07293 to 0.07083, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-38\n",
      "Epoch 39/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0731 - mean_squared_error: 0.0731 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07083\n",
      "Epoch 40/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0723 - mean_squared_error: 0.0723 - val_loss: 0.0753 - val_mean_squared_error: 0.0753\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07083\n",
      "Epoch 41/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0712 - mean_squared_error: 0.0712 - val_loss: 0.0861 - val_mean_squared_error: 0.0861\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07083\n",
      "Epoch 42/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0707 - mean_squared_error: 0.0707 - val_loss: 0.0699 - val_mean_squared_error: 0.0699\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.07083 to 0.06990, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-42\n",
      "Epoch 43/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0690 - mean_squared_error: 0.0690 - val_loss: 0.0740 - val_mean_squared_error: 0.0740\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06990\n",
      "Epoch 44/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0680 - mean_squared_error: 0.0680 - val_loss: 0.0668 - val_mean_squared_error: 0.0668\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.06990 to 0.06679, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-44\n",
      "Epoch 45/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0678 - mean_squared_error: 0.0678 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.06679 to 0.06566, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-45\n",
      "Epoch 46/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0660 - mean_squared_error: 0.0660 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.06566 to 0.06394, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-46\n",
      "Epoch 47/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0648 - mean_squared_error: 0.0648 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.06394 to 0.06133, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-47\n",
      "Epoch 48/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0634 - mean_squared_error: 0.0634 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.06133 to 0.06129, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-48\n",
      "Epoch 49/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0623 - mean_squared_error: 0.0623 - val_loss: 0.0598 - val_mean_squared_error: 0.0598\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06129 to 0.05979, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-49\n",
      "Epoch 50/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0609 - mean_squared_error: 0.0609 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05979 to 0.05831, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-50\n",
      "Epoch 51/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0603 - mean_squared_error: 0.0603 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05831\n",
      "Epoch 52/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0590 - mean_squared_error: 0.0590 - val_loss: 0.0555 - val_mean_squared_error: 0.0555\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05831 to 0.05547, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-52\n",
      "Epoch 53/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.05547 to 0.05347, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-53\n",
      "Epoch 54/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.05347 to 0.05108, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-54\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0552 - mean_squared_error: 0.0552 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05108\n",
      "Epoch 56/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0543 - mean_squared_error: 0.0543 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.05108\n",
      "Epoch 57/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0532 - mean_squared_error: 0.0532 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05108\n",
      "Epoch 58/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0525 - mean_squared_error: 0.0525 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05108 to 0.04956, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-58\n",
      "Epoch 59/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0515 - mean_squared_error: 0.0515 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04956 to 0.04871, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-59\n",
      "Epoch 60/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0510 - mean_squared_error: 0.0510 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04871\n",
      "Epoch 61/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0507 - mean_squared_error: 0.0507 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04871\n",
      "Epoch 62/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04871 to 0.04747, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-62\n",
      "Epoch 63/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0491 - mean_squared_error: 0.0491 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.04747 to 0.04645, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-63\n",
      "Epoch 64/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.04645 to 0.04518, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-64\n",
      "Epoch 65/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.04518 to 0.04482, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-65\n",
      "Epoch 66/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0476 - mean_squared_error: 0.0476 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04482\n",
      "Epoch 67/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0469 - mean_squared_error: 0.0469 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.04482 to 0.04375, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-67\n",
      "Epoch 68/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0462 - mean_squared_error: 0.0462 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04375\n",
      "Epoch 69/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04375\n",
      "Epoch 70/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0457 - mean_squared_error: 0.0457 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.04375 to 0.04301, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-70\n",
      "Epoch 71/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0450 - mean_squared_error: 0.0450 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04301\n",
      "Epoch 72/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0435 - mean_squared_error: 0.0435 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04301\n",
      "Epoch 73/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.04301 to 0.03963, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-73\n",
      "Epoch 74/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03963\n",
      "Epoch 75/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0416 - mean_squared_error: 0.0416 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03963\n",
      "Epoch 76/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.03963 to 0.03898, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-76\n",
      "Epoch 77/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03898\n",
      "Epoch 78/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.03898 to 0.03525, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-78\n",
      "Epoch 79/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03525\n",
      "Epoch 80/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03525\n",
      "Epoch 81/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.03525 to 0.03484, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-81\n",
      "Epoch 82/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03484\n",
      "Epoch 83/100\n",
      "6072894/6072894 [==============================] - 187s 31us/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03484\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03484\n",
      "Epoch 85/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03484\n",
      "Epoch 86/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03484\n",
      "Epoch 87/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03484\n",
      "Epoch 88/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03484\n",
      "Epoch 89/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.03484 to 0.03338, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-89\n",
      "Epoch 90/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03338\n",
      "Epoch 91/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03338\n",
      "Epoch 92/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03338\n",
      "Epoch 93/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03338 to 0.03270, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-93\n",
      "Epoch 94/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03270\n",
      "Epoch 95/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03270 to 0.03185, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-95\n",
      "Epoch 96/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03185\n",
      "Epoch 97/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03185\n",
      "Epoch 98/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03185 to 0.03090, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-98\n",
      "Epoch 99/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.03090 to 0.03078, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-0-99\n",
      "Epoch 100/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03078\n",
      "1\n",
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 2.0391 - mean_squared_error: 2.0391 - val_loss: 0.8457 - val_mean_squared_error: 0.8457\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84570, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.8642 - mean_squared_error: 0.8642 - val_loss: 0.7458 - val_mean_squared_error: 0.7458\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84570 to 0.74578, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-02\n",
      "Epoch 3/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.6737 - mean_squared_error: 0.6737 - val_loss: 0.3240 - val_mean_squared_error: 0.3240\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74578 to 0.32400, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-03\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.5529 - mean_squared_error: 0.5529 - val_loss: 0.3431 - val_mean_squared_error: 0.3431\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32400\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 174s 29us/step - loss: 0.4960 - mean_squared_error: 0.4960 - val_loss: 0.2521 - val_mean_squared_error: 0.2521\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32400 to 0.25207, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-05\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.4473 - mean_squared_error: 0.4473 - val_loss: 0.3198 - val_mean_squared_error: 0.3198\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25207\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.4182 - mean_squared_error: 0.4182 - val_loss: 1.3338 - val_mean_squared_error: 1.3338\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25207\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.2167 - val_mean_squared_error: 0.2167\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25207 to 0.21673, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-08\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.3698 - mean_squared_error: 0.3698 - val_loss: 0.2637 - val_mean_squared_error: 0.2637\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21673\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.3495 - mean_squared_error: 0.3495 - val_loss: 0.4906 - val_mean_squared_error: 0.4906\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21673\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.3271 - mean_squared_error: 0.3271 - val_loss: 0.3967 - val_mean_squared_error: 0.3967\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21673\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.1925 - val_mean_squared_error: 0.1925\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21673 to 0.19248, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-12\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.1995 - val_mean_squared_error: 0.1995\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19248\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.3022 - mean_squared_error: 0.3022 - val_loss: 0.5720 - val_mean_squared_error: 0.5720\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19248\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2890 - mean_squared_error: 0.2890 - val_loss: 0.4032 - val_mean_squared_error: 0.4032\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19248\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2853 - mean_squared_error: 0.2853 - val_loss: 0.4080 - val_mean_squared_error: 0.4080\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19248\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.2837 - mean_squared_error: 0.2837 - val_loss: 0.1563 - val_mean_squared_error: 0.1563\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19248 to 0.15630, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-17\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2769 - mean_squared_error: 0.2769 - val_loss: 0.2274 - val_mean_squared_error: 0.2274\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15630\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.2639 - mean_squared_error: 0.2639 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15630 to 0.12392, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-19\n",
      "Epoch 20/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2607 - mean_squared_error: 0.2607 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.12392 to 0.11242, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-20\n",
      "Epoch 21/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2531 - mean_squared_error: 0.2531 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11242\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2424 - mean_squared_error: 0.2424 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11242 to 0.11236, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-22\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 174s 29us/step - loss: 0.2403 - mean_squared_error: 0.2403 - val_loss: 0.2425 - val_mean_squared_error: 0.2425\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11236\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.2326 - mean_squared_error: 0.2326 - val_loss: 0.1009 - val_mean_squared_error: 0.1009\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11236 to 0.10095, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-24\n",
      "Epoch 25/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2354 - mean_squared_error: 0.2354 - val_loss: 0.1438 - val_mean_squared_error: 0.1438\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10095\n",
      "Epoch 26/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2269 - mean_squared_error: 0.2269 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10095\n",
      "Epoch 27/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.2227 - mean_squared_error: 0.2227 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10095\n",
      "Epoch 28/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.2214 - mean_squared_error: 0.2214 - val_loss: 0.1851 - val_mean_squared_error: 0.1851\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10095\n",
      "Epoch 29/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.2141 - mean_squared_error: 0.2141 - val_loss: 0.1820 - val_mean_squared_error: 0.1820\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10095\n",
      "Epoch 30/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2136 - mean_squared_error: 0.2136 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10095\n",
      "Epoch 31/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2137 - mean_squared_error: 0.2137 - val_loss: 0.1277 - val_mean_squared_error: 0.1277\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10095\n",
      "Epoch 32/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2167 - mean_squared_error: 0.2167 - val_loss: 0.5261 - val_mean_squared_error: 0.5261\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10095\n",
      "Epoch 33/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.2139 - mean_squared_error: 0.2139 - val_loss: 0.1588 - val_mean_squared_error: 0.1588\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10095\n",
      "Epoch 34/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0780 - mean_squared_error: 0.0780 - val_loss: 0.0722 - val_mean_squared_error: 0.0722\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.10095 to 0.07217, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-34\n",
      "Epoch 35/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0739 - mean_squared_error: 0.0739 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07217\n",
      "Epoch 36/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0722 - mean_squared_error: 0.0722 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07217 to 0.06923, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-36\n",
      "Epoch 37/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0710 - mean_squared_error: 0.0710 - val_loss: 0.0682 - val_mean_squared_error: 0.0682\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.06923 to 0.06820, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-37\n",
      "Epoch 38/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0697 - mean_squared_error: 0.0697 - val_loss: 0.0654 - val_mean_squared_error: 0.0654\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.06820 to 0.06537, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-38\n",
      "Epoch 39/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0690 - mean_squared_error: 0.0690 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06537\n",
      "Epoch 40/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0676 - mean_squared_error: 0.0676 - val_loss: 0.0621 - val_mean_squared_error: 0.0621\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.06537 to 0.06208, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-40\n",
      "Epoch 41/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0669 - mean_squared_error: 0.0669 - val_loss: 0.0633 - val_mean_squared_error: 0.0633\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06208\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0659 - mean_squared_error: 0.0659 - val_loss: 0.0731 - val_mean_squared_error: 0.0731\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06208\n",
      "Epoch 43/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.0654 - mean_squared_error: 0.0654 - val_loss: 0.0654 - val_mean_squared_error: 0.0654\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06208\n",
      "Epoch 44/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0649 - mean_squared_error: 0.0649 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06208\n",
      "Epoch 45/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0645 - mean_squared_error: 0.0645 - val_loss: 0.0612 - val_mean_squared_error: 0.0612\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.06208 to 0.06116, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-45\n",
      "Epoch 46/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0638 - mean_squared_error: 0.0638 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.06116 to 0.06023, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-46\n",
      "Epoch 47/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0635 - mean_squared_error: 0.0635 - val_loss: 0.0625 - val_mean_squared_error: 0.0625\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06023\n",
      "Epoch 48/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0628 - mean_squared_error: 0.0628 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06023\n",
      "Epoch 49/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0622 - mean_squared_error: 0.0622 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06023 to 0.05894, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-49\n",
      "Epoch 50/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.0620 - mean_squared_error: 0.0620 - val_loss: 0.0644 - val_mean_squared_error: 0.0644\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05894\n",
      "Epoch 51/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0615 - mean_squared_error: 0.0615 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05894\n",
      "Epoch 52/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0611 - mean_squared_error: 0.0611 - val_loss: 0.0570 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05894 to 0.05705, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-52\n",
      "Epoch 53/100\n",
      "6072894/6072894 [==============================] - 181s 30us/step - loss: 0.0609 - mean_squared_error: 0.0609 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05705\n",
      "Epoch 54/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0604 - mean_squared_error: 0.0604 - val_loss: 0.0604 - val_mean_squared_error: 0.0604\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.05705\n",
      "Epoch 55/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 0.0558 - val_mean_squared_error: 0.0558\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.05705 to 0.05579, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-55\n",
      "Epoch 56/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0598 - mean_squared_error: 0.0598 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.05579\n",
      "Epoch 57/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0595 - mean_squared_error: 0.0595 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05579\n",
      "Epoch 58/100\n",
      "6072894/6072894 [==============================] - 175s 29us/step - loss: 0.0595 - mean_squared_error: 0.0595 - val_loss: 0.0555 - val_mean_squared_error: 0.0555\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05579 to 0.05548, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-58\n",
      "Epoch 59/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0594 - mean_squared_error: 0.0594 - val_loss: 0.0632 - val_mean_squared_error: 0.0632\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.05548\n",
      "Epoch 60/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.0587 - mean_squared_error: 0.0587 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.05548\n",
      "Epoch 61/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.05548\n",
      "Epoch 62/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0585 - mean_squared_error: 0.0585 - val_loss: 0.0553 - val_mean_squared_error: 0.0553\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.05548 to 0.05528, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-62\n",
      "Epoch 63/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.0582 - mean_squared_error: 0.0582 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.05528 to 0.05333, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-63\n",
      "Epoch 64/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0581 - mean_squared_error: 0.0581 - val_loss: 0.0557 - val_mean_squared_error: 0.0557\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.05333\n",
      "Epoch 65/100\n",
      "6072894/6072894 [==============================] - 173s 29us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0556 - val_mean_squared_error: 0.0556\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.05333\n",
      "Epoch 66/100\n",
      "6072894/6072894 [==============================] - 172s 28us/step - loss: 0.0579 - mean_squared_error: 0.0579 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05333\n",
      "Epoch 67/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0577 - mean_squared_error: 0.0577 - val_loss: 0.0547 - val_mean_squared_error: 0.0547\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05333\n",
      "Epoch 68/100\n",
      "6072894/6072894 [==============================] - 173s 28us/step - loss: 0.0575 - mean_squared_error: 0.0575 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05333 to 0.05317, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-1-68\n",
      "Epoch 00068: early stopping\n",
      "2\n",
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 2.1692 - mean_squared_error: 2.1692 - val_loss: 1.0564 - val_mean_squared_error: 1.0564\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05638, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 1.0056 - mean_squared_error: 1.0056 - val_loss: 0.4525 - val_mean_squared_error: 0.4525\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05638 to 0.45246, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-02\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.7897 - mean_squared_error: 0.7897 - val_loss: 0.4432 - val_mean_squared_error: 0.4432\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45246 to 0.44320, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-03\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.6616 - mean_squared_error: 0.6616 - val_loss: 0.5670 - val_mean_squared_error: 0.5670\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44320\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.5839 - mean_squared_error: 0.5839 - val_loss: 0.2494 - val_mean_squared_error: 0.2494\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44320 to 0.24940, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-05\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.5188 - mean_squared_error: 0.5188 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24940\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.4872 - mean_squared_error: 0.4872 - val_loss: 0.3863 - val_mean_squared_error: 0.3863\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24940\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.4606 - mean_squared_error: 0.4606 - val_loss: 1.7851 - val_mean_squared_error: 1.7851\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24940\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.4286 - mean_squared_error: 0.4286 - val_loss: 0.1945 - val_mean_squared_error: 0.1945\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24940 to 0.19448, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-09\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.4167 - mean_squared_error: 0.4167 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19448 to 0.16366, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-10\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.4135 - mean_squared_error: 0.4135 - val_loss: 0.3399 - val_mean_squared_error: 0.3399\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16366\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.5568 - mean_squared_error: 0.5568 - val_loss: 0.3553 - val_mean_squared_error: 0.3553\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16366\n",
      "Epoch 13/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3866 - mean_squared_error: 0.3866 - val_loss: 0.5338 - val_mean_squared_error: 0.5338\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16366\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 1.5064 - val_mean_squared_error: 1.5064\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16366\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.5059 - val_mean_squared_error: 0.5059\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16366\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.3443 - mean_squared_error: 0.3443 - val_loss: 0.3912 - val_mean_squared_error: 0.3912\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16366\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3339 - mean_squared_error: 0.3339 - val_loss: 0.3189 - val_mean_squared_error: 0.3189\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16366\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.1630 - val_mean_squared_error: 0.1630\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.16366 to 0.16298, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-18\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3046 - mean_squared_error: 0.3046 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16298\n",
      "Epoch 20/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.3075 - mean_squared_error: 0.3075 - val_loss: 0.1651 - val_mean_squared_error: 0.1651\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16298\n",
      "Epoch 21/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2835 - mean_squared_error: 0.2835 - val_loss: 0.2523 - val_mean_squared_error: 0.2523\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16298\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2798 - mean_squared_error: 0.2798 - val_loss: 0.1861 - val_mean_squared_error: 0.1861\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16298\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2716 - mean_squared_error: 0.2716 - val_loss: 0.1603 - val_mean_squared_error: 0.1603\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16298 to 0.16030, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-23\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2656 - mean_squared_error: 0.2656 - val_loss: 0.2276 - val_mean_squared_error: 0.2276\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16030\n",
      "Epoch 25/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2568 - mean_squared_error: 0.2568 - val_loss: 0.1872 - val_mean_squared_error: 0.1872\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16030\n",
      "Epoch 26/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2549 - mean_squared_error: 0.2549 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16030 to 0.13916, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-26\n",
      "Epoch 27/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2507 - mean_squared_error: 0.2507 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13916\n",
      "Epoch 28/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2447 - mean_squared_error: 0.2447 - val_loss: 0.1839 - val_mean_squared_error: 0.1839\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13916\n",
      "Epoch 29/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2408 - mean_squared_error: 0.2408 - val_loss: 0.1408 - val_mean_squared_error: 0.1408\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.13916\n",
      "Epoch 30/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2331 - mean_squared_error: 0.2331 - val_loss: 0.8327 - val_mean_squared_error: 0.8327\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13916\n",
      "Epoch 31/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2349 - mean_squared_error: 0.2349 - val_loss: 0.1406 - val_mean_squared_error: 0.1406\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.13916\n",
      "Epoch 32/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2286 - mean_squared_error: 0.2286 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13916 to 0.12961, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-32\n",
      "Epoch 33/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2277 - mean_squared_error: 0.2277 - val_loss: 0.2686 - val_mean_squared_error: 0.2686\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12961\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2204 - mean_squared_error: 0.2204 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.12961 to 0.11781, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-34\n",
      "Epoch 35/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2154 - mean_squared_error: 0.2154 - val_loss: 0.1821 - val_mean_squared_error: 0.1821\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11781\n",
      "Epoch 36/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2375 - mean_squared_error: 0.2375 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11781\n",
      "Epoch 37/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2215 - mean_squared_error: 0.2215 - val_loss: 0.1251 - val_mean_squared_error: 0.1251\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11781\n",
      "Epoch 38/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2146 - mean_squared_error: 0.2146 - val_loss: 0.1954 - val_mean_squared_error: 0.1954\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11781\n",
      "Epoch 39/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2095 - mean_squared_error: 0.2095 - val_loss: 0.1254 - val_mean_squared_error: 0.1254\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11781\n",
      "Epoch 40/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2115 - mean_squared_error: 0.2115 - val_loss: 0.1387 - val_mean_squared_error: 0.1387\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11781\n",
      "Epoch 41/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2101 - mean_squared_error: 0.2101 - val_loss: 0.3015 - val_mean_squared_error: 0.3015\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11781\n",
      "Epoch 42/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2038 - mean_squared_error: 0.2038 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11781\n",
      "Epoch 43/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2032 - mean_squared_error: 0.2032 - val_loss: 0.1561 - val_mean_squared_error: 0.1561\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11781\n",
      "Epoch 44/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.2075 - mean_squared_error: 0.2075 - val_loss: 0.1194 - val_mean_squared_error: 0.1194\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11781\n",
      "Epoch 45/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.2003 - mean_squared_error: 0.2003 - val_loss: 0.1914 - val_mean_squared_error: 0.1914\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11781\n",
      "Epoch 46/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1995 - mean_squared_error: 0.1995 - val_loss: 0.2628 - val_mean_squared_error: 0.2628\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11781\n",
      "Epoch 47/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1920 - mean_squared_error: 0.1920 - val_loss: 0.1153 - val_mean_squared_error: 0.1153\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.11781 to 0.11529, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-47\n",
      "Epoch 48/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1910 - mean_squared_error: 0.1910 - val_loss: 0.2591 - val_mean_squared_error: 0.2591\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11529\n",
      "Epoch 49/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1962 - mean_squared_error: 0.1962 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11529 to 0.09735, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-49\n",
      "Epoch 50/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1918 - mean_squared_error: 0.1918 - val_loss: 0.1860 - val_mean_squared_error: 0.1860\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09735\n",
      "Epoch 51/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1899 - mean_squared_error: 0.1899 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.09735\n",
      "Epoch 52/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1888 - mean_squared_error: 0.1888 - val_loss: 0.1473 - val_mean_squared_error: 0.1473\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.09735\n",
      "Epoch 53/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1906 - mean_squared_error: 0.1906 - val_loss: 0.1068 - val_mean_squared_error: 0.1068\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.09735\n",
      "Epoch 54/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1869 - mean_squared_error: 0.1869 - val_loss: 0.1246 - val_mean_squared_error: 0.1246\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.09735\n",
      "Epoch 55/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1843 - mean_squared_error: 0.1843 - val_loss: 0.1341 - val_mean_squared_error: 0.1341\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.09735\n",
      "Epoch 56/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1847 - mean_squared_error: 0.1847 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.09735\n",
      "Epoch 57/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1842 - mean_squared_error: 0.1842 - val_loss: 0.3124 - val_mean_squared_error: 0.3124\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.09735\n",
      "Epoch 58/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1793 - mean_squared_error: 0.1793 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.09735\n",
      "Epoch 59/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1805 - mean_squared_error: 0.1805 - val_loss: 0.1206 - val_mean_squared_error: 0.1206\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.09735\n",
      "Epoch 60/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1774 - mean_squared_error: 0.1774 - val_loss: 0.1445 - val_mean_squared_error: 0.1445\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.09735\n",
      "Epoch 61/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1780 - mean_squared_error: 0.1780 - val_loss: 0.4225 - val_mean_squared_error: 0.4225\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.09735\n",
      "Epoch 62/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1738 - mean_squared_error: 0.1738 - val_loss: 0.1260 - val_mean_squared_error: 0.1260\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09735\n",
      "Epoch 63/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1748 - mean_squared_error: 0.1748 - val_loss: 0.1649 - val_mean_squared_error: 0.1649\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.09735\n",
      "Epoch 64/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1702 - mean_squared_error: 0.1702 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.09735\n",
      "Epoch 65/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1720 - mean_squared_error: 0.1720 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.09735\n",
      "Epoch 66/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1694 - mean_squared_error: 0.1694 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09735 to 0.08656, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-66\n",
      "Epoch 67/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1700 - mean_squared_error: 0.1700 - val_loss: 0.0807 - val_mean_squared_error: 0.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_loss improved from 0.08656 to 0.08066, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-2-67\n",
      "Epoch 68/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1751 - mean_squared_error: 0.1751 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08066\n",
      "Epoch 69/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1693 - mean_squared_error: 0.1693 - val_loss: 0.2621 - val_mean_squared_error: 0.2621\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08066\n",
      "Epoch 00069: early stopping\n",
      "3\n",
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 8.2439 - mean_squared_error: 8.2439 - val_loss: 5.9796 - val_mean_squared_error: 5.9796\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.97956, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 5.4550 - mean_squared_error: 5.4550 - val_loss: 4.9355 - val_mean_squared_error: 4.9355\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.97956 to 4.93551, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-02\n",
      "Epoch 3/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 4.7191 - mean_squared_error: 4.7191 - val_loss: 4.4320 - val_mean_squared_error: 4.4320\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.93551 to 4.43196, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-03\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 4.3018 - mean_squared_error: 4.3018 - val_loss: 4.3297 - val_mean_squared_error: 4.3297\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.43196 to 4.32972, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-04\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 4.0179 - mean_squared_error: 4.0179 - val_loss: 4.0592 - val_mean_squared_error: 4.0592\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.32972 to 4.05919, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-05\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 3.8107 - mean_squared_error: 3.8107 - val_loss: 4.0610 - val_mean_squared_error: 4.0610\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.05919\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 3.6421 - mean_squared_error: 3.6421 - val_loss: 3.8807 - val_mean_squared_error: 3.8807\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.05919 to 3.88065, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-07\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 3.4760 - mean_squared_error: 3.4760 - val_loss: 3.6521 - val_mean_squared_error: 3.6521\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.88065 to 3.65211, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-08\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 3.3628 - mean_squared_error: 3.3628 - val_loss: 4.5397 - val_mean_squared_error: 4.5397\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.65211\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 3.2650 - mean_squared_error: 3.2650 - val_loss: 4.3718 - val_mean_squared_error: 4.3718\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.65211\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 3.1791 - mean_squared_error: 3.1791 - val_loss: 4.3822 - val_mean_squared_error: 4.3822\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.65211\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 3.1061 - mean_squared_error: 3.1061 - val_loss: 3.0471 - val_mean_squared_error: 3.0471\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.65211 to 3.04714, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-12\n",
      "Epoch 13/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 3.0417 - mean_squared_error: 3.0417 - val_loss: 3.0574 - val_mean_squared_error: 3.0574\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.04714\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.9880 - mean_squared_error: 2.9880 - val_loss: 2.8058 - val_mean_squared_error: 2.8058\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.04714 to 2.80577, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-14\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.9402 - mean_squared_error: 2.9402 - val_loss: 2.7386 - val_mean_squared_error: 2.7386\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.80577 to 2.73861, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-15\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.8914 - mean_squared_error: 2.8914 - val_loss: 2.8412 - val_mean_squared_error: 2.8412\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.73861\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.8498 - mean_squared_error: 2.8498 - val_loss: 3.2099 - val_mean_squared_error: 3.2099\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.73861\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.8093 - mean_squared_error: 2.8093 - val_loss: 2.7912 - val_mean_squared_error: 2.7912\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.73861\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.7705 - mean_squared_error: 2.7705 - val_loss: 2.6097 - val_mean_squared_error: 2.6097\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.73861 to 2.60968, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-19\n",
      "Epoch 20/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.7345 - mean_squared_error: 2.7345 - val_loss: 2.9349 - val_mean_squared_error: 2.9349\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.60968\n",
      "Epoch 21/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.7074 - mean_squared_error: 2.7074 - val_loss: 2.5620 - val_mean_squared_error: 2.5620\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.60968 to 2.56201, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-21\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.6754 - mean_squared_error: 2.6754 - val_loss: 2.5738 - val_mean_squared_error: 2.5738\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.56201\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.6506 - mean_squared_error: 2.6506 - val_loss: 2.4558 - val_mean_squared_error: 2.4558\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.56201 to 2.45585, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-23\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.6296 - mean_squared_error: 2.6296 - val_loss: 2.5669 - val_mean_squared_error: 2.5669\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.45585\n",
      "Epoch 25/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.6046 - mean_squared_error: 2.6046 - val_loss: 2.4951 - val_mean_squared_error: 2.4951\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.45585\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.5833 - mean_squared_error: 2.5833 - val_loss: 2.4341 - val_mean_squared_error: 2.4341\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.45585 to 2.43413, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-26\n",
      "Epoch 27/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.5608 - mean_squared_error: 2.5608 - val_loss: 2.4281 - val_mean_squared_error: 2.4281\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.43413 to 2.42807, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-27\n",
      "Epoch 28/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.5377 - mean_squared_error: 2.5377 - val_loss: 2.2454 - val_mean_squared_error: 2.2454\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.42807 to 2.24541, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-28\n",
      "Epoch 29/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.5219 - mean_squared_error: 2.5219 - val_loss: 2.4867 - val_mean_squared_error: 2.4867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.24541\n",
      "Epoch 30/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4981 - mean_squared_error: 2.4981 - val_loss: 2.3072 - val_mean_squared_error: 2.3072\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.24541\n",
      "Epoch 31/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4891 - mean_squared_error: 2.4891 - val_loss: 2.3069 - val_mean_squared_error: 2.3069\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.24541\n",
      "Epoch 32/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4679 - mean_squared_error: 2.4679 - val_loss: 2.2571 - val_mean_squared_error: 2.2571\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.24541\n",
      "Epoch 33/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4527 - mean_squared_error: 2.4527 - val_loss: 2.2668 - val_mean_squared_error: 2.2668\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.24541\n",
      "Epoch 34/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4359 - mean_squared_error: 2.4359 - val_loss: 2.2167 - val_mean_squared_error: 2.2167\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.24541 to 2.21670, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-34\n",
      "Epoch 35/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4192 - mean_squared_error: 2.4192 - val_loss: 2.2041 - val_mean_squared_error: 2.2041\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.21670 to 2.20414, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-35\n",
      "Epoch 36/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.4087 - mean_squared_error: 2.4087 - val_loss: 2.4729 - val_mean_squared_error: 2.4729\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.20414\n",
      "Epoch 37/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3923 - mean_squared_error: 2.3923 - val_loss: 2.4756 - val_mean_squared_error: 2.4756\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.20414\n",
      "Epoch 38/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3796 - mean_squared_error: 2.3796 - val_loss: 2.1118 - val_mean_squared_error: 2.1118\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.20414 to 2.11179, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-38\n",
      "Epoch 39/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3690 - mean_squared_error: 2.3690 - val_loss: 2.5563 - val_mean_squared_error: 2.5563\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.11179\n",
      "Epoch 40/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.3560 - mean_squared_error: 2.3560 - val_loss: 2.6461 - val_mean_squared_error: 2.6461\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.11179\n",
      "Epoch 41/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3462 - mean_squared_error: 2.3462 - val_loss: 2.4565 - val_mean_squared_error: 2.4565\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.11179\n",
      "Epoch 42/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3307 - mean_squared_error: 2.3307 - val_loss: 2.2182 - val_mean_squared_error: 2.2182\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.11179\n",
      "Epoch 43/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.3141 - mean_squared_error: 2.3141 - val_loss: 2.2846 - val_mean_squared_error: 2.2846\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.11179\n",
      "Epoch 44/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.3125 - mean_squared_error: 2.3125 - val_loss: 2.1123 - val_mean_squared_error: 2.1123\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.11179\n",
      "Epoch 45/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2911 - mean_squared_error: 2.2911 - val_loss: 2.3070 - val_mean_squared_error: 2.3070\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.11179\n",
      "Epoch 46/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.2698 - mean_squared_error: 2.2698 - val_loss: 2.4161 - val_mean_squared_error: 2.4161\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.11179\n",
      "Epoch 47/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2571 - mean_squared_error: 2.2571 - val_loss: 2.2881 - val_mean_squared_error: 2.2881\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.11179\n",
      "Epoch 48/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2470 - mean_squared_error: 2.2470 - val_loss: 2.1067 - val_mean_squared_error: 2.1067\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.11179 to 2.10666, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-48\n",
      "Epoch 49/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2444 - mean_squared_error: 2.2444 - val_loss: 3.4852 - val_mean_squared_error: 3.4852\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.10666\n",
      "Epoch 50/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2247 - mean_squared_error: 2.2247 - val_loss: 2.1530 - val_mean_squared_error: 2.1530\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.10666\n",
      "Epoch 51/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2210 - mean_squared_error: 2.2210 - val_loss: 2.0045 - val_mean_squared_error: 2.0045\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.10666 to 2.00449, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-51\n",
      "Epoch 52/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2157 - mean_squared_error: 2.2157 - val_loss: 2.3837 - val_mean_squared_error: 2.3837\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.00449\n",
      "Epoch 53/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.2029 - mean_squared_error: 2.2029 - val_loss: 1.9491 - val_mean_squared_error: 1.9491\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.00449 to 1.94914, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-53\n",
      "Epoch 54/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1987 - mean_squared_error: 2.1987 - val_loss: 2.2081 - val_mean_squared_error: 2.2081\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.94914\n",
      "Epoch 55/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1871 - mean_squared_error: 2.1871 - val_loss: 1.9740 - val_mean_squared_error: 1.9740\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.94914\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1819 - mean_squared_error: 2.1819 - val_loss: 2.3289 - val_mean_squared_error: 2.3289\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.94914\n",
      "Epoch 57/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1749 - mean_squared_error: 2.1749 - val_loss: 2.2294 - val_mean_squared_error: 2.2294\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.94914\n",
      "Epoch 58/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1646 - mean_squared_error: 2.1646 - val_loss: 2.2552 - val_mean_squared_error: 2.2552\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.94914\n",
      "Epoch 59/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1556 - mean_squared_error: 2.1556 - val_loss: 2.3938 - val_mean_squared_error: 2.3938\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.94914\n",
      "Epoch 60/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.1529 - mean_squared_error: 2.1529 - val_loss: 2.0473 - val_mean_squared_error: 2.0473\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.94914\n",
      "Epoch 61/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.1451 - mean_squared_error: 2.1451 - val_loss: 1.8473 - val_mean_squared_error: 1.8473\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.94914 to 1.84726, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-61\n",
      "Epoch 62/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.1423 - mean_squared_error: 2.1423 - val_loss: 1.9163 - val_mean_squared_error: 1.9163\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.84726\n",
      "Epoch 63/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.1332 - mean_squared_error: 2.1332 - val_loss: 2.1111 - val_mean_squared_error: 2.1111\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.84726\n",
      "Epoch 64/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1262 - mean_squared_error: 2.1262 - val_loss: 2.3956 - val_mean_squared_error: 2.3956\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.84726\n",
      "Epoch 65/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1194 - mean_squared_error: 2.1194 - val_loss: 2.1249 - val_mean_squared_error: 2.1249\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.84726\n",
      "Epoch 66/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1144 - mean_squared_error: 2.1144 - val_loss: 2.8877 - val_mean_squared_error: 2.8877\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.84726\n",
      "Epoch 67/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.1169 - mean_squared_error: 2.1169 - val_loss: 2.0834 - val_mean_squared_error: 2.0834\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.84726\n",
      "Epoch 68/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0990 - mean_squared_error: 2.0990 - val_loss: 2.8277 - val_mean_squared_error: 2.8277\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.84726\n",
      "Epoch 69/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0972 - mean_squared_error: 2.0972 - val_loss: 1.8858 - val_mean_squared_error: 1.8858\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.84726\n",
      "Epoch 70/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.0896 - mean_squared_error: 2.0896 - val_loss: 1.8024 - val_mean_squared_error: 1.8024\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.84726 to 1.80241, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-70\n",
      "Epoch 71/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0869 - mean_squared_error: 2.0869 - val_loss: 1.9831 - val_mean_squared_error: 1.9831\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.80241\n",
      "Epoch 72/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.0802 - mean_squared_error: 2.0802 - val_loss: 2.6181 - val_mean_squared_error: 2.6181\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.80241\n",
      "Epoch 73/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0742 - mean_squared_error: 2.0742 - val_loss: 1.9271 - val_mean_squared_error: 1.9271\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.80241\n",
      "Epoch 74/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0692 - mean_squared_error: 2.0692 - val_loss: 1.9915 - val_mean_squared_error: 1.9915\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.80241\n",
      "Epoch 75/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0624 - mean_squared_error: 2.0624 - val_loss: 1.9013 - val_mean_squared_error: 1.9013\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.80241\n",
      "Epoch 76/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0552 - mean_squared_error: 2.0552 - val_loss: 1.8966 - val_mean_squared_error: 1.8966\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.80241\n",
      "Epoch 77/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0515 - mean_squared_error: 2.0515 - val_loss: 1.8333 - val_mean_squared_error: 1.8333\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.80241\n",
      "Epoch 78/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0482 - mean_squared_error: 2.0482 - val_loss: 2.8889 - val_mean_squared_error: 2.8889\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.80241\n",
      "Epoch 79/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0438 - mean_squared_error: 2.0438 - val_loss: 1.9331 - val_mean_squared_error: 1.9331\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.80241\n",
      "Epoch 80/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0373 - mean_squared_error: 2.0373 - val_loss: 2.4532 - val_mean_squared_error: 2.4532\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.80241\n",
      "Epoch 81/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0339 - mean_squared_error: 2.0339 - val_loss: 1.7631 - val_mean_squared_error: 1.7631\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.80241 to 1.76308, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-81\n",
      "Epoch 82/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0303 - mean_squared_error: 2.0303 - val_loss: 1.7919 - val_mean_squared_error: 1.7919\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.76308\n",
      "Epoch 83/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0264 - mean_squared_error: 2.0264 - val_loss: 1.7770 - val_mean_squared_error: 1.7770\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.76308\n",
      "Epoch 84/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.0215 - mean_squared_error: 2.0215 - val_loss: 1.7168 - val_mean_squared_error: 1.7168\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.76308 to 1.71682, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-3-84\n",
      "Epoch 85/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 2.0168 - mean_squared_error: 2.0168 - val_loss: 1.7940 - val_mean_squared_error: 1.7940\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.71682\n",
      "Epoch 86/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0111 - mean_squared_error: 2.0111 - val_loss: 1.8112 - val_mean_squared_error: 1.8112\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.71682\n",
      "Epoch 87/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0079 - mean_squared_error: 2.0079 - val_loss: 2.0416 - val_mean_squared_error: 2.0416\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.71682\n",
      "Epoch 88/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0056 - mean_squared_error: 2.0056 - val_loss: 1.8998 - val_mean_squared_error: 1.8998\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.71682\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0007 - mean_squared_error: 2.0007 - val_loss: 2.0175 - val_mean_squared_error: 2.0175\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.71682\n",
      "Epoch 90/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 2.0009 - mean_squared_error: 2.0009 - val_loss: 2.0256 - val_mean_squared_error: 2.0256\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.71682\n",
      "Epoch 91/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9908 - mean_squared_error: 1.9908 - val_loss: 1.7330 - val_mean_squared_error: 1.7330\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.71682\n",
      "Epoch 92/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9890 - mean_squared_error: 1.9890 - val_loss: 1.8220 - val_mean_squared_error: 1.8220\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.71682\n",
      "Epoch 93/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 1.9746 - mean_squared_error: 1.9746 - val_loss: 1.9504 - val_mean_squared_error: 1.9504\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.71682\n",
      "Epoch 94/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 1.9693 - mean_squared_error: 1.9693 - val_loss: 1.7576 - val_mean_squared_error: 1.7576\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.71682\n",
      "Epoch 95/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9568 - mean_squared_error: 1.9568 - val_loss: 1.8069 - val_mean_squared_error: 1.8069\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.71682\n",
      "Epoch 96/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9582 - mean_squared_error: 1.9582 - val_loss: 4.5414 - val_mean_squared_error: 4.5414\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.71682\n",
      "Epoch 97/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9475 - mean_squared_error: 1.9475 - val_loss: 2.4790 - val_mean_squared_error: 2.4790\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.71682\n",
      "Epoch 98/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9474 - mean_squared_error: 1.9474 - val_loss: 1.7654 - val_mean_squared_error: 1.7654\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.71682\n",
      "Epoch 99/100\n",
      "6072894/6072894 [==============================] - 138s 23us/step - loss: 1.9415 - mean_squared_error: 1.9415 - val_loss: 1.7627 - val_mean_squared_error: 1.7627\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.71682\n",
      "Epoch 100/100\n",
      "6072894/6072894 [==============================] - 137s 23us/step - loss: 1.9370 - mean_squared_error: 1.9370 - val_loss: 1.8328 - val_mean_squared_error: 1.8328\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.71682\n",
      "4\n",
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 2.4561 - mean_squared_error: 2.4561 - val_loss: 3.0405 - val_mean_squared_error: 3.0405\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.04048, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 1.3812 - mean_squared_error: 1.3812 - val_loss: 0.7262 - val_mean_squared_error: 0.7262\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.04048 to 0.72617, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-02\n",
      "Epoch 3/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 1.1375 - mean_squared_error: 1.1375 - val_loss: 1.0506 - val_mean_squared_error: 1.0506\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.72617\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.9283 - mean_squared_error: 0.9283 - val_loss: 5.0553 - val_mean_squared_error: 5.0553\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.72617\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.8185 - mean_squared_error: 0.8185 - val_loss: 0.9640 - val_mean_squared_error: 0.9640\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.72617\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.7332 - mean_squared_error: 0.7332 - val_loss: 8.2300 - val_mean_squared_error: 8.2300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.72617\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.6949 - mean_squared_error: 0.6949 - val_loss: 0.4485 - val_mean_squared_error: 0.4485\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72617 to 0.44851, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-07\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.6758 - mean_squared_error: 0.6758 - val_loss: 0.5692 - val_mean_squared_error: 0.5692\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44851\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.6448 - mean_squared_error: 0.6448 - val_loss: 0.5485 - val_mean_squared_error: 0.5485\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44851\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.6156 - mean_squared_error: 0.6156 - val_loss: 0.7269 - val_mean_squared_error: 0.7269\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44851\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.6002 - mean_squared_error: 0.6002 - val_loss: 0.5453 - val_mean_squared_error: 0.5453\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44851\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.5790 - mean_squared_error: 0.5790 - val_loss: 0.4361 - val_mean_squared_error: 0.4361\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44851 to 0.43609, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-12\n",
      "Epoch 13/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.5412 - mean_squared_error: 0.5412 - val_loss: 0.3411 - val_mean_squared_error: 0.3411\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43609 to 0.34112, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-13\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.5172 - mean_squared_error: 0.5172 - val_loss: 0.4634 - val_mean_squared_error: 0.4634\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34112\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.4987 - mean_squared_error: 0.4987 - val_loss: 0.3370 - val_mean_squared_error: 0.3370\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34112 to 0.33699, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-15\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.4852 - mean_squared_error: 0.4852 - val_loss: 0.7789 - val_mean_squared_error: 0.7789\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33699\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4573 - mean_squared_error: 0.4573 - val_loss: 0.4302 - val_mean_squared_error: 0.4302\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33699\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4365 - mean_squared_error: 0.4365 - val_loss: 0.3346 - val_mean_squared_error: 0.3346\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33699 to 0.33460, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-18\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4341 - mean_squared_error: 0.4341 - val_loss: 0.2971 - val_mean_squared_error: 0.2971\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33460 to 0.29707, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-19\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.2725 - val_mean_squared_error: 0.2725\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.29707 to 0.27251, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-20\n",
      "Epoch 21/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.4184 - mean_squared_error: 0.4184 - val_loss: 0.3261 - val_mean_squared_error: 0.3261\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.27251\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3982 - mean_squared_error: 0.3982 - val_loss: 0.2861 - val_mean_squared_error: 0.2861\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.27251\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3851 - mean_squared_error: 0.3851 - val_loss: 0.3591 - val_mean_squared_error: 0.3591\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.27251\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3744 - mean_squared_error: 0.3744 - val_loss: 0.5681 - val_mean_squared_error: 0.5681\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.27251\n",
      "Epoch 25/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3799 - val_mean_squared_error: 0.3799\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27251\n",
      "Epoch 26/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3563 - mean_squared_error: 0.3563 - val_loss: 0.2531 - val_mean_squared_error: 0.2531\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.27251 to 0.25309, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-26\n",
      "Epoch 27/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3589 - mean_squared_error: 0.3589 - val_loss: 0.2683 - val_mean_squared_error: 0.2683\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.25309\n",
      "Epoch 28/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.3405 - mean_squared_error: 0.3405 - val_loss: 0.2337 - val_mean_squared_error: 0.2337\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.25309 to 0.23373, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-28\n",
      "Epoch 29/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.3491 - mean_squared_error: 0.3491 - val_loss: 0.2540 - val_mean_squared_error: 0.2540\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.23373\n",
      "Epoch 30/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.3407 - mean_squared_error: 0.3407 - val_loss: 0.2420 - val_mean_squared_error: 0.2420\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23373\n",
      "Epoch 31/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.3426 - mean_squared_error: 0.3426 - val_loss: 0.2135 - val_mean_squared_error: 0.2135\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23373 to 0.21348, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-31\n",
      "Epoch 32/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1729 - val_mean_squared_error: 0.1729\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21348 to 0.17286, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-32\n",
      "Epoch 33/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1595 - mean_squared_error: 0.1595 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17286 to 0.15925, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-33\n",
      "Epoch 34/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1563 - mean_squared_error: 0.1563 - val_loss: 0.1565 - val_mean_squared_error: 0.1565\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15925 to 0.15647, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-34\n",
      "Epoch 35/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1538 - mean_squared_error: 0.1538 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15647\n",
      "Epoch 36/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1470 - val_mean_squared_error: 0.1470\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15647 to 0.14697, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-36\n",
      "Epoch 37/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14697\n",
      "Epoch 38/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.14697 to 0.14431, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-38\n",
      "Epoch 39/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14431\n",
      "Epoch 40/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1488 - mean_squared_error: 0.1488 - val_loss: 0.1458 - val_mean_squared_error: 0.1458\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14431\n",
      "Epoch 41/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1485 - mean_squared_error: 0.1485 - val_loss: 0.1479 - val_mean_squared_error: 0.1479\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.14431\n",
      "Epoch 42/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1479 - mean_squared_error: 0.1479 - val_loss: 0.1445 - val_mean_squared_error: 0.1445\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14431\n",
      "Epoch 43/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1468 - mean_squared_error: 0.1468 - val_loss: 0.1449 - val_mean_squared_error: 0.1449\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.14431\n",
      "Epoch 44/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1462 - mean_squared_error: 0.1462 - val_loss: 0.1431 - val_mean_squared_error: 0.1431\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14431 to 0.14314, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-44\n",
      "Epoch 45/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1451 - mean_squared_error: 0.1451 - val_loss: 0.1413 - val_mean_squared_error: 0.1413\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14314 to 0.14127, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-45\n",
      "Epoch 46/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1440 - mean_squared_error: 0.1440 - val_loss: 0.1419 - val_mean_squared_error: 0.1419\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.14127\n",
      "Epoch 47/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1432 - mean_squared_error: 0.1432 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.14127\n",
      "Epoch 48/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1454 - val_mean_squared_error: 0.1454\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.14127\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1459 - val_mean_squared_error: 0.1459ean_squared_error: 0.14\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14127\n",
      "Epoch 50/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1414 - val_mean_squared_error: 0.1414\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.14127\n",
      "Epoch 51/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1402 - mean_squared_error: 0.1402 - val_loss: 0.1363 - val_mean_squared_error: 0.1363\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.14127 to 0.13634, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-51\n",
      "Epoch 52/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1400 - mean_squared_error: 0.1400 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.13634\n",
      "Epoch 53/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1396 - mean_squared_error: 0.1396 - val_loss: 0.1361 - val_mean_squared_error: 0.1361\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.13634 to 0.13609, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-53\n",
      "Epoch 54/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1393 - mean_squared_error: 0.1393 - val_loss: 0.1403 - val_mean_squared_error: 0.1403\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13609\n",
      "Epoch 55/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1386 - mean_squared_error: 0.1386 - val_loss: 0.1396 - val_mean_squared_error: 0.1396\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.13609\n",
      "Epoch 56/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1371 - mean_squared_error: 0.1371 - val_loss: 0.1357 - val_mean_squared_error: 0.1357\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13609 to 0.13571, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-56\n",
      "Epoch 57/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1357 - mean_squared_error: 0.1357 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.13571 to 0.13185, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-57\n",
      "Epoch 58/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1348 - mean_squared_error: 0.1348 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.13185 to 0.13175, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-58\n",
      "Epoch 59/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1344 - mean_squared_error: 0.1344 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.13175 to 0.13117, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-59\n",
      "Epoch 60/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1343 - mean_squared_error: 0.1343 - val_loss: 0.1329 - val_mean_squared_error: 0.1329\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.13117\n",
      "Epoch 61/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 0.1274 - val_mean_squared_error: 0.1274\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13117 to 0.12744, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-61\n",
      "Epoch 62/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1323 - mean_squared_error: 0.1323 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.12744\n",
      "Epoch 63/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1321 - mean_squared_error: 0.1321 - val_loss: 0.1334 - val_mean_squared_error: 0.1334\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.12744\n",
      "Epoch 64/100\n",
      "6072894/6072894 [==============================] - 184s 30us/step - loss: 0.1313 - mean_squared_error: 0.1313 - val_loss: 0.1282 - val_mean_squared_error: 0.1282\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.12744\n",
      "Epoch 65/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1308 - mean_squared_error: 0.1308 - val_loss: 0.1357 - val_mean_squared_error: 0.1357\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.12744\n",
      "Epoch 66/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1311 - mean_squared_error: 0.1311 - val_loss: 0.1277 - val_mean_squared_error: 0.1277\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.12744\n",
      "Epoch 67/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1302 - mean_squared_error: 0.1302 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.12744\n",
      "Epoch 68/100\n",
      "6072894/6072894 [==============================] - 185s 30us/step - loss: 0.1295 - mean_squared_error: 0.1295 - val_loss: 0.1280 - val_mean_squared_error: 0.1280\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.12744\n",
      "Epoch 69/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1292 - mean_squared_error: 0.1292 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.12744\n",
      "Epoch 70/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1294 - mean_squared_error: 0.1294 - val_loss: 0.1249 - val_mean_squared_error: 0.1249\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.12744 to 0.12486, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-70\n",
      "Epoch 71/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1288 - mean_squared_error: 0.1288 - val_loss: 0.1435 - val_mean_squared_error: 0.1435\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.12486\n",
      "Epoch 72/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1285 - mean_squared_error: 0.1285 - val_loss: 0.1255 - val_mean_squared_error: 0.1255\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.12486\n",
      "Epoch 73/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1283 - mean_squared_error: 0.1283 - val_loss: 0.1294 - val_mean_squared_error: 0.1294\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.12486\n",
      "Epoch 74/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1279 - mean_squared_error: 0.1279 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.12486\n",
      "Epoch 75/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1280 - mean_squared_error: 0.1280 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.12486\n",
      "Epoch 76/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1274 - mean_squared_error: 0.1274 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.12486\n",
      "Epoch 77/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1272 - mean_squared_error: 0.1272 - val_loss: 0.1390 - val_mean_squared_error: 0.1390\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.12486\n",
      "Epoch 78/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1266 - mean_squared_error: 0.1266 - val_loss: 0.1235 - val_mean_squared_error: 0.1235\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.12486 to 0.12353, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-78\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1263 - mean_squared_error: 0.1263 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.12353\n",
      "Epoch 80/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1267 - mean_squared_error: 0.1267 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.12353 to 0.12317, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-80\n",
      "Epoch 81/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1264 - mean_squared_error: 0.1264 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.12317\n",
      "Epoch 82/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1261 - mean_squared_error: 0.1261 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.12317\n",
      "Epoch 83/100\n",
      "6072894/6072894 [==============================] - 186s 31us/step - loss: 0.1258 - mean_squared_error: 0.1258 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.12317 to 0.12264, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-83\n",
      "Epoch 84/100\n",
      "6072894/6072894 [==============================] - 185s 31us/step - loss: 0.1261 - mean_squared_error: 0.1261 - val_loss: 0.1225 - val_mean_squared_error: 0.1225\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.12264 to 0.12254, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-4-84\n",
      "Epoch 00084: early stopping\n",
      "5\n",
      "Train on 6072894 samples, validate on 1515113 samples\n",
      "Epoch 1/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 11.2116 - mean_squared_error: 11.2116 - val_loss: 8.8555 - val_mean_squared_error: 8.8555\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.85551, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-01\n",
      "Epoch 2/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 8.2634 - mean_squared_error: 8.2634 - val_loss: 7.7589 - val_mean_squared_error: 7.7589\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.85551 to 7.75893, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-02\n",
      "Epoch 3/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 7.5286 - mean_squared_error: 7.5286 - val_loss: 7.2065 - val_mean_squared_error: 7.2065\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.75893 to 7.20654, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-03\n",
      "Epoch 4/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 7.1354 - mean_squared_error: 7.1354 - val_loss: 7.0039 - val_mean_squared_error: 7.0039\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.20654 to 7.00390, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-04\n",
      "Epoch 5/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.8765 - mean_squared_error: 6.8765 - val_loss: 6.8818 - val_mean_squared_error: 6.8818\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.00390 to 6.88177, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-05\n",
      "Epoch 6/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.6899 - mean_squared_error: 6.6899 - val_loss: 6.6316 - val_mean_squared_error: 6.6316\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.88177 to 6.63163, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-06\n",
      "Epoch 7/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.5460 - mean_squared_error: 6.5460 - val_loss: 6.4552 - val_mean_squared_error: 6.4552\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.63163 to 6.45523, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-07\n",
      "Epoch 8/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.4309 - mean_squared_error: 6.4309 - val_loss: 6.4627 - val_mean_squared_error: 6.4627\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.45523\n",
      "Epoch 9/100\n",
      "6072894/6072894 [==============================] - 140s 23us/step - loss: 6.3504 - mean_squared_error: 6.3504 - val_loss: 6.2864 - val_mean_squared_error: 6.2864\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.45523 to 6.28644, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-09\n",
      "Epoch 10/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.2990 - mean_squared_error: 6.2990 - val_loss: 6.2023 - val_mean_squared_error: 6.2023\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.28644 to 6.20227, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-10\n",
      "Epoch 11/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.2236 - mean_squared_error: 6.2236 - val_loss: 6.2522 - val_mean_squared_error: 6.2522\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6.20227\n",
      "Epoch 12/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.1564 - mean_squared_error: 6.1564 - val_loss: 6.0201 - val_mean_squared_error: 6.0201\n",
      "\n",
      "Epoch 00012: val_loss improved from 6.20227 to 6.02005, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-12\n",
      "Epoch 13/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.1035 - mean_squared_error: 6.1035 - val_loss: 6.0602 - val_mean_squared_error: 6.0602\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 6.02005\n",
      "Epoch 14/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.0486 - mean_squared_error: 6.0486 - val_loss: 6.0491 - val_mean_squared_error: 6.0491\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.02005\n",
      "Epoch 15/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 6.0041 - mean_squared_error: 6.0041 - val_loss: 5.8664 - val_mean_squared_error: 5.8664\n",
      "\n",
      "Epoch 00015: val_loss improved from 6.02005 to 5.86644, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-15\n",
      "Epoch 16/100\n",
      "6072894/6072894 [==============================] - 139s 23us/step - loss: 5.9601 - mean_squared_error: 5.9601 - val_loss: 5.9529 - val_mean_squared_error: 5.9529\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.86644\n",
      "Epoch 17/100\n",
      "6072894/6072894 [==============================] - 145s 24us/step - loss: 5.9228 - mean_squared_error: 5.9228 - val_loss: 5.9584 - val_mean_squared_error: 5.9584\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.86644\n",
      "Epoch 18/100\n",
      "6072894/6072894 [==============================] - 140s 23us/step - loss: 5.8905 - mean_squared_error: 5.8905 - val_loss: 6.3319 - val_mean_squared_error: 6.3319\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.86644\n",
      "Epoch 19/100\n",
      "6072894/6072894 [==============================] - 145s 24us/step - loss: 5.8579 - mean_squared_error: 5.8579 - val_loss: 5.8422 - val_mean_squared_error: 5.8422\n",
      "\n",
      "Epoch 00019: val_loss improved from 5.86644 to 5.84218, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-19\n",
      "Epoch 20/100\n",
      "6072894/6072894 [==============================] - 150s 25us/step - loss: 5.8292 - mean_squared_error: 5.8292 - val_loss: 5.8810 - val_mean_squared_error: 5.8810\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.84218\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072894/6072894 [==============================] - 151s 25us/step - loss: 5.8031 - mean_squared_error: 5.8031 - val_loss: 5.7604 - val_mean_squared_error: 5.7604\n",
      "\n",
      "Epoch 00021: val_loss improved from 5.84218 to 5.76037, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-21\n",
      "Epoch 22/100\n",
      "6072894/6072894 [==============================] - 151s 25us/step - loss: 5.7759 - mean_squared_error: 5.7759 - val_loss: 5.6828 - val_mean_squared_error: 5.6828\n",
      "\n",
      "Epoch 00022: val_loss improved from 5.76037 to 5.68275, saving model to /home/afengler/git_repos/nn_likelihoods/keras_models//dnnregressor_wftp_hyp_opt_choice_rt_09_15_18_23_59_39/ckpt-5-22\n",
      "Epoch 23/100\n",
      "6072894/6072894 [==============================] - 148s 24us/step - loss: 5.7512 - mean_squared_error: 5.7512 - val_loss: 5.6845 - val_mean_squared_error: 5.6845\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.68275\n",
      "Epoch 24/100\n",
      "6072894/6072894 [==============================] - 150s 25us/step - loss: 5.7280 - mean_squared_error: 5.7280 - val_loss: 5.6932 - val_mean_squared_error: 5.6932\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.68275\n",
      "Epoch 25/100\n",
      "3214752/6072894 [==============>...............] - ETA: 1:04 - loss: 5.7229 - mean_squared_error: 5.7229"
     ]
    }
   ],
   "source": [
    "# Hyperparameter training loop:\n",
    "\n",
    "# Runs: \n",
    "num_runs = 20\n",
    "cnt = 0\n",
    "max_layers = 5\n",
    "layer_sizes = [10, 20, 50]\n",
    "batch_sizes = [1000, 10000, 50000]\n",
    "\n",
    "# Update model directory to make sure we collect all our models from this hyperparameter optimization run in the same place\n",
    "cpm.data_params['model_directory'] =  '/home/afengler/git_repos/nn_likelihoods/keras_models/'\n",
    "cpm.data_params['model_name'] = 'dnnregressor_wftp_hyp_opt'\n",
    "cpm.data_params['model_cnt'] = 32\n",
    "\n",
    "histories = []\n",
    "\n",
    "while cnt < num_runs:\n",
    "    cnt += 1\n",
    "    \n",
    "    # Sample # layers \n",
    "    num_layers = np.random.choice(np.arange(1, max_layers, 1))\n",
    "    \n",
    "    # Layer sizes\n",
    "    layers = []\n",
    "    activations = []\n",
    "    regularizers = []\n",
    "    \n",
    "    for i in range(0, num_layers, 1):\n",
    "        layers.append(np.random.choice(layer_sizes))\n",
    "        activations.append('relu')\n",
    "        regularizers.append(0.0)\n",
    "        \n",
    "    # Batch size\n",
    "    batch_size = np.random.choice(batch_sizes)\n",
    "    \n",
    "    # Update relevant model parameters\n",
    "    cpm.train_params['batch_size'] = batch_size\n",
    "    cpm.model_params['hidden_layers'] = layers\n",
    "    cpm.model_params['hidden_activations'] = activations\n",
    "    cpm.model_params['l1_activation'] = regularizers\n",
    "    cpm.model_params['l2_activation'] = regularizers\n",
    "    cpm.model_params['l1_kernel'] = regularizers\n",
    "    cpm.model_params['l2_kernel'] = regularizers\n",
    "    \n",
    "    # Increment model count\n",
    "    cpm.data_params['model_cnt'] += 1\n",
    "    \n",
    "    # Make new timestamp\n",
    "    #cpm.data_params['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "    \n",
    "    # Make model\n",
    "    cpm.keras_model_generate(save_model = True)\n",
    "    \n",
    "    # Train model\n",
    "    histories.append(cpm.run_training(save_history = True, \n",
    "                                    warm_start = False))\n",
    "    \n",
    "    histories[-1]['model_cnt'] = cpm.train_params['model_cnt']\n",
    "    histories[-1]['num_layers'] = num_layers\n",
    "    histories[-1]['size_layers'] = str(layers)\n",
    "    histories[-1]['activations'] = str(activations) \n",
    "    histories[-1]['batch_size'] = batch_size\n",
    "    \n",
    "    print(cnt)\n",
    "    \n",
    "histories = pd.concat(histories)\n",
    "histories['optimizer'] = cpm.model_params['optimizer']\n",
    "histories['timestamp'] = datetime.now().strftime('%m_%d_%y_%H_%M_%S')\n",
    "histories.to_csv(cpm.data_params['model_directory'] + cpm.data_params['model_name'] + '_choice_rt_' +\\\n",
    "                 cpm.data_params['timestamp'] + '/hyp_opt_histories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm.train_params['min_delta'] = 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
