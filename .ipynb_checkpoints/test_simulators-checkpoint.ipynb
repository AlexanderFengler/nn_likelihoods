{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/afengler/miniconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Environ\n",
    "import scipy as scp\n",
    "import tensorflow as tf\n",
    "from scipy.stats import gamma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# import dataset_generator as dg\n",
    "# import make_data_lba as mdlba\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# Own\n",
    "import ddm_data_simulation as ds\n",
    "import cddm_data_simulation as cds\n",
    "import kde_training_utilities as kde_util\n",
    "import kde_class as kde\n",
    "import boundary_functions as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDM  \n",
    "repeats = 1\n",
    "my_means = np.zeros(repeats)\n",
    "for i in range(repeats):\n",
    "    out = cds.ddm_flexbound(v = 0, \n",
    "                            a = 0.96,\n",
    "                            w = 0.5,\n",
    "                            ndt = 0.5,\n",
    "                            delta_t = 0.01, \n",
    "                            max_t = 20,\n",
    "                            n_samples = 20000,\n",
    "                            boundary_fun = bf.weibull_cdf,\n",
    "                            boundary_multiplicative = False, \n",
    "                            boundary_params = {'a': 1, 'beta': 2})\n",
    "                            #boundary_params = {\"theta\": 0.01})\n",
    "    print(i)\n",
    "    \n",
    "    my_means[i] = np.mean(out[0][out[1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_simulator_output(out = [0, 0],\n",
    "                         bin_dt = 0.04,\n",
    "                         n_bins = 0,\n",
    "                         eps_correction = 1e-7, # min p for a bin\n",
    "                         params = ['v', 'a', 'w', 'ndt']\n",
    "                        ): # ['v', 'a', 'w', 'ndt', 'angle']\n",
    "\n",
    "    # Generate bins\n",
    "    if n_bins == 0:\n",
    "        n_bins = int(out[2]['max_t'] / bin_dt)\n",
    "        bins = np.linspace(0, out[2]['max_t'], n_bins)\n",
    "    else:    \n",
    "        bins = np.linspace(0, out[2]['max_t'], n_bins)\n",
    "        bins = np.append(bins, [100])\n",
    "        print(bins)\n",
    "    counts = []\n",
    "    cnt = 0\n",
    "    counts = np.zeros( (n_bins, len(out[2]['possible_choices']) ) )\n",
    "    counts_size = counts.shape[0] * counts.shape[1]\n",
    "    \n",
    "    for choice in out[2]['possible_choices']:\n",
    "        counts[:, cnt] = np.histogram(out[0][out[1] == choice], bins = bins)[0] / out[2]['n_samples']\n",
    "        cnt += 1\n",
    "    \n",
    "    # Apply correction for empty bins\n",
    "    n_small = 0\n",
    "    n_big = 0\n",
    "    n_small = np.sum(counts < eps_correction)\n",
    "    n_big = counts_size - n_small \n",
    "    \n",
    "    if eps_correction > 0:\n",
    "        counts[counts <= eps_correction] = eps_correction\n",
    "        counts[counts > eps_correction] -= (eps_correction * (n_small / n_big))\n",
    "\n",
    "    return ([out[2][param] for param in params], # features\n",
    "            counts, # labels\n",
    "            {'max_t': out[2]['max_t'], \n",
    "             'bin_dt': bin_dt, \n",
    "             'n_samples': out[2]['n_samples']} # meta data\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 5\n",
    "a, b = bin_simulator_output(out = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cds.ornstein_uhlenbeck(v = 0.21,\n",
    "                             a = 1.5,\n",
    "                             w = 0.5,\n",
    "                             g = 1,\n",
    "                             ndt = 0.92,\n",
    "                             boundary_fun = bf.constant,\n",
    "                             n_samples = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sims = bin_simulator_output(out = out,\n",
    "                                   n_bins = 256,\n",
    "                                   eps_correction = 1e-7,\n",
    "                                   params = ['v', 'a', 'w', 'g', 'ndt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(binned_sims[1][:, 1])\n",
    "plt.plot(binned_sims[1][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sims[1][255, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_ = os.listdir('/media/data_cifs/afengler/data/kde/ddm/base_simulations_20000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((250000, 500, 2))\n",
    "features = np.zeros((250000, 3))\n",
    "\n",
    "cnt = 0\n",
    "i = 0\n",
    "file_dim = 100\n",
    "for file_ in files_[:1000]:\n",
    "    if file_[:8] == 'ddm_flex':\n",
    "        out = pickle.load(open('/media/data_cifs/afengler/data/kde/ddm/base_simulations_20000/' + file_, 'rb'))\n",
    "        features[cnt], labels[cnt] = bin_simulator_output(out = out)\n",
    "        if cnt % file_dim == 0:\n",
    "            print(cnt)\n",
    "            pickle.dump((labels[(i * file_dim):((i + 1) * file_dim)], features[(i * file_dim):((i + 1) * file_dim)]), open('/media/data_cifs/afengler/data/kde/ddm/base_simulations_20000_binned/dataset_' + str(i), 'wb'))\n",
    "            i += 1\n",
    "        cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DDM  \n",
    "repeats = 50\n",
    "my_means = np.zeros(repeats)\n",
    "for i in range(repeats):\n",
    "    out = cds.full_ddm(v = 0, \n",
    "                       a = 0.96,\n",
    "                       w = 0.5,\n",
    "                       ndt = 0.5,\n",
    "                       dw = 0.0,\n",
    "                       sdv = 0.0,\n",
    "                       dndt = 0.5,\n",
    "                       delta_t = 0.01, \n",
    "                       max_t = 20,\n",
    "                       n_samples = 10000,\n",
    "                       boundary_fun = bf.constant,\n",
    "                       boundary_multiplicative = True, \n",
    "                       boundary_params = {})\n",
    "    print(i)\n",
    "    \n",
    "    my_means[i] = np.mean(out[0][out[1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out[0] * out[1], bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(50 / out[2]['delta_t'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCA \n",
    "repeats = 1\n",
    "my_means = np.zeros(repeats)\n",
    "for i in range(repeats):\n",
    "    out = cds.lca(v = np.array([0, 0], dtype = np.float32), \n",
    "                  a = 2, \n",
    "                  w = np.array([0.5, 0.5], dtype = np.float32), \n",
    "                  ndt = np.array([1.0, 1.0], dtype = np.float32),\n",
    "                  g = -1.0,\n",
    "                  b = 1.0,\n",
    "                  delta_t = 0.01, \n",
    "                  max_t = 40,\n",
    "                  n_samples = 10000,\n",
    "                  boundary_fun = bf.constant,\n",
    "                  boundary_multiplicative = True, \n",
    "                  boundary_params = {})\n",
    "    print(i)\n",
    "    my_means[i] = np.mean(out[0][out[1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1][out[1] == 0] = -1\n",
    "plt.hist(out[0] * out[1], bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCA \n",
    "repeats = 10\n",
    "my_means = np.zeros(repeats)\n",
    "for i in range(repeats):\n",
    "    out = cds.ddm_flexbound(v = 0.0, \n",
    "                            a = 1.5, \n",
    "                            w = 0.5, \n",
    "                            ndt = 0.1,\n",
    "                            delta_t = 0.01, \n",
    "                            max_t = 40,\n",
    "                            n_samples = 10000,\n",
    "                            boundary_fun = bf.constant,\n",
    "                            boundary_multiplicative = True, \n",
    "                            boundary_params = {})\n",
    "    print(i)\n",
    "    my_means[i] = np.mean(out[0][out[1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(name, *args, **kwargs):\n",
    "    print (\"args: \", args)\n",
    "    print (\"Type of args: \", type(args))\n",
    "    if len(args)>2:\n",
    "        args = args[0], args[1]     #- Created Same name variable.\n",
    "    print (\"Temp args:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = []\n",
    "for key in test_dat.keys():\n",
    "    if key[0] == 'v':\n",
    "        my_keys.append(key)\n",
    "np.array(test_dat.loc[1, ['v_0', 'v_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dat = mdlba.make_data_rt_choice(target_folder = my_target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(my_dat['log_likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([out[0], out[1]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "cds.race_model(boundary_fun = bf.constant,\n",
    "              n_samples = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(np.random.uniform(size = (10000,4)), q = [0.05, 0.10, 0.9, 0.95], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(map(tuple, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.apply_along_axis(my_func, 0, a, key_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(a[0,:], ['a' ,'b', 'c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x = 0, key_vec = ['a' ,'b', 'c']):\n",
    "    return dict(zip(key_vec, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_func_init = my_func(key_vec = ['d', 'e', 'f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_vec = ['d', 'e', 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = yaml.load(open('config_files/config_data_generator.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =tuple([i[1] for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "starmap() got an unexpected keyword argument 'callback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b1b17a601579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: starmap() got an unexpected keyword argument 'callback'"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def myfunc(a):\n",
    "    return a ** 2\n",
    "pbar = tqdm(total = 100)\n",
    "def update():\n",
    "    pbar.update\n",
    "\n",
    "a = tuple()\n",
    "for i in range(pbar.total):\n",
    "    a += ((1, ), )\n",
    "    \n",
    "pool = Pool(4)\n",
    "pool.starmap(myfunc, a, callback = update)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fun(*args):\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fun((1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dg.make_dataset_r_dgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dict(x = [], \n",
    "             key_vec = ['a', 'b', 'c']):\n",
    "    return dict(zip(key_vec, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dg = dg.data_generator(file_id = 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = my_dg.make_dataset_perturbation_experiment(save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((100, 2))\n",
    "b = ['a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.apply_along_axis(zip_dict, 1,\n",
    "                    a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = my_dg.make_dataset_uniform(save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dg.param_grid_perturbation_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = my_dg.param_grid_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "tt = my_dg.generate_data_grid_parallel(param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dg.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a': 10, 'b': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, 1] = ['a', 'a', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.choice(10, size = (1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in zip([1,2,3], [1, 2, 3], [1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
