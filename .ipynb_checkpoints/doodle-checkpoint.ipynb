{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.stats as scps\n",
    "import pickle\n",
    "\n",
    "# Load my own functions\n",
    "import dnnregressor_train_eval_keras as dnnk\n",
    "from kde_training_utilities import kde_load_data\n",
    "import make_data_wfpt as mdw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (7,))\n",
    "x = Dense(20, activation = 'relu')(inputs)\n",
    "# x = Dense(40, activation = 'relu')(x)\n",
    "# x = Dense(60, activation = 'relu')(x)\n",
    "# x = Dense(80, activation = 'relu')(x)\n",
    "# x = Dense(100, activation = 'relu')(x)\n",
    "# x = Dense(120, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'linear')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer = 'nadam',\n",
    "              loss = 'mse',\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(low = -1, high = 1, size = ((100000000, 7)))\n",
    "labels = np.matmul(data, np.array([1, 2, 3, 4, 5, 6, 7]))\n",
    "labels = labels + np.random.normal(loc = 0, scale = 0.1, size = 100000000)\n",
    "#labesl = np.random.uniform(low = -1, high = 1, size = ((100000000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.random.uniform(low = -1, high = 1, size = ((10000000, 7)))\n",
    "labels_test = np.matmul(data_test, np.array([1, 2, 3, 4, 5, 6, 7]))\n",
    "labels_test = labels_test + np.random.normal(loc = 0, scale = 0.1, size = 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000000 samples, validate on 10000000 samples\n",
      "Epoch 1/20\n",
      "100000000/100000000 [==============================] - 55s 1us/step - loss: 11.5801 - mean_squared_error: 11.5801 - val_loss: 0.3553 - val_mean_squared_error: 0.3553\n",
      "Epoch 2/20\n",
      "100000000/100000000 [==============================] - 53s 1us/step - loss: 0.2401 - mean_squared_error: 0.2401 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 3/20\n",
      "100000000/100000000 [==============================] - 56s 1us/step - loss: 0.1214 - mean_squared_error: 0.1214 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 4/20\n",
      "100000000/100000000 [==============================] - 52s 1us/step - loss: 0.0690 - mean_squared_error: 0.0690 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "Epoch 5/20\n",
      "100000000/100000000 [==============================] - 52s 1us/step - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "Epoch 6/20\n",
      "100000000/100000000 [==============================] - 52s 1us/step - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 7/20\n",
      "100000000/100000000 [==============================] - 56s 1us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 8/20\n",
      "100000000/100000000 [==============================] - 55s 1us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
      "Epoch 9/20\n",
      "100000000/100000000 [==============================] - 56s 1us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 10/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 11/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 12/20\n",
      "100000000/100000000 [==============================] - 51s 1us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "Epoch 13/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 14/20\n",
      "100000000/100000000 [==============================] - 55s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 15/20\n",
      "100000000/100000000 [==============================] - 55s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 16/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 17/20\n",
      "100000000/100000000 [==============================] - 56s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 18/20\n",
      "100000000/100000000 [==============================] - 53s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 19/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 20/20\n",
      "100000000/100000000 [==============================] - 54s 1us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n"
     ]
    }
   ],
   "source": [
    "out = model.fit(data[:,:7],\n",
    "                  labels,\n",
    "                  epochs = 20,\n",
    "                  validation_data = ((data_test, labels_test)),\n",
    "                  batch_size = 200000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
